{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import psutil\n",
    "from typing import Tuple, Union\n",
    "from timeit import timeit\n",
    "from typing import Callable\n",
    "from warnings import warn\n",
    "\n",
    "# PyTorch dependencies\n",
    "import torch\n",
    "import torch.backends.opt_einsum as opt_einsum\n",
    "from torch import Tensor\n",
    "\n",
    "# Jax Depencencies\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import Array\n",
    "from jax.experimental.jet import jet\n",
    "from jax._src.lib import xla_client\n",
    "\n",
    "# Internal dependencies\n",
    "from thoad import backward, Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# control size of tensors\n",
    "TENSOR_SCALE: Union[int, float] = 1\n",
    "REPEAT_SCALE: Union[int, float] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275c42dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system           Windows 11 10.0.26100\n"
     ]
    }
   ],
   "source": [
    "sys: platform.uname_result = platform.uname()\n",
    "print(f\"system           {sys.system} {sys.release} {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b7adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device     cpu -> AMD64 Family 23 Model 160 Stepping 0, AuthenticAMD\n",
      "physical cores   4\n",
      "logical cores    8\n"
     ]
    }
   ],
   "source": [
    "torch_dev: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch_dev.type == 'cuda':\n",
    "    idx = torch_dev.index if torch_dev.index is not None else 0\n",
    "    props: \"_CudaDeviceProperties\" = torch.cuda.get_device_properties(idx)\n",
    "    name: str = props.name\n",
    "    total_mem_gb: float = props.total_memory / (1024**3)\n",
    "    print(f\"using device     {torch_dev} -> {name}\")\n",
    "    print(f\"device memory    {total_mem_gb:.1f} GB)\")\n",
    "else:\n",
    "    cpu_name: str = platform.processor() or \"CPU\"\n",
    "    print(f\"using device     {torch_dev} -> {cpu_name}\")\n",
    "    print(f\"physical cores   {psutil.cpu_count(logical=False)}\")\n",
    "    print(f\"logical cores    {psutil.cpu_count(logical=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db955b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device     TFRT_CPU_0\n"
     ]
    }
   ],
   "source": [
    "_available_gpus: list[xla_client.Device]\n",
    "_available_gpus = [d for d in jax.devices() if d.platform == \"gpu\"]\n",
    "dev_name: xla_client.Device\n",
    "dev_name = _available_gpus[0] if len(_available_gpus) > 0 else jax.devices(\"cpu\")[0]\n",
    "print(f\"using device     {dev_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd37689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_einsum backend enabled\n"
     ]
    }
   ],
   "source": [
    "if opt_einsum.is_available():\n",
    "    opt_einsum.enabled = True\n",
    "    print(\"opt_einsum backend enabled\")\n",
    "    opt_einsum.strategy = \"optimal\"\n",
    "else:\n",
    "    warn(\n",
    "        \"opt_einsum backend is not available. \"\n",
    "        \"For better performance, install and enable opt_einsum.\",\n",
    "        UserWarning\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b6eb3",
   "metadata": {},
   "source": [
    "jax.experimental.jet documentation example (https://docs.jax.dev/en/latest/jax.experimental.jet.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82093f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f   : [0.09983342 0.19866933 0.29552022]\n",
      "df*h1: [0.9950042 0.9800666 0.9553365]\n",
      "ddf*h1^2 + df*h2: [-0.09983342 -0.19866933 -0.29552022]\n"
     ]
    }
   ],
   "source": [
    "h0: Array = jnp.array([0.1, 0.2, 0.3])\n",
    "h1: Array = jnp.ones_like(h0)\n",
    "h2: Array = jnp.zeros_like(h0)\n",
    "\n",
    "f: Callable[[Array], Array]\n",
    "df: Callable[[Array], Array]\n",
    "ddf: Callable[[Array], Array]\n",
    "f, df, ddf = jnp.sin, jnp.cos, lambda x: -jnp.sin(x)\n",
    "\n",
    "f0: Array\n",
    "f1: Array\n",
    "f2: Array\n",
    "f0, (f1, f2) = jax.experimental.jet.jet(f, (h0,), ((h1, h2),))\n",
    "\n",
    "print(\"f   :\", (jet_f0 := f(h0)))\n",
    "print(\"df*h1:\", (jet_f1 := df(h0) * h1))               \n",
    "print(\"ddf*h1^2 + df*h2:\", (jet_f2 := ddf(h0) * h1**2 + df(h0) * h2))\n",
    "assert jnp.allclose(f0, jet_f0)\n",
    "assert jnp.allclose(f1, jet_f1)\n",
    "assert jnp.allclose(f2, jet_f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e54b75",
   "metadata": {},
   "source": [
    "## **Benchmark differentiations on full MLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605824e0",
   "metadata": {},
   "source": [
    "definition of MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8178fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jax_forward_pass(X: jax.Array, *params: jax.Array) -> jax.Array:\n",
    "    T: Array = X\n",
    "    for i, P in enumerate(params):\n",
    "        last_step: bool = (i == len(params) - 1)\n",
    "        T = T @ P\n",
    "        T = jnp.maximum(T, 0) if not last_step else jax.nn.softmax(T, axis=1)\n",
    "    return T\n",
    "\n",
    "def torch_foward_pass(X: Tensor, *params) -> Tensor:\n",
    "    T: Tensor = X\n",
    "    for i, P in enumerate(params):\n",
    "        last_step: bool = i == (len(params) - 1)\n",
    "        T = T @ P\n",
    "        T = torch.softmax(T, dim=1) if last_step else torch.relu(T)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823667b",
   "metadata": {},
   "source": [
    "definition of helper functions to meassure differentiation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "214f4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_jet_differentiation(reps: int, order: int, X: jax.Array, *params) -> float:\n",
    "    def _fwd(x) -> Array:\n",
    "        return jax_forward_pass(x, *params)\n",
    "    seed_tangents: Tuple[Array, ...] = tuple(jnp.ones_like(X) for _ in range(order))\n",
    "    series: Tuple[Tuple[Array, ...]] = (seed_tangents,)\n",
    "    jet(_fwd, (X,), series)  # warm up once to avoid including compile time\n",
    "    return timeit(lambda: jet(_fwd, (X,), series), number=reps)\n",
    "\n",
    "def time_thoad_differentiation(reps: int, order:int, X: Tensor, *params) -> float:\n",
    "    X.requires_grad_(True)\n",
    "    params: list[Tensor] = [P.requires_grad_(False) for P in params]\n",
    "    assert all(not param.requires_grad for param in params)\n",
    "    def _foward_and_backward() -> None:\n",
    "        T: Tensor = torch_foward_pass(X, *params)\n",
    "        ctrl: Controller = backward(tensor=T, order=order, crossings=False, keep_batch=True)\n",
    "        ctrl.clear()\n",
    "        return None\n",
    "    time: float = timeit(\n",
    "        lambda: _foward_and_backward(),\n",
    "        number=reps,\n",
    "    )\n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727de33e",
   "metadata": {},
   "source": [
    "differentiation computational cost w.r.t. **order** and **batch size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4abe7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDER 1\n",
      "batch size: 15 -> jax time: 0.0035  thoad time: 0.0086\n",
      "batch size: 30 -> jax time: 0.0034  thoad time: 0.0085\n",
      "batch size: 45 -> jax time: 0.0049  thoad time: 0.0102\n",
      "batch size: 60 -> jax time: 0.0042  thoad time: 0.0122\n",
      "batch size: 75 -> jax time: 0.0037  thoad time: 0.0118\n",
      "batch size: 90 -> jax time: 0.0040  thoad time: 0.0148\n",
      "\n",
      "ORDER 2\n",
      "batch size: 07 -> jax time: 0.0055  thoad time: 0.0154\n",
      "batch size: 15 -> jax time: 0.0043  thoad time: 0.0173\n",
      "batch size: 22 -> jax time: 0.0043  thoad time: 0.0171\n",
      "batch size: 30 -> jax time: 0.0062  thoad time: 0.0262\n",
      "batch size: 37 -> jax time: 0.0044  thoad time: 0.0248\n",
      "batch size: 45 -> jax time: 0.0052  thoad time: 0.0253\n",
      "\n",
      "ORDER 3\n",
      "batch size: 05 -> jax time: 0.0057  thoad time: 0.0268\n",
      "batch size: 10 -> jax time: 0.0056  thoad time: 0.0264\n",
      "batch size: 15 -> jax time: 0.0069  thoad time: 0.0320\n",
      "batch size: 20 -> jax time: 0.0081  thoad time: 0.0438\n",
      "batch size: 25 -> jax time: 0.0052  thoad time: 0.0577\n",
      "batch size: 30 -> jax time: 0.0062  thoad time: 0.0572\n"
     ]
    }
   ],
   "source": [
    "for o in [1, 2, 3]:\n",
    "    print(f\"\\nORDER {o}\")\n",
    "    for batch_size in [15, 30, 45, 60, 75, 90]:\n",
    "        batch_size //= o\n",
    "        param_size: int = int(5 * TENSOR_SCALE)\n",
    "        x_shape: Tuple[int, int] = (batch_size, param_size)\n",
    "        p_shape: Tuple[int, int] = (param_size, param_size)\n",
    "\n",
    "        # create jax tensors\n",
    "        key: Array = jax.random.PRNGKey(0)\n",
    "        jax_X: Array = jax.random.uniform(key, x_shape)\n",
    "        jax_params: list[Array] = []\n",
    "        for i in range(3):\n",
    "            key: Array\n",
    "            subkey: Array\n",
    "            key, subkey = jax.random.split(key)\n",
    "            jax_params.append(jax.random.uniform(subkey, p_shape))\n",
    "\n",
    "        # create torch tensors\n",
    "        torch_X: Tensor = torch.rand(size=x_shape, device=torch_dev)\n",
    "        torch_params: list[Tensor] = [\n",
    "            torch.rand(size=p_shape, device=torch_dev) for _ in range(3)\n",
    "        ]\n",
    "\n",
    "        reps: int = int(600 * (1 / batch_size) * (1/o) * REPEAT_SCALE)\n",
    "        jax_time: float = time_jet_differentiation(reps, o, jax_X, *jax_params)\n",
    "        thoad_time: float = time_thoad_differentiation(reps, o, torch_X, *torch_params)\n",
    "        print(\n",
    "            f\"batch size: {batch_size:02d} -> \"\n",
    "            f\"jax time: {jax_time/reps:.4f}  thoad time: {thoad_time/reps:.4f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f907f6",
   "metadata": {},
   "source": [
    "differentiation computational cost w.r.t. **order** and **param size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dfbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDER 1\n",
      "param size: 10 -> jax time: 0.0044  thoad time: 0.0089\n",
      "param size: 20 -> jax time: 0.0045  thoad time: 0.0125\n",
      "param size: 30 -> jax time: 0.0039  thoad time: 0.0104\n",
      "param size: 40 -> jax time: 0.0044  thoad time: 0.0102\n",
      "param size: 50 -> jax time: 0.0045  thoad time: 0.0106\n",
      "param size: 60 -> jax time: 0.0065  thoad time: 0.0199\n",
      "\n",
      "ORDER 2\n",
      "param size: 05 -> jax time: 0.0066  thoad time: 0.0161\n",
      "param size: 10 -> jax time: 0.0064  thoad time: 0.0202\n",
      "param size: 15 -> jax time: 0.0061  thoad time: 0.0224\n",
      "param size: 20 -> jax time: 0.0074  thoad time: 0.0225\n",
      "param size: 25 -> jax time: 0.0044  thoad time: 0.0275\n",
      "param size: 30 -> jax time: 0.0079  thoad time: 0.0483\n",
      "\n",
      "ORDER 3\n",
      "param size: 03 -> jax time: 0.0054  thoad time: 0.0297\n",
      "param size: 06 -> jax time: 0.0057  thoad time: 0.0268\n",
      "param size: 10 -> jax time: 0.0090  thoad time: 0.0477\n",
      "param size: 13 -> jax time: 0.0059  thoad time: 0.0599\n",
      "param size: 16 -> jax time: 0.0060  thoad time: 0.0941\n",
      "param size: 20 -> jax time: 0.0071  thoad time: 0.1627\n"
     ]
    }
   ],
   "source": [
    "for o in [1, 2, 3]:\n",
    "    print(f\"\\nORDER {o}\")\n",
    "    for param_size in [10, 20, 30, 40, 50, 60]:\n",
    "        batch_size: int = int(5 * TENSOR_SCALE)\n",
    "        param_size //= o\n",
    "        x_shape: Tuple[int, int] = (batch_size, param_size)\n",
    "        p_shape: Tuple[int, int] = (param_size, param_size)\n",
    "\n",
    "        # create jax tensors\n",
    "        key: Array = jax.random.PRNGKey(0)\n",
    "        jax_X: Array = jax.random.uniform(key, x_shape)\n",
    "        jax_params: list[Array] = []\n",
    "        for i in range(3):\n",
    "            key: Array\n",
    "            subkey: Array\n",
    "            key, subkey = jax.random.split(key)\n",
    "            jax_params.append(jax.random.uniform(subkey, p_shape))\n",
    "\n",
    "        # create torch tensors\n",
    "        torch_X: Tensor = torch.rand(size=x_shape, device=torch_dev)\n",
    "        torch_params: list[Tensor] = [\n",
    "            torch.rand(size=p_shape, device=torch_dev) for _ in range(3)\n",
    "        ]\n",
    "\n",
    "        reps: int = int(600 * (1 / param_size) * (1/o) * REPEAT_SCALE)\n",
    "        jax_time: float = time_jet_differentiation(reps, o, jax_X, *jax_params)\n",
    "        thoad_time: float = time_thoad_differentiation(reps, o, torch_X, *torch_params)\n",
    "        print(\n",
    "            f\"param size: {param_size:02d} -> \"\n",
    "            f\"jax time: {jax_time/reps:.4f}  thoad time: {thoad_time/reps:.4f}\"\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f61f5fe",
   "metadata": {},
   "source": [
    "differentiation computational cost w.r.t. **graph depth** (param gradients included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd6063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORDER 1\n",
      "depth size: 02 -> jax time: 0.0047  thoad time: 0.0115\n",
      "depth size: 03 -> jax time: 0.0039  thoad time: 0.0150\n",
      "depth size: 04 -> jax time: 0.0059  thoad time: 0.0184\n",
      "depth size: 05 -> jax time: 0.0066  thoad time: 0.0243\n",
      "depth size: 06 -> jax time: 0.0080  thoad time: 0.0243\n",
      "depth size: 07 -> jax time: 0.0069  thoad time: 0.0287\n",
      "depth size: 08 -> jax time: 0.0098  thoad time: 0.0290\n",
      "\n",
      "ORDER 2\n",
      "depth size: 02 -> jax time: 0.0052  thoad time: 0.0152\n",
      "depth size: 03 -> jax time: 0.0048  thoad time: 0.0179\n",
      "depth size: 04 -> jax time: 0.0060  thoad time: 0.0227\n",
      "depth size: 05 -> jax time: 0.0104  thoad time: 0.0274\n",
      "depth size: 06 -> jax time: 0.0086  thoad time: 0.0333\n",
      "depth size: 07 -> jax time: 0.0109  thoad time: 0.0381\n",
      "depth size: 08 -> jax time: 0.0119  thoad time: 0.0394\n",
      "\n",
      "ORDER 3\n",
      "depth size: 02 -> jax time: 0.0048  thoad time: 0.0265\n",
      "depth size: 03 -> jax time: 0.0074  thoad time: 0.0257\n",
      "depth size: 04 -> jax time: 0.0077  thoad time: 0.0340\n",
      "depth size: 05 -> jax time: 0.0124  thoad time: 0.0399\n",
      "depth size: 06 -> jax time: 0.0118  thoad time: 0.0469\n",
      "depth size: 07 -> jax time: 0.0230  thoad time: 0.0524\n",
      "depth size: 08 -> jax time: 0.0115  thoad time: 0.0617\n"
     ]
    }
   ],
   "source": [
    "for o in [1, 2, 3]:\n",
    "    print(f\"\\nORDER {o}\")\n",
    "    for depth in [2, 3, 4, 5, 6, 7, 8]:\n",
    "        batch_size: int = 40 // o\n",
    "        param_size: int = int(10 // o * TENSOR_SCALE)\n",
    "        x_shape: Tuple[int, int] = (batch_size, param_size)\n",
    "        p_shape: Tuple[int, int] = (param_size, param_size)\n",
    "\n",
    "        # create jax tensors\n",
    "        key: Array = jax.random.PRNGKey(0)\n",
    "        jax_X: Array = jax.random.uniform(key, x_shape)\n",
    "        jax_params: list[Array] = []\n",
    "        for i in range(depth):\n",
    "            key: Array\n",
    "            subkey: Array\n",
    "            key, subkey = jax.random.split(key)\n",
    "            jax_params.append(jax.random.uniform(subkey, p_shape))\n",
    "\n",
    "        # create torch tensors\n",
    "        torch_X: Tensor = torch.rand(size=x_shape, device=torch_dev)\n",
    "        torch_params: list[Tensor] = [\n",
    "            torch.rand(size=p_shape, device=torch_dev) for _ in range(depth)\n",
    "        ]\n",
    "\n",
    "        reps: int = int(600 * (1 / depth) * (1/o) * REPEAT_SCALE)\n",
    "        jax_time: float = time_jet_differentiation(reps, o, jax_X, *jax_params)\n",
    "        thoad_time: float = time_thoad_differentiation(reps, o, torch_X, *torch_params)\n",
    "        print(\n",
    "            f\"depth size: {depth:02d} -> \"\n",
    "            f\"jax time: {jax_time/reps:.4f}  thoad time: {thoad_time/reps:.4f}\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
