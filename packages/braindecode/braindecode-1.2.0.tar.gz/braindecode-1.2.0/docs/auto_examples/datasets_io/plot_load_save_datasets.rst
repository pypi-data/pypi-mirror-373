
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/datasets_io/plot_load_save_datasets.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_datasets_io_plot_load_save_datasets.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_datasets_io_plot_load_save_datasets.py:

.. _load-save-dataset:

Load and save dataset example
=============================

In this example, we show how to load and save braindecode datasets.

.. GENERATED FROM PYTHON SOURCE LINES 8-23

.. code-block:: Python


    # Authors: Lukas Gemein <l.gemein@gmail.com>
    #
    # License: BSD (3-clause)

    import tempfile

    from braindecode.datasets import MOABBDataset
    from braindecode.datautil import load_concat_dataset
    from braindecode.preprocessing import (
        Preprocessor,
        create_windows_from_events,
        preprocess,
    )


.. GENERATED FROM PYTHON SOURCE LINES 24-25

First, we load some dataset using MOABB.

.. GENERATED FROM PYTHON SOURCE LINES 25-30

.. code-block:: Python

    dataset = MOABBDataset(
        dataset_name="BNCI2014001",
        subject_ids=[1],
    )


.. GENERATED FROM PYTHON SOURCE LINES 31-33

We can apply preprocessing steps to the dataset. It is also possible to skip
this step and not apply any preprocessing.

.. GENERATED FROM PYTHON SOURCE LINES 33-35

.. code-block:: Python

    preprocess(concat_ds=dataset, preprocessors=[Preprocessor(fn="resample", sfreq=10)])


.. GENERATED FROM PYTHON SOURCE LINES 36-42

We save the dataset to a an existing directory. It will create a '.fif' file
for every dataset in the concat dataset. Additionally it will create two
JSON files, the first holding the description of the dataset, the second
holding the name of the target. If you want to store to the same directory
several times, for example due to trying different preprocessing, you can
choose to overwrite the existing files.

.. GENERATED FROM PYTHON SOURCE LINES 42-49

.. code-block:: Python


    tmpdir = tempfile.mkdtemp()  # write in a temporary directory
    dataset.save(
        path=tmpdir,
        overwrite=False,
    )


.. GENERATED FROM PYTHON SOURCE LINES 50-56

We load the saved dataset from a directory. Signals can be preloaded in
compliance with mne. Optionally, only specific '.fif' files can be loaded
by specifying their ids. The target name can be changed, if the dataset
supports it (TUHAbnormal for example supports 'pathological', 'age', and
'gender'. If you stored a preprocessed version with target 'pathological'
it is possible to change the target upon loading).

.. GENERATED FROM PYTHON SOURCE LINES 56-63

.. code-block:: Python

    dataset_loaded = load_concat_dataset(
        path=tmpdir,
        preload=True,
        ids_to_load=[1, 3],
        target_name=None,
    )


.. GENERATED FROM PYTHON SOURCE LINES 64-66

The serialization utility also supports WindowsDatasets, so we create
compute windows next.

.. GENERATED FROM PYTHON SOURCE LINES 66-74

.. code-block:: Python

    windows_dataset = create_windows_from_events(
        concat_ds=dataset_loaded,
        trial_start_offset_samples=0,
        trial_stop_offset_samples=0,
    )

    windows_dataset.description


.. GENERATED FROM PYTHON SOURCE LINES 75-81

Again, we save the dataset to an existing directory. It will create a
'-epo.fif' file for every dataset in the concat dataset. Additionally it
will create a JSON file holding the description of the dataset. If you
want to store to the same directory several times, for example due to
trying different windowing parameters, you can choose to overwrite the
existing files.

.. GENERATED FROM PYTHON SOURCE LINES 81-86

.. code-block:: Python

    windows_dataset.save(
        path=tmpdir,
        overwrite=True,
    )


.. GENERATED FROM PYTHON SOURCE LINES 87-90

Load the saved dataset from a directory. Signals can be preloaded in
compliance with mne. Optionally, only specific '-epo.fif' files can be
loaded by specifying their ids.

.. GENERATED FROM PYTHON SOURCE LINES 90-99

.. code-block:: Python

    windows_dataset_loaded = load_concat_dataset(
        path=tmpdir,
        preload=False,
        ids_to_load=[0],
        target_name=None,
    )

    windows_dataset_loaded.description


.. GENERATED FROM PYTHON SOURCE LINES 100-101

.. include:: /links.inc

**Estimated memory usage:**  0 MB


.. _sphx_glr_download_auto_examples_datasets_io_plot_load_save_datasets.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_load_save_datasets.ipynb <plot_load_save_datasets.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_load_save_datasets.py <plot_load_save_datasets.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_load_save_datasets.zip <plot_load_save_datasets.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
