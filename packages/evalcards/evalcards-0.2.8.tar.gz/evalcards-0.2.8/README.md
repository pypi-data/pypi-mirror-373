# evalcards

[![PyPI version](https://img.shields.io/pypi/v/evalcards?logo=pypi&label=PyPI)](https://pypi.org/project/evalcards/)
[![Python versions](https://img.shields.io/pypi/pyversions/evalcards?logo=python&label=Python)](https://pypi.org/project/evalcards/)
[![Wheel](https://img.shields.io/pypi/wheel/evalcards?label=wheel)](https://pypi.org/project/evalcards/#files)
[![License](https://img.shields.io/pypi/l/evalcards?label=License)](https://pypi.org/project/evalcards/)
[![CI](https://github.com/Ricardouchub/evalcards/actions/workflows/ci.yml/badge.svg)](https://github.com/Ricardouchub/evalcards/actions/workflows/ci.yml)
[![Publish](https://github.com/Ricardouchub/evalcards/actions/workflows/release.yml/badge.svg)](https://github.com/Ricardouchub/evalcards/actions/workflows/release.yml)

**[evalcards](https://pypi.org/project/evalcards/)** genera reportes de evaluaci√≥n para **modelos supervisados** en **Markdown**, con **m√©tricas** y **gr√°ficos** listos para pegar en informes. Soporta:
- **Clasificaci√≥n**: binaria y **multiclase (OvR)** con curvas **ROC/PR** por clase.
- **Regresi√≥n**.
- **Forecasting** (series de tiempo): **sMAPE (%)** y **MASE**.




## Instalaci√≥n
-----------
```bash
pip install evalcards
```

## Uso r√°pido (Python)
-------------------
```python
from evalcards import make_report

# y_true: etiquetas/valores reales
# y_pred: etiquetas/valores predichos
# y_proba (opcional):
#   - binaria: vector 1D con prob. de la clase positiva
#   - multiclase: matriz (n_samples, n_classes) con prob. por clase

path = make_report(
    y_true, y_pred,
    y_proba=proba,                 # opcional
    path="reporte.md",             # nombre del archivo Markdown
    title="Mi modelo"              # t√≠tulo del reporte
)
print(path)  # ruta del reporte generado
```

## Qu√© eval√∫a
------------------
- **Clasificaci√≥n (binaria/multiclase)**  
  M√©tricas: `accuracy`, `precision/recall/F1` (macro/weighted),  
  AUC: `roc_auc` (binaria) y `roc_auc_ovr_macro` (multiclase).  
  Gr√°ficos: **matriz de confusi√≥n**, **ROC** y **PR** (por clase en multiclase).

- **Regresi√≥n**  
  M√©tricas: `MAE`, `MSE`, `RMSE`, `R¬≤`.  
  Gr√°ficos: **Ajuste (y vs ≈∑)** y **Residuales**.

- **Forecasting**  
  M√©tricas: `MAE`, `MSE`, `RMSE`, **sMAPE (%)**, **MASE**.  
  Par√°metros extra: `season` (p.ej. 12) e `insample` (serie de entrenamiento para MASE).  
  Gr√°ficos: **Ajuste** y **Residuales**.

## Ejemplos 
---------------
**1) Clasificaci√≥n binaria (scikit-learn)**
```python
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from evalcards import make_report

X, y = make_classification(n_samples=600, n_features=10, random_state=0)
X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3, random_state=0)

clf = LogisticRegression(max_iter=1000).fit(X_tr, y_tr)
y_pred = clf.predict(X_te)
proba = clf.predict_proba(X_te)[:, 1]

make_report(y_te, y_pred, y_proba=proba, path="rep_bin.md", title="Clasificaci√≥n binaria")
```

**2) Multiclase (OvR)**
```python
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from evalcards import make_report

X, y = load_iris(return_X_y=True)
X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3, random_state=0)

clf = RandomForestClassifier(random_state=0).fit(X_tr, y_tr)
y_pred = clf.predict(X_te)
proba = clf.predict_proba(X_te)  # (n_samples, n_classes)

make_report(
    y_te, y_pred, y_proba=proba,
    labels=[f"Clase_{c}" for c in clf.classes_],   # opcional (nombres por clase)
    path="rep_multi.md", title="Multiclase OvR"
)
```

**3) Regresi√≥n**
```python
from sklearn.datasets import make_regression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from evalcards import make_report

X, y = make_regression(n_samples=600, n_features=8, noise=10, random_state=0)
X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3, random_state=0)

reg = RandomForestRegressor(random_state=0).fit(X_tr, y_tr)
y_pred = reg.predict(X_te)

make_report(y_te, y_pred, path="rep_reg.md", title="Regresi√≥n")
```

**4) Forecasting (sMAPE/MASE)**
```python
import numpy as np
from evalcards import make_report

rng = np.random.default_rng(0)
t = np.arange(360)
y = 10 + 0.05*t + 5*np.sin(2*np.pi*t/12) + rng.normal(0,1,360)

y_train, y_test = y[:300], y[300:]
y_hat = y_test + rng.normal(0, 1.2, y_test.size)  # predicci√≥n de ejemplo

make_report(
    y_test, y_hat,
    task="forecast", season=12, insample=y_train,
    path="rep_forecast.md", title="Forecast"
)
```

## Salidas y PATH
-------------------
- Un archivo **Markdown** con las m√©tricas y referencias a im√°genes.
- Im√°genes **PNG** (confusi√≥n, ROC/PR, ajuste, residuales).
- Por defecto, si `path` no incluye carpeta, todo se guarda en `./evalcards_reports/`.  
  Puedes cambiar la carpeta con el argumento `out_dir` o usando una ruta en `path`.


## Soporte de idioma üá™üá∏ üá¨üáß
-------------------
Puedes generar reportes en espa√±ol o ingl√©s usando el par√°metro `lang` (Python o CLI):

```python
make_report(y_true, y_pred, path="rep.md", lang="en", title="My Model Report")
```
```bash
evalcards --y_true y_true.csv --y_pred y_pred.csv --lang en --out rep_en.md
```
Valores soportados: `"es"` (espa√±ol, default), `"en"` (ingl√©s).


## Entradas esperadas (formas comunes)
-----------------------------------
- **Clasificaci√≥n**
  - `y_true`: enteros 0..K-1 (o etiquetas string).
  - `y_pred`: del mismo tipo/espacio de clases que `y_true`.
  - `y_proba` (opcional):
    - **Binaria**: vector 1D con prob. de la clase positiva.
    - **Multiclase**: matriz `(n_samples, n_classes)` con una columna por clase (mismo orden que tu modelo).
- **Regresi√≥n / Forecast**
  - `y_true`, `y_pred`: arrays 1D de floats.
  - `insample` (forecast): serie de entrenamiento para MASE; `season` seg√∫n la estacionalidad (ej. 12 mensual/anual).

## Compatibilidad de modelos
------------------------
Funciona con **cualquier modelo** que produzca `predict` (y opcionalmente `predict_proba`):
- scikit-learn, XGBoost/LightGBM/CatBoost, statsmodels, Prophet/NeuralProphet, Keras/PyTorch (si pasas tus arrays).
- Multiclase: pasa `y_proba` como matriz (una columna por clase) y, si quieres, `labels` para nombres.


## Roadmap
------------------------
### v0.3 ‚Äî Salida y m√©tricas clave
- [ ] Reporte HTML autocontenido (`format="md|html"`)
- [ ] Export JSON** de m√©tricas/paths (`--export-json`)
- [ ] M√©tricas nuevas (clasificaci√≥n): AUPRC, Balanced Accuracy, MCC, Log Loss
- [ ] M√©tricas nuevas (regresi√≥n): MAPE, MedAE, RMSLE

### v0.4 ‚Äî Multiclase y umbrales
- [ ] ROC/PR micro & macro (multiclase) + `roc_auc_macro`, `average_precision_macro`
- [ ] An√°lisis de umbral (curvas precisi√≥n‚Äìrecobrado‚ÄìF1 vs umbral + mejor umbral por m√©trica)
- [ ] Matriz de confusi√≥n normalizada (global y por clase)

### v0.5 ‚Äî Probabilidades y comparaci√≥n
- [ ] Calibraci√≥n: Brier score + curva de confiabilidad
- [ ] Comparaci√≥n multi-modelo en un √∫nico reporte (tabla ‚Äúmejor por m√©trica‚Äù)
- [ ] Curvas gain/lift (opcional)

### v0.6 ‚Äî DX, formatos y docs
- [ ] Nuevos formatos de entrada: Parquet/Feather/NPZ
- [ ] Config de proyecto (`.evalcards.toml`) para defaults (outdir, t√≠tulos, idioma)
- [ ] Docs con MkDocs + GitHub Pages (gu√≠a, API, ejemplos ejecutables)
- [ ] Plantillas/temas Jinja2 (branding)


### Ideas
------------------------
- [ ] Soporte **multi-label**
- [ ] M√©tricas de ranking (MAP/NDCG)
- [ ] Curvas de calibraci√≥n por bins configurables
- [ ] QQ-plot e histograma de residuales (regresi√≥n)
- [ ] i18n ES/EN (mensajes y etiquetas)


## Documentaci√≥n
------------------------
**[Gu√≠a](docs/index.md)** | **[Referencia de API](docs/api.md)** | **[Changelog](CHANGELOG.md)**


## Licencia
------------------------
MIT


## Autor
------------------------
**Ricardo Urdaneta**

**[Linkedin](https://www.linkedin.com/in/ricardourdanetacastro)**

