Metadata-Version: 2.1
Name: tencent_tiinfer
Version: 0.1.5
Summary: Model Serving made Efficient in the Cloud
Home-page: https://git.woa.com/ti-cloud/ti-cloud-ems-infer/ti-cloud-infer-framework.git
Author: luisyjliu
Author-email: Hayescao <hayescao@tencent.com>
License: Apache-2.0
Project-URL: homepage, https://git.woa.com/ti-cloud/ti-cloud-ems-infer/ti-cloud-infer-framework
Project-URL: documentation, https://git.woa.com/ti-cloud/ti-cloud-ems-infer/ti-cloud-infer-framework
Project-URL: repository, https://git.woa.com/ti-cloud/ti-cloud-ems-infer/ti-cloud-infer-framework
Project-URL: changelog, https://git.woa.com/ti-cloud/ti-cloud-ems-infer/ti-cloud-infer-framework
Keywords: machine learning,deep learning,model serving
Classifier: Environment :: GPU
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Rust
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Software Development :: Build Tools
Requires-Python: >=3.6
Description-Content-Type: text/markdown

# 框架环境变量

| 环境变量                        | 说明       | 默认值         |
|-----------------------------|----------|-------------|
| TI_MODEL_DIR                | 模型路径     | /data/model |
| TI_PREPROCESS_NUMS          | 预处理进程数   | 0       |
| TI_INFERENCE_NUMS           | 推理进程数    | 1           |
| TI_POSTPROCESS_NUMS         | 后处理进程数   | 0       |
| TI_INFERENCE_MAX_BATCH_SIZE | 推理Batch数 | 1           |

## 说明

- 当TI_PREPROCESS_NUMS==0且TI_POSTPROCESS_NUMS==0时; 
  
  model_service.py 文件中preprocess，postpress，predict 函数在一个进程中执行

- 否则，model_service.py 文件中preprocess, postpress, predict 函数分别处于不同进程中执行，

  load 函数与predict 函数处于同一进程; 
