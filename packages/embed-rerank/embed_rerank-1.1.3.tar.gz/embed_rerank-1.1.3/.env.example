############################################################
# Example Environment (.env example)
############################################################

# Backend
BACKEND=auto
MODEL_NAME=mlx-community/Qwen3-Embedding-4B-4bit-DWQ
MODEL_PATH=
CROSS_ENCODER_MODEL=

# Model Cache & Storage
# MODEL_PATH: Custom path for MLX models (overrides auto cache detection)
# If empty, uses Hugging Face cache or environment variables below:
# TRANSFORMERS_CACHE: Override HF transformers cache location
# HF_HOME: Hugging Face cache home directory  
# Default cache location: ~/.cache/huggingface/hub/
# 
# Examples:
# MODEL_PATH=/path/to/local/models/Qwen3-Embedding-4B-4bit-DWQ
# TRANSFORMERS_CACHE=/custom/cache/transformers
# HF_HOME=/custom/huggingface

# Server
HOST=0.0.0.0
PORT=9000
RELOAD=false

# Performance
BATCH_SIZE=32
MAX_BATCH_SIZE=128
MAX_TEXTS_PER_REQUEST=100
MAX_PASSAGES_PER_RERANK=1000
MAX_SEQUENCE_LENGTH=512
DEVICE_MEMORY_FRACTION=0.8
REQUEST_TIMEOUT=300

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Security (optional)
# ALLOWED_HOSTS=["example.com","api.example.com"]
# ALLOWED_ORIGINS=["https://example.com","https://app.example.com"]

# Copy to .env and adjust as needed.
