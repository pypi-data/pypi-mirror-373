"""
æ…¢é€Ÿäº¤æ˜“å·¥ä½œæµä¸»ç¨‹åº
æä¾›å‘½ä»¤è¡Œæ¥å£å’ŒHTTP APIæ¥å£
"""

import asyncio
import argparse
import logging
from typing import Dict, Any
from datetime import datetime
import json
import re

try:
    from .controller.slow_trading_controller import create_slow_trading_controller, AnalysisTask
    from .core.agent_executor import create_memecoin_analyst
except ImportError:
    # å½“ç›´æ¥è¿è¡Œæ—¶ä½¿ç”¨ç»å¯¹å¯¼å…¥
    import sys
    import os
    sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
    from controller.slow_trading_controller import create_slow_trading_controller, AnalysisTask
    from core.agent_executor import create_memecoin_analyst

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('slow_trading_agent.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# ============ å›è°ƒå‡½æ•° ============

def on_analysis_complete(task: AnalysisTask):
    """åˆ†æå®Œæˆå›è°ƒ"""
    logger.info(f"ğŸ‰ åˆ†æå®Œæˆ: {task.token_discovery.token_address}")
    
    if task.result and task.result.get('parsed_report'):
        report = task.result['parsed_report']
        if 'multi_dimensional_scores' in report:
            scores = report['multi_dimensional_scores']
            overall_score = scores.get('overall_score', 'N/A')
            logger.info(f"ğŸ“Š æ•´ä½“è¯„åˆ†: {overall_score}")

def on_analysis_failed(task: AnalysisTask):
    """åˆ†æå¤±è´¥å›è°ƒ"""
    logger.error(f"âŒ åˆ†æå¤±è´¥: {task.token_discovery.token_address} - {task.error_message}")

# ============ å‘½ä»¤è¡Œæ¥å£ ============

async def run_single_analysis(token_address: str, context: str = ""):
    """è¿è¡Œå•ä¸ªä»£å¸åˆ†æ"""
    print(f"\nğŸ” å¼€å§‹åˆ†æä»£å¸: {token_address}")
    print("=" * 60)
    
    # åˆ›å»ºAgentå¹¶æ‰§è¡Œåˆ†æ
    agent = create_memecoin_analyst()
    result = agent.analyze_token(token_address, context)
    
    # æ˜¾ç¤ºç»“æœ
    print(f"åˆ†æçŠ¶æ€: {result.get('status', 'unknown')}")
    print(f"åˆ†ææ—¶é—´: {result.get('analysis_time', 'N/A')}")
    print(f"å·¥å…·è°ƒç”¨æ¬¡æ•°: {len(result.get('tool_calls', []))}")
    
    # å°è¯•è§£æå’Œæ˜¾ç¤ºAIåˆ†ææŠ¥å‘Š
    if result.get('parsed_report'):
        report = result['parsed_report']
        print("\n" + "="*60)
        print("ğŸ“‹ AIåˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # æ–°å¢ï¼šä»£å¸åŸºç¡€ä¿¡æ¯æ¦‚è§ˆ
        if 'token_summary' in report:
            summary = report['token_summary']
            print(f"ğŸ“Š ä»£å¸åŸºç¡€ä¿¡æ¯æ¦‚è§ˆ (æ•°æ®æ¥æº: é“¾ä¸ŠAPI)")
            print("-" * 30)
            if 'basic_info' in summary:
                print(f"  åç§°: {summary['basic_info'].get('name', 'N/A')}")
                print(f"  ç¬¦å·: {summary['basic_info'].get('symbol', 'N/A')}")
            if 'market_data' in summary:
                # å¢å¼ºç‰ˆæ•°æ®æ¸…ç†å’Œè½¬æ¢
                def clean_and_convert(value):
                    if isinstance(value, (int, float)):
                        return float(value)
                    if isinstance(value, bool):
                        return 1.0 if value else 0.0
                    if not isinstance(value, str):
                        return 0.0
                    try:
                        # ç§»é™¤ '$', ',', '%' ç­‰éæ•°å­—å­—ç¬¦
                        cleaned_str = re.sub(r'[^\d.]', '', value)
                        return float(cleaned_str) if cleaned_str else 0.0
                    except (ValueError, TypeError):
                        return 0.0

                price_usd = clean_and_convert(summary['market_data'].get('price_usd', 0))
                market_cap = clean_and_convert(summary['market_data'].get('market_cap', 0))
                liquidity_usd = clean_and_convert(summary['market_data'].get('liquidity_usd', 0))

                print(f"  ä»·æ ¼: ${price_usd:.8f}")
                print(f"  å¸‚å€¼: ${market_cap:,.0f}")
                print(f"  æµåŠ¨æ€§: ${liquidity_usd:,.0f}")
            if 'security_assessment' in summary:
                # å¯¹å®‰å…¨è¯„ä¼°ä¸­çš„æ•°æ®ä¹Ÿä½¿ç”¨åŒæ ·çš„æ¸…ç†é€»è¾‘
                is_honeypot = summary['security_assessment'].get('is_honeypot', False)
                buy_tax = clean_and_convert(summary['security_assessment'].get('buy_tax', 0))
                sell_tax = clean_and_convert(summary['security_assessment'].get('sell_tax', 0))
                holder_count = int(clean_and_convert(summary['security_assessment'].get('holder_count', 0)))

                print(f"\nğŸ”’ å®‰å…¨çŠ¶å†µ:")
                print(f"  èœœç½é£é™©: {'æ˜¯' if is_honeypot else 'å¦'}")
                print(f"  ä¹°å…¥ç¨: {buy_tax:.1f}%")
                print(f"  å–å‡ºç¨: {sell_tax:.1f}%")
                print(f"  æŒæœ‰è€…: {holder_count:,}äºº")
            print("-" * 30)
        
        # å™äº‹åˆ†æä¸æ€»ç»“
        if 'narrative_analysis_summary' in report:
            print(f"\nğŸ¯ å™äº‹åˆ†æä¸æ€»ç»“:")
            print(f"{report['narrative_analysis_summary']}")
        
        # å…³é”®è¯è¯†åˆ«ä¸æ ‡ç­¾åˆ†ç±»
        if 'keyword_identification_classification' in report:
            print(f"\nğŸ·ï¸ å…³é”®è¯è¯†åˆ«ä¸æ ‡ç­¾åˆ†ç±»:")
            keywords = report['keyword_identification_classification']
            if isinstance(keywords, dict):
                for category, words in keywords.items():
                    print(f"  {category}: {words}")
            else:
                print(f"{keywords}")
        
        # ä»£å¸å¸‚å€¼åˆ†æ
        if 'market_cap_analysis' in report:
            print(f"\nğŸ“ˆ ä»£å¸å¸‚å€¼åˆ†æ:")
            print(f"{report['market_cap_analysis']}")
        
        # å¤šç»´å™äº‹è¯„åˆ†
        if 'multi_dimensional_narrative_scores' in report:
            print(f"\nâ­ å¤šç»´å™äº‹è¯„åˆ† (100åˆ†åˆ¶):")
            scores = report['multi_dimensional_narrative_scores']
            if isinstance(scores, dict):
                for dimension, score in scores.items():
                    print(f"  {dimension}: {score}åˆ†")
                if 'total_score' in scores:
                    print(f"  æ€»åˆ†: {scores['total_score']}/100")
            else:
                print(f"{scores}")
        
        print("\n" + "="*60)
    
    elif result.get('agent_output'):
        # å¦‚æœæ²¡æœ‰è§£æçš„æŠ¥å‘Šï¼Œæ˜¾ç¤ºåŸå§‹Agentè¾“å‡º
        print("\nğŸ“‹ AgentåŸå§‹è¾“å‡º:")
        print("-" * 60)
        print(result['agent_output'])
        print("-" * 60)
        
        # å°è¯•æ‰‹åŠ¨è§£æJSON
        try:
            output_text = result['agent_output']
            # å¯»æ‰¾å¯èƒ½çš„JSONéƒ¨åˆ†
            json_patterns = [
                (r'```json\s*(.*?)\s*```', 1),  # ```json ... ```
                (r'\{.*\}', 0),  # ä»»ä½•åŒ…å«{}çš„éƒ¨åˆ†
            ]
            
            parsed_json = None
            for pattern, group in json_patterns:
                matches = re.finditer(pattern, output_text, re.DOTALL)
                for match in matches:
                    try:
                        json_text = match.group(group).strip()
                        parsed_json = json.loads(json_text)
                        break
                    except:
                        continue
                if parsed_json:
                    break
            
            if parsed_json:
                print("\nâœ… æˆåŠŸè§£æJSONæŠ¥å‘Š:")
                print(json.dumps(parsed_json, ensure_ascii=False, indent=2))
            else:
                print("\nâŒ æ— æ³•ä»Agentè¾“å‡ºä¸­æå–æœ‰æ•ˆçš„JSONæŠ¥å‘Š")
                
        except Exception as e:
            print(f"\nâŒ JSONè§£æé”™è¯¯: {e}")
    
    else:
        print("\nâŒ æœªè·å¾—æœ‰æ•ˆçš„åˆ†ææŠ¥å‘Š")
        if result.get('error'):
            print(f"é”™è¯¯ä¿¡æ¯: {result['error']}")
        if result.get('parse_error'):
            print(f"è§£æé”™è¯¯: {result['parse_error']}")
    
    # ä¿å­˜å®Œæ•´ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = f"analysis_result_{timestamp}.json"
    
    # æ¸…ç†æ— æ³•åºåˆ—åŒ–çš„å¯¹è±¡
    if 'intermediate_steps' in result:
        result['intermediate_steps'] = [str(step) for step in result['intermediate_steps']]
        
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜è‡³: {result_file}")
    return result

async def run_batch_processing():
    """è¿è¡Œæ‰¹é‡å¤„ç†æ¨¡å¼"""
    print("\nğŸš€ å¯åŠ¨æ…¢é€Ÿäº¤æ˜“å·¥ä½œæµæ‰¹é‡å¤„ç†")
    print("=" * 60)
    
    # åˆ›å»ºæ§åˆ¶å™¨
    controller = create_slow_trading_controller()
    controller.on_analysis_complete = on_analysis_complete
    controller.on_analysis_failed = on_analysis_failed
    
    # æ·»åŠ ä¸€äº›æµ‹è¯•ä»£å¸
    test_tokens = [
        ("0x1234567890abcdef1234567890abcdef12345678", "æµ‹è¯•ä»£å¸1 - çŒ«ä¸»é¢˜Memeå¸", 8),
        ("0xabcdef1234567890abcdef1234567890abcdef12", "æµ‹è¯•ä»£å¸2 - ç¤¾åŒºé©±åŠ¨é¡¹ç›®", 6),
        ("0x567890abcdef1234567890abcdef1234567890ab", "æµ‹è¯•ä»£å¸3 - æ–°å‘å°„ä»£å¸", 7)
    ]
    
    for token_address, context, priority in test_tokens:
        task_id = controller.add_token_for_analysis(
            token_address=token_address,
            source="manual",
            context=context,
            priority=priority
        )
        print(f"âœ… å·²æ·»åŠ ä»»åŠ¡: {task_id}")
    
    # å¯åŠ¨å¤„ç†
    await controller.start_processing()
    
    print("\nğŸ“Š å®æ—¶ç›‘æ§é˜Ÿåˆ—çŠ¶æ€...")
    try:
        while controller.is_running:
            status = controller.get_queue_status()
            print(f"\rå¾…å¤„ç†: {status['pending_count']} | "
                  f"è¿›è¡Œä¸­: {status['active_count']} | "
                  f"å·²å®Œæˆ: {status['completed_count']} | "
                  f"å¤±è´¥: {status['failed_count']}", end="")
            
            # å¦‚æœæ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆäº†ï¼Œé€€å‡º
            if (status['pending_count'] == 0 and 
                status['active_count'] == 0 and
                status['completed_count'] > 0):
                print("\n\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ!")
                break
            
            await asyncio.sleep(2)
    
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢...")
    
    finally:
        await controller.stop_processing()
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        final_status = controller.get_queue_status()
        print(f"\nğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:")
        print(f"  æˆåŠŸå®Œæˆ: {final_status['completed_count']}")
        print(f"  å¤±è´¥ä»»åŠ¡: {final_status['failed_count']}")
        
        # æ˜¾ç¤ºæˆåŠŸä»»åŠ¡çš„ç®€è¦ä¿¡æ¯
        if controller.completed_tasks:
            print(f"\nâœ… æˆåŠŸåˆ†æçš„ä»£å¸:")
            for task in controller.completed_tasks[-5:]:  # æ˜¾ç¤ºæœ€å5ä¸ª
                token_addr = task.token_discovery.token_address
                duration = (task.completed_time - task.started_time).total_seconds()
                print(f"  {token_addr[-10:]}... (è€—æ—¶: {duration:.1f}s)")

async def run_interactive_mode():
    """è¿è¡Œäº¤äº’æ¨¡å¼"""
    print("\nğŸ® è¿›å…¥äº¤äº’æ¨¡å¼")
    print("è¾“å…¥ä»£å¸åœ°å€è¿›è¡Œåˆ†æï¼Œè¾“å…¥ 'quit' é€€å‡º")
    print("=" * 60)
    
    while True:
        try:
            token_input = input("\nä»£å¸åœ°å€: ").strip()
            
            if token_input.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ é€€å‡ºäº¤äº’æ¨¡å¼")
                break
            
            if not token_input:
                continue
            
            # ç®€å•éªŒè¯åœ°å€æ ¼å¼
            if not token_input.startswith('0x') or len(token_input) != 42:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„BSCä»£å¸åœ°å€ (0xå¼€å¤´ï¼Œ42å­—ç¬¦)")
                continue
            
            context = input("é¢å¤–ä¿¡æ¯ (å¯é€‰): ").strip()
            
            await run_single_analysis(token_input, context)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ é€€å‡ºäº¤äº’æ¨¡å¼")
            break
        except Exception as e:
            print(f"âŒ åˆ†æå‡ºé”™: {e}")

# ============ ä¸»ç¨‹åºå…¥å£ ============

async def main():
    """ä¸»ç¨‹åºå…¥å£"""
    parser = argparse.ArgumentParser(description="æ…¢é€Ÿäº¤æ˜“å·¥ä½œæµ - Memecoinæ™ºèƒ½åˆ†æç³»ç»Ÿ")
    parser.add_argument("--mode", choices=["single", "batch", "interactive"], 
                       default="interactive", help="è¿è¡Œæ¨¡å¼")
    parser.add_argument("--token", type=str, help="ä»£å¸åœ°å€ (singleæ¨¡å¼)")
    parser.add_argument("--context", type=str, default="", help="é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯")
    
    args = parser.parse_args()
    
    print("ğŸ¤– æ…¢é€Ÿäº¤æ˜“å·¥ä½œæµ - Memecoinæ™ºèƒ½åˆ†æç³»ç»Ÿ")
    print("åŸºäºLangChain + ReActæ¶æ„")
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")
    
    try:
        if args.mode == "single":
            if not args.token:
                print("âŒ singleæ¨¡å¼éœ€è¦æä¾› --token å‚æ•°")
                return
            await run_single_analysis(args.token, args.context)
            
        elif args.mode == "batch":
            await run_batch_processing()
            
        elif args.mode == "interactive":
            await run_interactive_mode()
    
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸: {e}")
        print(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")

if __name__ == "__main__":
    asyncio.run(main())
