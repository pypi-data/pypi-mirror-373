"""
å™äº‹è¯„åˆ†å·¥å…·æ¨¡å—
ä¸“é—¨è´Ÿè´£å¯¹ä»£å¸è¿›è¡Œå¤šç»´åº¦å™äº‹è´¨é‡è¯„åˆ†ï¼ˆ100åˆ†åˆ¶ï¼‰
"""

from langchain.tools import BaseTool
from typing import Type, Dict, Any, List, Optional
from pydantic import BaseModel, Field
import re
import logging

logger = logging.getLogger(__name__)

# ============ è¾“å…¥æ¨¡å¼å®šä¹‰ ============

class NarrativeScoringInput(BaseModel):
    token_name: Optional[str] = Field(default=None, description="ä»£å¸åç§°")
    token_symbol: Optional[str] = Field(default=None, description="ä»£å¸ç¬¦å·")
    token_description: Optional[str] = Field(default="", description="ä»£å¸æè¿°æˆ–é¡¹ç›®ä»‹ç»")
    community_info: Optional[Dict[str, Any]] = Field(default_factory=dict, description="ç¤¾åŒºä¿¡æ¯")
    market_data: Optional[Dict[str, Any]] = Field(default_factory=dict, description="å¸‚åœºæ•°æ®")

class KeywordAnalysisInput(BaseModel):
    token_name: Optional[str] = Field(default=None, description="ä»£å¸åç§°")
    token_symbol: Optional[str] = Field(default=None, description="ä»£å¸ç¬¦å·")
    project_description: Optional[str] = Field(default="", description="é¡¹ç›®æè¿°")
    social_mentions: Optional[List[str]] = Field(default_factory=list, description="ç¤¾äº¤åª’ä½“æåŠå†…å®¹")

# ============ å¤šç»´å™äº‹è¯„åˆ†å·¥å…· ============

class MultiDimensionalNarrativeScoringTool(BaseTool):
    """å¤šç»´å™äº‹è¯„åˆ†å·¥å…· - 100åˆ†åˆ¶è¯„åˆ†ç³»ç»Ÿ"""
    name: str = "multi_dimensional_narrative_scoring"
    description: str = """
    å¯¹ä»£å¸è¿›è¡Œå¤šç»´åº¦å™äº‹è´¨é‡è¯„åˆ†ï¼Œé‡‡ç”¨100åˆ†åˆ¶ï¼š
    1. å™äº‹å®Œæ•´æ€§ (0-20åˆ†) - æ•…äº‹çš„å®Œæ•´æ€§å’Œé€»è¾‘æ€§
    2. ä¼ æ’­å¯èƒ½æ€§ (0-20åˆ†) - åœ¨ç¤¾äº¤åª’ä½“ä¼ æ’­çš„æ½œåŠ›
    3. åˆ›æ„è¡¨ç° (0-20åˆ†) - åˆ›æ–°æ€§å’Œç‹¬ç‰¹æ€§
    4. ç†è§£å‹å¥½åº¦ (0-20åˆ†) - æ™®é€šç”¨æˆ·çš„ç†è§£éš¾åº¦
    5. å¯ä¿¡åº¦ (0-20åˆ†) - é¡¹ç›®çš„å¯é æ€§å’ŒçœŸå®æ€§
    æ€»åˆ†100åˆ†ï¼Œæä¾›è¯¦ç»†çš„è¯„åˆ†è¯´æ˜å’Œæ”¹è¿›å»ºè®®ã€‚
    """
    args_schema: Type[BaseModel] = NarrativeScoringInput
    
    def _run(
        self, 
        token_name: Optional[str] = None, 
        token_symbol: Optional[str] = None, 
        token_description: Optional[str] = "", 
        community_info: Optional[Dict[str, Any]] = None, 
        market_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        
        import json
        final_args = {}
        # éå†æ‰€æœ‰å¯èƒ½çš„è¾“å…¥å‚æ•°ï¼Œå°è¯•è§£æJSON
        all_inputs = [token_name, token_symbol, token_description, community_info, market_data]
        
        for item in all_inputs:
            if isinstance(item, str) and item.startswith('{'):
                try:
                    data = json.loads(item)
                    final_args.update(data)
                except (json.JSONDecodeError, TypeError):
                    pass

        # ä½¿ç”¨åŸå§‹å‚æ•°å¡«å……å°šæœªè§£æçš„å­—æ®µ
        if token_name and 'token_name' not in final_args: final_args['token_name'] = token_name
        if token_symbol and 'token_symbol' not in final_args: final_args['token_symbol'] = token_symbol
        if token_description and 'token_description' not in final_args: final_args['token_description'] = token_description
        if community_info and 'community_info' not in final_args: final_args['community_info'] = community_info
        if market_data and 'market_data' not in final_args: final_args['market_data'] = market_data
            
        # åœ¨å·¥å…·å†…éƒ¨è¿›è¡Œä¸¥æ ¼éªŒè¯
        if 'token_name' not in final_args or 'token_symbol' not in final_args:
            error_msg = f"MultiDimensionalNarrativeScoringToolç¼ºå°‘å¿…éœ€å‚æ•°ã€‚æ”¶åˆ°: name='{token_name}', symbol='{token_symbol}'"
            logger.error(error_msg)
            return {"error": error_msg}

        # ä½¿ç”¨éªŒè¯å’Œæ¸…ç†åçš„å‚æ•°
        valid_name = final_args['token_name']
        valid_symbol = final_args['token_symbol']
        valid_description = final_args.get('token_description', "")
        valid_community_info = final_args.get('community_info') or {}
        valid_market_data = final_args.get('market_data') or {}
        
        logger.info(f"è¿›è¡Œå¤šç»´å™äº‹è¯„åˆ†: {valid_name} ({valid_symbol})")

        # 1. å™äº‹å®Œæ•´æ€§è¯„åˆ† (0-20åˆ†)
        narrative_completeness = self._evaluate_narrative_completeness(valid_name, valid_symbol, valid_description, valid_community_info)
        
        # 2. ä¼ æ’­å¯èƒ½æ€§è¯„åˆ† (0-20åˆ†)
        viral_potential = self._evaluate_viral_potential(valid_name, valid_symbol, valid_description, valid_market_data)
        
        # 3. åˆ›æ„è¡¨ç°è¯„åˆ† (0-20åˆ†)
        creative_expression = self._evaluate_creative_expression(valid_name, valid_symbol, valid_description)
        
        # 4. ç†è§£å‹å¥½åº¦è¯„åˆ† (0-20åˆ†)
        accessibility = self._evaluate_accessibility(valid_name, valid_symbol, valid_description)
        
        # 5. å¯ä¿¡åº¦è¯„åˆ† (0-20åˆ†)
        credibility = self._evaluate_credibility(valid_name, valid_symbol, valid_community_info, valid_market_data)
        
        # è®¡ç®—æ€»åˆ†
        total_score = (
            narrative_completeness["score"] + 
            viral_potential["score"] + 
            creative_expression["score"] + 
            accessibility["score"] + 
            credibility["score"]
        )
        
        # ç”Ÿæˆè¯„åˆ†ç­‰çº§
        score_grade = self._get_score_grade(total_score)
        
        return {
            "narrative_completeness": narrative_completeness,
            "viral_potential": viral_potential,
            "creative_expression": creative_expression,
            "accessibility": accessibility,
            "credibility": credibility,
            "total_narrative_score": total_score,
            "score_grade": score_grade,
            "score_breakdown": self._generate_score_breakdown(
                narrative_completeness, viral_potential, creative_expression, 
                accessibility, credibility, total_score
            ),
            "improvement_suggestions": self._generate_improvement_suggestions(
                narrative_completeness, viral_potential, creative_expression, 
                accessibility, credibility
            )
        }
    
    def _evaluate_narrative_completeness(self, name: str, symbol: str, description: str, 
                                       community_info: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°å™äº‹å®Œæ•´æ€§ (0-20åˆ†)"""
        score = 0
        evaluation_points = []
        
        # åŸºç¡€æ•…äº‹å®Œæ•´æ€§ (0-8åˆ†) - ä¹è§‚ç‰ˆæœ¬
        if description and len(description) > 50:
            if len(description) > 200:
                score += 8
                evaluation_points.append("âœ… é¡¹ç›®æè¿°è¯¦ç»†å®Œæ•´")
            elif len(description) > 100:
                score += 6
                evaluation_points.append("âœ… é¡¹ç›®æè¿°è¾ƒä¸ºå®Œæ•´")
            else:
                score += 4
                evaluation_points.append("âœ… é¡¹ç›®æè¿°ç®€æ´æœ‰åŠ›")
        elif description and len(description) > 10:
            score += 3
            evaluation_points.append("âœ… æœ‰åŸºç¡€é¡¹ç›®æè¿°")
        else:
            score += 1  # å³ä½¿æ²¡æœ‰æè¿°ä¹Ÿç»™1åˆ†åŸºç¡€åˆ†
            evaluation_points.append("âš ï¸ é¡¹ç›®æè¿°å¾…å®Œå–„")
        
        # åç§°ä¸ç¬¦å·ä¸€è‡´æ€§ (0-4åˆ†)
        if self._check_name_symbol_consistency(name, symbol):
            score += 4
            evaluation_points.append("âœ… åç§°ä¸ç¬¦å·é«˜åº¦ä¸€è‡´")
        elif self._check_name_symbol_relevance(name, symbol):
            score += 2
            evaluation_points.append("âœ… åç§°ä¸ç¬¦å·ç›¸å…³")
        else:
            evaluation_points.append("âš ï¸ åç§°ä¸ç¬¦å·å…³è”æ€§è¾ƒå¼±")
        
        # ä¸»é¢˜è¿è´¯æ€§ (0-4åˆ†)
        theme_score = self._analyze_theme_coherence(name, symbol, description)
        score += theme_score
        if theme_score >= 3:
            evaluation_points.append("âœ… ä¸»é¢˜è¿è´¯æ€§å¼º")
        elif theme_score >= 2:
            evaluation_points.append("âœ… ä¸»é¢˜è¿è´¯æ€§ä¸€èˆ¬")
        else:
            evaluation_points.append("âš ï¸ ä¸»é¢˜è¿è´¯æ€§æœ‰å¾…æå‡")
        
        # ç¤¾åŒºå‚ä¸åº¦ (0-4åˆ†)
        community_score = self._evaluate_community_engagement(community_info)
        score += community_score
        if community_score >= 3:
            evaluation_points.append("âœ… ç¤¾åŒºå‚ä¸åº¦é«˜")
        elif community_score >= 2:
            evaluation_points.append("âœ… ç¤¾åŒºå‚ä¸åº¦ä¸­ç­‰")
        else:
            evaluation_points.append("âš ï¸ ç¤¾åŒºå‚ä¸åº¦è¾ƒä½")
        
        return {
            "score": min(score, 20),
            "evaluation": " | ".join(evaluation_points),
            "details": {
                "story_completeness": min(score // 4 * 4, 8),
                "name_consistency": min((score % 20) // 4 * 4, 4),
                "theme_coherence": theme_score,
                "community_engagement": community_score
            }
        }
    
    def _evaluate_viral_potential(self, name: str, symbol: str, description: str, 
                                market_data: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°ä¼ æ’­å¯èƒ½æ€§ (0-20åˆ†)"""
        score = 0
        evaluation_points = []
        
        # è®°å¿†æ€§å’Œæœ—æœ—ä¸Šå£ (0-6åˆ†)
        if self._is_memorable_name(name):
            score += 4
            evaluation_points.append("âœ… åç§°æ˜“è®°å¿†")
        if self._is_catchy_symbol(symbol):
            score += 2
            evaluation_points.append("âœ… ç¬¦å·æœ—æœ—ä¸Šå£")
        
        # æƒ…æ„Ÿå…±é¸£ (0-6åˆ†)
        emotional_score = self._analyze_emotional_appeal(name, symbol, description)
        score += emotional_score
        if emotional_score >= 4:
            evaluation_points.append("âœ… æƒ…æ„Ÿå…±é¸£å¼º")
        elif emotional_score >= 2:
            evaluation_points.append("âœ… æœ‰ä¸€å®šæƒ…æ„Ÿå…±é¸£")
        else:
            evaluation_points.append("âš ï¸ æƒ…æ„Ÿå…±é¸£è¾ƒå¼±")
        
        # è¶‹åŠ¿å…³è”æ€§ (0-4åˆ†)
        trend_score = self._analyze_trend_relevance(name, symbol, description)
        score += trend_score
        if trend_score >= 3:
            evaluation_points.append("âœ… é«˜åº¦å…³è”å½“å‰è¶‹åŠ¿")
        elif trend_score >= 2:
            evaluation_points.append("âœ… å…³è”éƒ¨åˆ†è¶‹åŠ¿")
        else:
            evaluation_points.append("âš ï¸ è¶‹åŠ¿å…³è”æ€§è¾ƒä½")
        
        # ç¤¾äº¤åª’ä½“é€‚åº”æ€§ (0-4åˆ†)
        social_score = self._evaluate_social_media_fitness(name, symbol)
        score += social_score
        if social_score >= 3:
            evaluation_points.append("âœ… éå¸¸é€‚åˆç¤¾äº¤åª’ä½“ä¼ æ’­")
        elif social_score >= 2:
            evaluation_points.append("âœ… é€‚åˆç¤¾äº¤åª’ä½“ä¼ æ’­")
        else:
            evaluation_points.append("âš ï¸ ç¤¾äº¤ä¼ æ’­é€‚åº”æ€§ä¸€èˆ¬")
        
        return {
            "score": min(score, 20),
            "evaluation": " | ".join(evaluation_points),
            "viral_factors": {
                "memorability": min(score // 4, 6),
                "emotional_appeal": emotional_score,
                "trend_relevance": trend_score,
                "social_fitness": social_score
            }
        }
    
    def _evaluate_creative_expression(self, name: str, symbol: str, description: str) -> Dict[str, Any]:
        """è¯„ä¼°åˆ›æ„è¡¨ç° (0-20åˆ†)"""
        score = 0
        evaluation_points = []
        
        # åŸåˆ›æ€§ (0-8åˆ†)
        originality_score = self._analyze_originality(name, symbol)
        score += originality_score
        if originality_score >= 6:
            evaluation_points.append("âœ… é«˜åº¦åŸåˆ›")
        elif originality_score >= 4:
            evaluation_points.append("âœ… æœ‰ä¸€å®šåŸåˆ›æ€§")
        else:
            evaluation_points.append("âš ï¸ åŸåˆ›æ€§ä¸è¶³")
        
        # åˆ›æ–°æ¦‚å¿µ (0-6åˆ†)
        innovation_score = self._analyze_innovation(name, symbol, description)
        score += innovation_score
        if innovation_score >= 4:
            evaluation_points.append("âœ… æ¦‚å¿µåˆ›æ–°")
        elif innovation_score >= 2:
            evaluation_points.append("âœ… æœ‰åˆ›æ–°å…ƒç´ ")
        else:
            evaluation_points.append("âš ï¸ ç¼ºä¹åˆ›æ–°")
        
        # è§†è§‰æƒ³è±¡åŠ› (0-6åˆ†)
        visual_score = self._analyze_visual_appeal(name, symbol, description)
        score += visual_score
        if visual_score >= 4:
            evaluation_points.append("âœ… è§†è§‰æƒ³è±¡åŠ›ä¸°å¯Œ")
        elif visual_score >= 2:
            evaluation_points.append("âœ… æœ‰è§†è§‰å¸å¼•åŠ›")
        else:
            evaluation_points.append("âš ï¸ è§†è§‰è¡¨ç°åŠ›ä¸€èˆ¬")
        
        return {
            "score": min(score, 20),
            "evaluation": " | ".join(evaluation_points),
            "creative_aspects": {
                "originality": originality_score,
                "innovation": innovation_score,
                "visual_appeal": visual_score
            }
        }
    
    def _evaluate_accessibility(self, name: str, symbol: str, description: str) -> Dict[str, Any]:
        """è¯„ä¼°ç†è§£å‹å¥½åº¦ (0-20åˆ†)"""
        score = 0
        evaluation_points = []
        
        # åç§°ç®€å•æ€§ (0-6åˆ†)
        if len(name) <= 6:
            score += 4
            evaluation_points.append("âœ… åç§°ç®€çŸ­æ˜“è®°")
        elif len(name) <= 10:
            score += 2
            evaluation_points.append("âœ… åç§°é•¿åº¦é€‚ä¸­")
        else:
            evaluation_points.append("âš ï¸ åç§°è¾ƒé•¿")
        
        if self._is_pronounceable(name):
            score += 2
            evaluation_points.append("âœ… å‘éŸ³ç®€å•")
        
        # ç¬¦å·æ¸…æ™°æ€§ (0-6åˆ†)
        if len(symbol) <= 5:
            score += 3
            evaluation_points.append("âœ… ç¬¦å·ç®€æ´")
        elif len(symbol) <= 8:
            score += 2
            evaluation_points.append("âœ… ç¬¦å·é•¿åº¦é€‚ä¸­")
        else:
            evaluation_points.append("âš ï¸ ç¬¦å·è¾ƒé•¿")
        
        if symbol.isalpha():
            score += 3
            evaluation_points.append("âœ… ç¬¦å·çº¯å­—æ¯ï¼Œæ˜“ç†è§£")
        elif symbol.isalnum():
            score += 2
            evaluation_points.append("âœ… ç¬¦å·å­—æ¯æ•°å­—æ··åˆ")
        
        # æ¦‚å¿µç›´è§‚æ€§ (0-8åˆ†)
        concept_score = self._analyze_concept_clarity(name, symbol, description)
        score += concept_score
        if concept_score >= 6:
            evaluation_points.append("âœ… æ¦‚å¿µç›´è§‚æ˜“æ‡‚")
        elif concept_score >= 4:
            evaluation_points.append("âœ… æ¦‚å¿µè¾ƒä¸ºæ¸…æ™°")
        else:
            evaluation_points.append("âš ï¸ æ¦‚å¿µç†è§£éœ€è¦è§£é‡Š")
        
        return {
            "score": min(score, 20),
            "evaluation": " | ".join(evaluation_points),
            "accessibility_factors": {
                "name_simplicity": min(6, score // 3),
                "symbol_clarity": min(6, (score % 18) // 3),
                "concept_clarity": concept_score
            }
        }
    
    def _evaluate_credibility(self, name: str, symbol: str, community_info: Dict[str, Any], 
                            market_data: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°å¯ä¿¡åº¦ (0-20åˆ†)"""
        score = 0
        evaluation_points = []
        
        # ä¸“ä¸šæ€§ (0-6åˆ†)
        if self._appears_professional(name, symbol):
            score += 4
            evaluation_points.append("âœ… åç§°ä¸“ä¸š")
        if not self._has_scam_indicators(name, symbol):
            score += 2
            evaluation_points.append("âœ… æ— æ˜æ˜¾è¯ˆéª—ç‰¹å¾")
        
        # æŠ€æœ¯å¯ä¿¡åº¦ (0-6åˆ†)
        if market_data.get('contract_verified', False):
            score += 3
            evaluation_points.append("âœ… åˆçº¦å·²éªŒè¯")
        if market_data.get('liquidity_usd', 0) > 50000:
            score += 2
            evaluation_points.append("âœ… æµåŠ¨æ€§å……è¶³")
        if market_data.get('holder_count', 0) > 1000:
            score += 1
            evaluation_points.append("âœ… æŒæœ‰è€…åŸºæ•°è‰¯å¥½")
        
        # ç¤¾åŒºå¯ä¿¡åº¦ (0-8åˆ†)
        community_score = self._evaluate_community_credibility(community_info)
        score += community_score
        if community_score >= 6:
            evaluation_points.append("âœ… ç¤¾åŒºå¯ä¿¡åº¦é«˜")
        elif community_score >= 4:
            evaluation_points.append("âœ… ç¤¾åŒºå¯ä¿¡åº¦ä¸­ç­‰")
        else:
            evaluation_points.append("âš ï¸ ç¤¾åŒºå¯ä¿¡åº¦æœ‰å¾…æå‡")
        
        return {
            "score": min(score, 20),
            "evaluation": " | ".join(evaluation_points),
            "credibility_factors": {
                "professionalism": min(6, score // 3),
                "technical_credibility": min(6, (score % 18) // 3),
                "community_credibility": community_score
            }
        }
    
    # ============ è¾…åŠ©è¯„ä¼°æ–¹æ³• ============
    
    def _check_name_symbol_consistency(self, name: str, symbol: str) -> bool:
        """æ£€æŸ¥åç§°ä¸ç¬¦å·çš„ä¸€è‡´æ€§"""
        if not name or not symbol:
            return False
        
        # é¦–å­—æ¯ä¸€è‡´æ€§
        if name[0].upper() == symbol[0].upper():
            return True
        
        # ç¼©å†™ä¸€è‡´æ€§
        name_words = re.findall(r'\b\w', name.upper())
        if ''.join(name_words) == symbol.upper():
            return True
        
        return False
    
    def _check_name_symbol_relevance(self, name: str, symbol: str) -> bool:
        """æ£€æŸ¥åç§°ä¸ç¬¦å·çš„ç›¸å…³æ€§"""
        if not name or not symbol:
            return False
        
        # åŒ…å«å…³ç³»
        if symbol.upper() in name.upper() or name.upper() in symbol.upper():
            return True
        
        # éƒ¨åˆ†åŒ¹é…
        name_clean = re.sub(r'[^a-zA-Z]', '', name.upper())
        symbol_clean = re.sub(r'[^a-zA-Z]', '', symbol.upper())
        
        if len(set(name_clean) & set(symbol_clean)) >= 2:
            return True
        
        return False
    
    def _analyze_theme_coherence(self, name: str, symbol: str, description: str) -> int:
        """åˆ†æä¸»é¢˜è¿è´¯æ€§ (0-4åˆ†)"""
        score = 0
        
        # åŠ¨ç‰©ä¸»é¢˜
        animal_keywords = ['cat', 'dog', 'frog', 'bird', 'lion', 'tiger', 'bear', 'wolf']
        if any(keyword in name.lower() for keyword in animal_keywords):
            if any(keyword in description.lower() for keyword in animal_keywords):
                score += 2
            else:
                score += 1
        
        # æŠ€æœ¯ä¸»é¢˜
        tech_keywords = ['ai', 'blockchain', 'defi', 'nft', 'web3', 'crypto']
        if any(keyword in name.lower() for keyword in tech_keywords):
            if any(keyword in description.lower() for keyword in tech_keywords):
                score += 2
            else:
                score += 1
        
        # Memeä¸»é¢˜
        meme_keywords = ['moon', 'rocket', 'diamond', 'hodl', 'safe', 'baby']
        if any(keyword in name.lower() for keyword in meme_keywords):
            if any(keyword in description.lower() for keyword in meme_keywords):
                score += 2
            else:
                score += 1
        
        return min(score, 4)
    
    def _evaluate_community_engagement(self, community_info: Dict[str, Any]) -> int:
        """è¯„ä¼°ç¤¾åŒºå‚ä¸åº¦ (0-4åˆ†)"""
        score = 0
        
        telegram_members = community_info.get('telegram_members', 0)
        twitter_followers = community_info.get('twitter_followers', 0)
        discord_members = community_info.get('discord_members', 0)
        
        total_community = telegram_members + twitter_followers + discord_members
        
        if total_community > 10000:
            score += 4
        elif total_community > 5000:
            score += 3
        elif total_community > 1000:
            score += 2
        elif total_community > 100:
            score += 1
        
        return score
    
    def _is_memorable_name(self, name: str) -> bool:
        """åˆ¤æ–­åç§°æ˜¯å¦æ˜“è®°å¿†"""
        if not name:
            return False
        
        # çŸ­åç§°æ›´æ˜“è®°å¿†
        if len(name) <= 6:
            return True
        
        # é‡å¤éŸ³èŠ‚
        if len(set(name.lower())) < len(name) * 0.7:
            return True
        
        # å¸¸è§å•è¯ç»„åˆ
        common_words = ['cat', 'dog', 'moon', 'safe', 'baby', 'king', 'lord']
        if any(word in name.lower() for word in common_words):
            return True
        
        return False
    
    def _is_catchy_symbol(self, symbol: str) -> bool:
        """åˆ¤æ–­ç¬¦å·æ˜¯å¦æœ—æœ—ä¸Šå£"""
        if not symbol:
            return False
        
        # çŸ­ç¬¦å·
        if len(symbol) <= 4:
            return True
        
        # é‡å¤å­—æ¯
        if len(set(symbol.upper())) < len(symbol) * 0.8:
            return True
        
        return False
    
    def _analyze_emotional_appeal(self, name: str, symbol: str, description: str) -> int:
        """åˆ†ææƒ…æ„Ÿå…±é¸£ (0-6åˆ†)"""
        score = 0
        text = f"{name} {symbol} {description}".lower()
        
        # ç§¯ææƒ…æ„Ÿè¯æ±‡
        positive_keywords = ['love', 'heart', 'happy', 'joy', 'cute', 'sweet', 'precious']
        score += min(2, sum(1 for keyword in positive_keywords if keyword in text))
        
        # åŠ›é‡æ„Ÿè¯æ±‡
        power_keywords = ['strong', 'power', 'king', 'lord', 'master', 'boss', 'alpha']
        score += min(2, sum(1 for keyword in power_keywords if keyword in text))
        
        # ç¤¾åŒºæƒ…æ„Ÿè¯æ±‡
        community_keywords = ['together', 'family', 'community', 'united', 'team']
        score += min(2, sum(1 for keyword in community_keywords if keyword in text))
        
        return min(score, 6)
    
    def _analyze_trend_relevance(self, name: str, symbol: str, description: str) -> int:
        """åˆ†æè¶‹åŠ¿å…³è”æ€§ (0-4åˆ†)"""
        score = 0
        text = f"{name} {symbol} {description}".lower()
        
        # å½“å‰åŠ å¯†è¶‹åŠ¿
        crypto_trends = ['ai', 'gamefi', 'metaverse', 'nft', 'defi', 'web3']
        score += min(2, sum(1 for trend in crypto_trends if trend in text))
        
        # ç¤¾äº¤è¶‹åŠ¿
        social_trends = ['viral', 'meme', 'trending', 'hot']
        score += min(2, sum(1 for trend in social_trends if trend in text))
        
        return min(score, 4)
    
    def _evaluate_social_media_fitness(self, name: str, symbol: str) -> int:
        """è¯„ä¼°ç¤¾äº¤åª’ä½“é€‚åº”æ€§ (0-4åˆ†)"""
        score = 0
        
        # æ ‡ç­¾å‹å¥½æ€§
        if re.match(r'^[a-zA-Z]+$', symbol):
            score += 2
        
        # æ˜“æœç´¢æ€§
        if len(name) >= 3 and len(name) <= 15:
            score += 1
        
        # æ˜“åˆ†äº«æ€§
        if ' ' not in name or len(name.split()) <= 2:
            score += 1
        
        return min(score, 4)
    
    def _analyze_originality(self, name: str, symbol: str) -> int:
        """åˆ†æåŸåˆ›æ€§ (0-8åˆ†)"""
        score = 8  # ä»æ»¡åˆ†å¼€å§‹æ‰£åˆ†
        
        # å¸¸è§æ¨¡å¼æ‰£åˆ†
        common_patterns = ['safe', 'baby', 'mini', 'max', 'super', 'mega', 'ultra']
        for pattern in common_patterns:
            if pattern in name.lower():
                score -= 2
                break
        
        # æ•°å­—åç¼€æ‰£åˆ†
        if re.search(r'\d+$', name):
            score -= 2
        
        # è¿‡äºç®€å•æ‰£åˆ†
        if len(name) <= 3:
            score -= 2
        
        return max(0, score)
    
    def _analyze_innovation(self, name: str, symbol: str, description: str) -> int:
        """åˆ†æåˆ›æ–°æ¦‚å¿µ (0-6åˆ†)"""
        score = 0
        text = f"{name} {symbol} {description}".lower()
        
        # æ–°æ¦‚å¿µå…³é”®è¯
        innovation_keywords = ['revolutionary', 'innovative', 'breakthrough', 'unique', 'first']
        score += min(3, sum(1 for keyword in innovation_keywords if keyword in text))
        
        # æŠ€æœ¯åˆ›æ–°
        tech_innovation = ['algorithm', 'protocol', 'mechanism', 'system']
        score += min(3, sum(1 for keyword in tech_innovation if keyword in text))
        
        return min(score, 6)
    
    def _analyze_visual_appeal(self, name: str, symbol: str, description: str) -> int:
        """åˆ†æè§†è§‰å¸å¼•åŠ› (0-6åˆ†)"""
        score = 0
        
        # è§†è§‰ç›¸å…³è¯æ±‡
        visual_keywords = ['color', 'bright', 'shiny', 'golden', 'diamond', 'crystal']
        text = f"{name} {symbol} {description}".lower()
        score += min(3, sum(1 for keyword in visual_keywords if keyword in text))
        
        # å½¢è±¡åŒ–åç§°
        if any(char in name.lower() for char in ['cat', 'dog', 'moon', 'star', 'sun']):
            score += 2
        
        # ç¬¦å·ç¾è§‚æ€§
        if len(symbol) <= 5 and symbol.isalpha():
            score += 1
        
        return min(score, 6)
    
    def _analyze_concept_clarity(self, name: str, symbol: str, description: str) -> int:
        """åˆ†ææ¦‚å¿µæ¸…æ™°åº¦ (0-8åˆ†)"""
        score = 0
        
        # ç›´è§‚å‘½å
        intuitive_words = ['coin', 'token', 'cash', 'pay', 'finance', 'money']
        if any(word in name.lower() for word in intuitive_words):
            score += 3
        
        # è¡Œä¸šæ¸…æ™°æ€§
        if any(word in name.lower() for word in ['defi', 'nft', 'game', 'social']):
            score += 2
        
        # æè¿°æ¸…æ™°æ€§
        if description and len(description) > 50:
            if any(word in description.lower() for word in ['purpose', 'goal', 'aim', 'objective']):
                score += 3
        
        return min(score, 8)
    
    def _is_pronounceable(self, name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜“å‘éŸ³"""
        if not name:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿‡å¤šè¿ç»­è¾…éŸ³
        consonants = 'bcdfghjklmnpqrstvwxyz'
        consecutive_consonants = 0
        max_consecutive = 0
        
        for char in name.lower():
            if char in consonants:
                consecutive_consonants += 1
                max_consecutive = max(max_consecutive, consecutive_consonants)
            else:
                consecutive_consonants = 0
        
        return max_consecutive <= 3
    
    def _appears_professional(self, name: str, symbol: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¾å¾—ä¸“ä¸š"""
        if not name or not symbol:
            return False
        
        # é¿å…å„¿ç«¥åŒ–è¯æ±‡
        childish_words = ['baby', 'cute', 'little', 'tiny', 'mini']
        if any(word in name.lower() for word in childish_words):
            return False
        
        # é¿å…è¿‡åº¦å¤¸å¼ 
        exaggerated_words = ['super', 'mega', 'ultra', 'extreme', 'maximum']
        if any(word in name.lower() for word in exaggerated_words):
            return False
        
        return True
    
    def _has_scam_indicators(self, name: str, symbol: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰è¯ˆéª—æŒ‡æ ‡"""
        scam_keywords = ['safe', 'moon', 'get rich', 'easy money', 'guaranteed']
        text = f"{name} {symbol}".lower()
        
        return any(keyword in text for keyword in scam_keywords)
    
    def _evaluate_community_credibility(self, community_info: Dict[str, Any]) -> int:
        """è¯„ä¼°ç¤¾åŒºå¯ä¿¡åº¦ (0-8åˆ†)"""
        score = 0
        
        # å®˜æ–¹æ¸ é“å®Œæ•´æ€§
        if community_info.get('official_website'):
            score += 2
        if community_info.get('twitter_verified'):
            score += 2
        if community_info.get('telegram_active'):
            score += 2
        
        # å›¢é˜Ÿé€æ˜åº¦
        if community_info.get('team_doxxed'):
            score += 2
        
        return min(score, 8)
    
    def _get_score_grade(self, total_score: int) -> str:
        """è·å–è¯„åˆ†ç­‰çº§"""
        if total_score >= 90:
            return "A+ (ä¼˜ç§€)"
        elif total_score >= 80:
            return "A (è‰¯å¥½)"
        elif total_score >= 70:
            return "B (ä¸­ç­‰åä¸Š)"
        elif total_score >= 60:
            return "C (ä¸­ç­‰)"
        elif total_score >= 50:
            return "D (ä¸­ç­‰åä¸‹)"
        else:
            return "F (éœ€è¦æ”¹è¿›)"
    
    def _generate_score_breakdown(self, narrative_completeness: Dict, viral_potential: Dict,
                                creative_expression: Dict, accessibility: Dict, 
                                credibility: Dict, total_score: int) -> str:
        """ç”Ÿæˆè¯„åˆ†è¯¦ç»†è¯´æ˜"""
        return f"""
æ€»åˆ† {total_score}/100 åˆ†è¯„åˆ†æ„æˆï¼š

ğŸ“– å™äº‹å®Œæ•´æ€§: {narrative_completeness['score']}/20 åˆ†
{narrative_completeness['evaluation']}

ğŸš€ ä¼ æ’­å¯èƒ½æ€§: {viral_potential['score']}/20 åˆ†
{viral_potential['evaluation']}

ğŸ¨ åˆ›æ„è¡¨ç°: {creative_expression['score']}/20 åˆ†
{creative_expression['evaluation']}

ğŸ”¤ ç†è§£å‹å¥½åº¦: {accessibility['score']}/20 åˆ†
{accessibility['evaluation']}

ğŸ›¡ï¸ å¯ä¿¡åº¦: {credibility['score']}/20 åˆ†
{credibility['evaluation']}

ç»¼åˆè¯„çº§: {self._get_score_grade(total_score)}
        """.strip()
    
    def _generate_improvement_suggestions(self, narrative_completeness: Dict, viral_potential: Dict,
                                        creative_expression: Dict, accessibility: Dict, 
                                        credibility: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []
        
        if narrative_completeness['score'] < 15:
            suggestions.append("å»ºè®®å®Œå–„é¡¹ç›®æè¿°ï¼Œå¢å¼ºæ•…äº‹çš„å®Œæ•´æ€§å’Œé€»è¾‘æ€§")
        
        if viral_potential['score'] < 15:
            suggestions.append("å»ºè®®ä¼˜åŒ–åç§°å’Œç¬¦å·ï¼Œæå‡ä¼ æ’­æ½œåŠ›å’Œè®°å¿†åº¦")
        
        if creative_expression['score'] < 15:
            suggestions.append("å»ºè®®å¢å¼ºåˆ›æ„è¡¨ç°ï¼Œæå‡é¡¹ç›®çš„ç‹¬ç‰¹æ€§å’Œåˆ›æ–°æ€§")
        
        if accessibility['score'] < 15:
            suggestions.append("å»ºè®®ç®€åŒ–æ¦‚å¿µè¡¨è¾¾ï¼Œæé«˜æ™®é€šç”¨æˆ·çš„ç†è§£åº¦")
        
        if credibility['score'] < 15:
            suggestions.append("å»ºè®®æå‡é¡¹ç›®çš„ä¸“ä¸šæ€§å’Œå¯ä¿¡åº¦ï¼Œå¢å¼ºç”¨æˆ·ä¿¡ä»»")
        
        return suggestions

# ============ å…³é”®è¯è¯†åˆ«åˆ†ç±»å·¥å…· ============

class KeywordIdentificationTool(BaseTool):
    """å…³é”®è¯è¯†åˆ«ä¸åˆ†ç±»å·¥å…·"""
    name: str = "keyword_identification_classification"
    description: str = """
    å¯¹ä»£å¸è¿›è¡Œå…¨é¢çš„å…³é”®è¯è¯†åˆ«å’Œåˆ†ç±»ï¼ŒåŒ…æ‹¬ï¼š
    - ä¸»è¦åˆ†ç±»è¯†åˆ«
    - ä¸»é¢˜æ ‡ç­¾æå–
    - å¸‚åœºæƒ…ç»ªå…³é”®è¯åˆ†æ
    - æŠ€æœ¯ç‰¹å¾å…³é”®è¯
    - ç¤¾åŒºæ–‡åŒ–å…³é”®è¯
    - é£é™©ä¿¡å·å…³é”®è¯
    - æµè¡Œæ ‡ç­¾è¯†åˆ«
    """
    args_schema: Type[BaseModel] = KeywordAnalysisInput
    
    def _run(
        self, 
        token_name: Optional[str] = None, 
        token_symbol: Optional[str] = None, 
        project_description: Optional[str] = "",
        social_mentions: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        
        import json
        final_args = {}
        all_inputs = [token_name, token_symbol, project_description, social_mentions]

        for item in all_inputs:
            if isinstance(item, str) and item.startswith('{'):
                try:
                    data = json.loads(item)
                    final_args.update(data)
                except (json.JSONDecodeError, TypeError):
                    pass
        
        # ä½¿ç”¨åŸå§‹å‚æ•°å¡«å……
        if token_name and 'token_name' not in final_args: final_args['token_name'] = token_name
        if token_symbol and 'token_symbol' not in final_args: final_args['token_symbol'] = token_symbol
        if project_description and 'project_description' not in final_args: final_args['project_description'] = project_description
        if social_mentions and 'social_mentions' not in final_args: final_args['social_mentions'] = social_mentions

        # å†…éƒ¨éªŒè¯
        if 'token_name' not in final_args or 'token_symbol' not in final_args:
            error_msg = f"KeywordIdentificationToolç¼ºå°‘å¿…éœ€å‚æ•°ã€‚æ”¶åˆ°: name='{token_name}', symbol='{token_symbol}'"
            logger.error(error_msg)
            return {"error": error_msg}

        valid_name = final_args['token_name']
        valid_symbol = final_args['token_symbol']
        valid_description = final_args.get('project_description', "")
        valid_mentions = final_args.get('social_mentions') or []

        logger.info(f"è¿›è¡Œå…³é”®è¯è¯†åˆ«: {valid_name} ({valid_symbol})")

        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬å†…å®¹
        all_text = f"{valid_name} {valid_symbol} {valid_description} {' '.join(valid_mentions)}".lower()
        
        # ä¸»è¦åˆ†ç±»è¯†åˆ«
        primary_category = self._identify_primary_category(valid_name, valid_symbol, valid_description)
        
        # ä¸»é¢˜æ ‡ç­¾è¯†åˆ«
        theme_tags = self._extract_theme_tags(all_text)
        
        # å¸‚åœºæƒ…ç»ªå…³é”®è¯
        sentiment_keywords = self._extract_sentiment_keywords(all_text)
        
        # æŠ€æœ¯å…³é”®è¯
        tech_keywords = self._extract_technology_keywords(all_text)
        
        # ç¤¾åŒºå…³é”®è¯
        community_keywords = self._extract_community_keywords(all_text)
        
        # é£é™©ä¿¡å·å…³é”®è¯
        risk_keywords = self._extract_risk_keywords(all_text)
        
        # æµè¡Œæ ‡ç­¾
        trending_hashtags = self._extract_trending_hashtags(all_text, valid_mentions)
        
        return {
            "primary_category": primary_category,
            "theme_tags": theme_tags,
            "market_sentiment_keywords": sentiment_keywords,
            "technology_keywords": tech_keywords,
            "community_keywords": community_keywords,
            "risk_signal_keywords": risk_keywords,
            "trending_hashtags": trending_hashtags,
            "keyword_analysis_summary": self._generate_keyword_summary(
                primary_category, theme_tags, sentiment_keywords, tech_keywords
            )
        }
    
    def _identify_primary_category(self, name: str, symbol: str, description: str) -> str:
        """è¯†åˆ«ä¸»è¦åˆ†ç±»"""
        text = f"{name} {symbol} {description}".lower()
        
        # DeFi ä»£å¸
        if any(keyword in text for keyword in ['defi', 'swap', 'liquidity', 'yield', 'farm', 'stake']):
            return "DeFi Token"
        
        # æ¸¸æˆä»£å¸
        if any(keyword in text for keyword in ['game', 'gaming', 'play', 'nft', 'metaverse']):
            return "Gaming Token"
        
        # AIä»£å¸
        if any(keyword in text for keyword in ['ai', 'artificial intelligence', 'machine learning', 'neural']):
            return "AI Token"
        
        # åŠ¨ç‰©ä¸»é¢˜Memeå¸
        animal_keywords = ['cat', 'dog', 'frog', 'bird', 'lion', 'tiger', 'bear', 'wolf', 'rabbit', 'mouse']
        if any(keyword in text for keyword in animal_keywords):
            return "Animal Theme Meme Coin"
        
        # ä¸€èˆ¬Memeå¸
        meme_keywords = ['meme', 'moon', 'rocket', 'diamond', 'hodl', 'ape', 'degen']
        if any(keyword in text for keyword in meme_keywords):
            return "Meme Coin"
        
        # æ”¯ä»˜ä»£å¸
        if any(keyword in text for keyword in ['pay', 'payment', 'cash', 'currency', 'money']):
            return "Payment Token"
        
        # ç¤¾äº¤ä»£å¸
        if any(keyword in text for keyword in ['social', 'community', 'creator', 'content']):
            return "Social Token"
        
        return "Utility Token"
    
    def _extract_theme_tags(self, text: str) -> List[str]:
        """æå–ä¸»é¢˜æ ‡ç­¾"""
        tags = []
        
        # æŠ€æœ¯ä¸»é¢˜
        tech_themes = {
            'blockchain': 'Blockchain',
            'web3': 'Web3',
            'defi': 'DeFi',
            'nft': 'NFT',
            'dao': 'DAO',
            'metaverse': 'Metaverse',
            'ai': 'Artificial Intelligence',
            'gamefi': 'GameFi'
        }
        
        # åŠ¨ç‰©ä¸»é¢˜
        animal_themes = {
            'cat': 'Cat Theme',
            'dog': 'Dog Theme', 
            'frog': 'Frog Theme',
            'bird': 'Bird Theme',
            'lion': 'Lion Theme',
            'bear': 'Bear Theme'
        }
        
        # æƒ…æ„Ÿä¸»é¢˜
        emotion_themes = {
            'love': 'Love Theme',
            'heart': 'Heart Theme',
            'happy': 'Happiness Theme',
            'peace': 'Peace Theme'
        }
        
        # æ£€æŸ¥æ‰€æœ‰ä¸»é¢˜
        for keyword, tag in {**tech_themes, **animal_themes, **emotion_themes}.items():
            if keyword in text and tag not in tags:
                tags.append(tag)
        
        return tags[:10]  # é™åˆ¶æ ‡ç­¾æ•°é‡
    
    def _extract_sentiment_keywords(self, text: str) -> List[str]:
        """æå–å¸‚åœºæƒ…ç»ªå…³é”®è¯"""
        keywords = []
        
        # ç§¯ææƒ…ç»ª
        positive_words = ['moon', 'rocket', 'gem', 'diamond', 'bullish', 'pump', 'lambo', 'moon']
        # æ¶ˆææƒ…ç»ª
        negative_words = ['rug', 'dump', 'bearish', 'scam', 'fail', 'dead']
        # ä¸­æ€§è¯æ±‡
        neutral_words = ['hodl', 'dyor', 'buy', 'sell', 'trade', 'invest']
        
        for word in positive_words + negative_words + neutral_words:
            if word in text and word not in keywords:
                keywords.append(word)
        
        return keywords
    
    def _extract_technology_keywords(self, text: str) -> List[str]:
        """æå–æŠ€æœ¯å…³é”®è¯"""
        keywords = []
        
        tech_words = [
            'erc-20', 'bep-20', 'smart contract', 'blockchain', 'consensus',
            'proof of stake', 'proof of work', 'mining', 'staking', 'yield',
            'liquidity', 'amm', 'dex', 'cex', 'bridge', 'layer2'
        ]
        
        for word in tech_words:
            if word in text and word not in keywords:
                keywords.append(word)
        
        return keywords
    
    def _extract_community_keywords(self, text: str) -> List[str]:
        """æå–ç¤¾åŒºå…³é”®è¯"""
        keywords = []
        
        community_words = [
            'hodl', 'diamond hands', 'paper hands', 'ape', 'fomo', 'fud',
            'community', 'family', 'together', 'strong', 'united', 'team'
        ]
        
        for word in community_words:
            if word in text and word not in keywords:
                keywords.append(word)
        
        return keywords
    
    def _extract_risk_keywords(self, text: str) -> List[str]:
        """æå–é£é™©ä¿¡å·å…³é”®è¯"""
        keywords = []
        
        risk_words = [
            'anonymous', 'no audit', 'high tax', 'locked liquidity', 'rug pull',
            'scam', 'ponzi', 'pyramid', 'get rich quick', 'guaranteed profit'
        ]
        
        for word in risk_words:
            if word in text and word not in keywords:
                keywords.append(word)
        
        return keywords
    
    def _extract_trending_hashtags(self, text: str, social_mentions: List[str]) -> List[str]:
        """æå–æµè¡Œæ ‡ç­¾"""
        hashtags = []
        
        # ä»ç¤¾äº¤åª’ä½“æåŠä¸­æå–hashtag
        for mention in social_mentions:
            hashtag_matches = re.findall(r'#\w+', mention)
            hashtags.extend(hashtag_matches)
        
        # å¸¸è§åŠ å¯†è´§å¸æ ‡ç­¾
        common_hashtags = [
            '#cryptocurrency', '#crypto', '#blockchain', '#defi', '#nft',
            '#web3', '#bitcoin', '#ethereum', '#bsc', '#memecoin'
        ]
        
        # æ·»åŠ å¸¸è§æ ‡ç­¾
        for tag in common_hashtags:
            if tag.lower().replace('#', '') in text and tag not in hashtags:
                hashtags.append(tag)
        
        return list(set(hashtags))[:15]  # å»é‡å¹¶é™åˆ¶æ•°é‡
    
    def _generate_keyword_summary(self, category: str, themes: List[str], 
                                sentiment: List[str], tech: List[str]) -> str:
        """ç”Ÿæˆå…³é”®è¯åˆ†ææ€»ç»“"""
        return f"""
å…³é”®è¯åˆ†ææ€»ç»“ï¼š

ğŸ·ï¸ ä¸»è¦åˆ†ç±»: {category}
ğŸ¯ æ ¸å¿ƒä¸»é¢˜: {', '.join(themes[:5]) if themes else 'æ— æ˜æ˜¾ä¸»é¢˜'}
ğŸ“Š æƒ…ç»ªå€¾å‘: {', '.join(sentiment[:5]) if sentiment else 'ä¸­æ€§'}
âš¡ æŠ€æœ¯ç‰¹å¾: {', '.join(tech[:3]) if tech else 'åŸºç¡€ä»£å¸'}

è¯¥ä»£å¸ä¸»è¦å®šä½ä¸º{category}ï¼Œå…·æœ‰{len(themes)}ä¸ªä¸»é¢˜æ ‡ç­¾ï¼Œ
æƒ…ç»ªå…³é”®è¯æ˜¾ç¤º{'ç§¯æ' if any(word in sentiment for word in ['moon', 'gem', 'bullish']) else 'ä¸­æ€§'}å€¾å‘ã€‚
        """.strip()

# ============ å·¥å…·å¯¼å‡ºå‡½æ•° ============

def get_narrative_scoring_tools() -> List[BaseTool]:
    """è·å–å™äº‹è¯„åˆ†ç›¸å…³å·¥å…·"""
    return [
        MultiDimensionalNarrativeScoringTool(),
        KeywordIdentificationTool()
    ]

if __name__ == "__main__":
    # æµ‹è¯•å·¥å…·
    scoring_tool = MultiDimensionalNarrativeScoringTool()
    keyword_tool = KeywordIdentificationTool()
    
    # æµ‹è¯•æ•°æ®
    test_result = scoring_tool._run(
        token_name="CatCoin",
        token_symbol="CAT",
        token_description="A community-driven meme token featuring cute cats",
        community_info={"telegram_members": 5000, "twitter_followers": 3000},
        market_data={"contract_verified": True, "liquidity_usd": 100000, "holder_count": 2000}
    )
    
    print("å™äº‹è¯„åˆ†æµ‹è¯•ç»“æœ:")
    print(f"æ€»åˆ†: {test_result['total_narrative_score']}/100")
    print(f"ç­‰çº§: {test_result['score_grade']}")
