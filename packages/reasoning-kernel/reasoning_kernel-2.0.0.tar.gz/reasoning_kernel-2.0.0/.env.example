# Development Environment Configuration (.env.example)
# Copy to .env and fill in values as needed for local development.

# ==========================
# App Environment
# ==========================
ENVIRONMENT=development
DEBUG=true
DEVELOPMENT=true
LOG_LEVEL=DEBUG

# ==========================
# AI Providers (configure at least one)
# ==========================
# OpenAI
OPENAI_API_KEY=your_openai_api_key_here

# Azure OpenAI
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# Preferred key in code; "_NAME" also supported. Either is fine.
AZURE_OPENAI_DEPLOYMENT=gpt-5
# AZURE_OPENAI_DEPLOYMENT_NAME=
AZURE_OPENAI_API_VERSION=2025-04-01-preview

# Azure Responses API (Reasoning models)
# When true, use /openai/v1/responses instead of chat/completions
AZURE_OPENAI_USE_RESPONSES=true
# Optional deployment override specifically for Responses API
AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=gpt-5

# Optional: Reasoning configuration for Responses API
# Effort can be: low, medium, high
AZURE_OPENAI_REASONING_EFFORT=high
# To request reasoning summaries when supported:
# Valid value: detailed (requires verified org access on some providers)
AZURE_OPENAI_REASONING_SUMMARY=

# Google AI / Gemini
# KernelManager reads either GOOGLE_AI_API_KEY or GEMINI_API_KEY;
# Settings maps GEMINI_API_KEY to google_api_key automatically.
GOOGLE_AI_API_KEY=your_google_ai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# ==========================
# Redis (single URL is preferred; components are also supported)
# ==========================
REDIS_URL=redis://localhost:6379
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=your_redis_password_here
REDIS_SSL=false

LANGCACHE_CACHE_ID=your_langcache_cache_id_here
LANGCACHE_ENDPOINT=https://your-langcache-endpoint.redis.io
LANGCACHE_API_KEY=your_langcache_api_key_here

REDIS_VECTOR_SIZE=1536
REDIS_COLLECTION_NAME=msa_knowledge
REDIS_MAX_CONNECTIONS=50
REDIS_SOCKET_TIMEOUT=5
REDIS_SOCKET_CONNECT_TIMEOUT=5
# ==========================
# Daytona Sandbox
# ==========================
DAYTONA_API_KEY=your_daytona_api_key_here
DAYTONA_API_URL=https://app.daytona.io/api
DAYTONA_TARGET=us
DAYTONA_WORKSPACE_ID=your_workspace_id_here
DAYTONA_PROXY_URL=
DAYTONA_CPU_LIMIT=2
DAYTONA_MEMORY_LIMIT_MB=512
DAYTONA_EXECUTION_TIMEOUT=30
DAYTONA_PYTHON_VERSION=3.12
DAYTONA_ENABLE_NETWORKING=false

# ==========================
# MSA Engine Settings
# ==========================
MAX_REASONING_STEPS=10
MAX_ITERATIONS=5
CONFIDENCE_THRESHOLD=0.7
UNCERTAINTY_THRESHOLD=0.8
PROBABILISTIC_SAMPLES=1000
NUMPYRO_NUM_CHAINS=2
JAX_ENABLE_X64=true

# ==========================
# Timeouts (seconds)
# ==========================
REASONING_TIMEOUT=300
KNOWLEDGE_EXTRACTION_TIMEOUT=120
PROBABILISTIC_SYNTHESIS_TIMEOUT=180

# ==========================
# Feature Flags
# ==========================
ENABLE_MEMORY=true
ENABLE_PLUGINS=true
ENABLE_CACHING=true
ENABLE_TRACING=false

# ==========================
# Security / CORS
# ==========================
API_KEY_VALIDATION=false
RATE_LIMITING=false
ENCRYPT_MEMORY=false
# Use a comma-separated list or "*"; Settings parses both.
CORS_ORIGINS=*

# ==========================
# Monitoring / Telemetry
# ==========================
STRUCTURED_LOGGING=true
ENABLE_METRICS=false
ENABLE_TELEMETRY=false
PROMETHEUS_PORT=9090
SENTRY_DSN=your_sentry_dsn_here
DATADOG_API_KEY=your_datadog_api_key_here

# ==========================
# Security Manager (Redis endpoints for subsystems)
# ==========================
API_KEY_REDIS_URL=redis://localhost:6379/1
RATE_LIMITING_REDIS_URL=redis://localhost:6379/0
AUDIT_REDIS_URL=redis://localhost:6379/2
