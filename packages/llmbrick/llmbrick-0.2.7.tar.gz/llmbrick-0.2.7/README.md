# LLMBrick

[![Python Version](https://img.shields.io/pypi/pyversions/llmbrick)](https://www.python.org/downloads/)
[![PyPI Version](https://img.shields.io/pypi/v/llmbrick)](https://pypi.org/project/llmbrick/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/JiHungLin/llmbrick/blob/main/LICENSE)
[![Documentation](https://img.shields.io/badge/docs-latest-brightgreen)](https://jihunglin.github.io/llmbrick/)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/JiHungLin/llmbrick)

ä¸€å€‹å¼·èª¿ã€Œæ¨¡çµ„åŒ–è¨­è¨ˆã€ã€ã€Œæ˜ç¢ºå”å®šå®šç¾©ã€ã€ã€Œéˆæ´»çµ„è£ã€èˆ‡ã€Œæ˜“æ–¼æ“´å±•ã€çš„ LLM æ‡‰ç”¨é–‹ç™¼æ¡†æ¶ã€‚
æ ¸å¿ƒç†å¿µç‚ºï¼šæ‰€æœ‰åŠŸèƒ½çš†ä»¥ Brick çµ„ä»¶ç‚ºå–®å…ƒï¼Œå”å®šæ˜ç¢ºã€çµ„è£å½ˆæ€§ï¼Œæ–¹ä¾¿æ“´å……èˆ‡å®¢è£½åŒ–ã€‚

## ç‰¹è‰²

- ğŸ§± **æ¨¡çµ„åŒ–è¨­è¨ˆ**ï¼šæ‰€æœ‰åŠŸèƒ½çš†ä»¥ Brick ç‚ºå–®å…ƒï¼Œçµ„ä»¶å¯æ’æ‹”ã€å¯é‡çµ„ï¼Œæ”¯æ´å¤šå±¤æ¬¡çµ„è£ã€‚
- ğŸ“‘ **æ˜ç¢ºå”å®šå®šç¾©**ï¼šæ‰€æœ‰ Brick ä¹‹é–“çš„è³‡æ–™æµã€å‹åˆ¥ã€éŒ¯èª¤çš†æœ‰æ˜ç¢ºå”å®šï¼ˆprotocols/ ç›®éŒ„ï¼‰ï¼Œä¾¿æ–¼è·¨èªè¨€ã€è·¨å”è­°æ•´åˆã€‚
- ğŸ”„ **å¤šå”è­°æ”¯æ´**ï¼šSSEã€gRPCï¼ˆWebSocket/WebRTC è¨ˆç•«ä¸­ï¼‰ï¼Œå¯ä¾éœ€æ±‚åˆ‡æ›ã€‚
- ğŸ”§ **æ˜“æ–¼æ“´å±•**ï¼šæ’ä»¶ç³»çµ±èˆ‡è‡ªå®šç¾©çµ„ä»¶ï¼Œæ”¯æ´éˆæ´»æ“´å……èˆ‡å®¢è£½åŒ–ã€‚

### è¨­è¨ˆç†å¿µ

- **æ¨¡çµ„åŒ–**ï¼šæ¯å€‹ Brick å¯ç¨ç«‹é–‹ç™¼ã€æ¸¬è©¦ã€çµ„è£ï¼Œé™ä½è€¦åˆã€‚
- **å”å®šå°å‘**ï¼šæ‰€æœ‰è³‡æ–™æµã€å‹åˆ¥ã€éŒ¯èª¤çš†æœ‰æ˜ç¢ºå”å®šï¼Œä¾¿æ–¼è·¨èªè¨€ã€è·¨å”è­°æ•´åˆã€‚
- **éˆæ´»çµ„è£**ï¼šPipelineã€Serverã€Client çš†å¯è‡ªç”±çµ„åˆå„ç¨® Brickï¼Œæ”¯æ´å¤šç¨®æ‡‰ç”¨å ´æ™¯ã€‚
- **æ˜“æ–¼æ“´å±•**ï¼šå¯è‡ªè¨‚æ–° Brickã€å”å®šæˆ–æ’ä»¶ï¼Œå¿«é€Ÿæ“´å……åŠŸèƒ½ã€‚

## å¿«é€Ÿé–‹å§‹

### å®‰è£

```bash
pip install llmbrick
```

### åŸºæœ¬ä½¿ç”¨

```python
from llmbrick import OpenAILLM
from llmbrick.servers.sse import SSEServer

# å»ºç«‹ LLM Brick
llm_brick = OpenAILLM(api_key="your-api-key")

# å•Ÿå‹• SSE æœå‹™
server = SSEServer(llm_brick)
server.run(host="0.0.0.0", port=8000)
```

## æ¸¬è©¦é é¢

SSEServer æä¾›äº†å…§å»ºçš„æ¸¬è©¦é é¢ï¼Œæ–¹ä¾¿é–‹ç™¼å’Œæ¸¬è©¦ï¼š

```python
# å•Ÿç”¨æ¸¬è©¦é é¢
server = SSEServer(enable_test_page=True)
server.run(host="0.0.0.0", port=8000)
```

æ¸¬è©¦é é¢ç‰¹è‰²ï¼š
- å®Œæ•´çš„è«‹æ±‚è¡¨å–®ï¼Œæ”¯æ´æ‰€æœ‰ SSERequest æ¬„ä½
- å‹•æ…‹è¨Šæ¯ç®¡ç†ï¼ˆæ–°å¢/åˆªé™¤/é‡æ’åºï¼‰
- å³æ™‚ä¸²æµè¼¸å‡ºé¡¯ç¤ºï¼Œæ”¯æ´è‡ªå‹•æ²å‹•
- ä¸åŒé¡å‹è¨Šæ¯é¡è‰²å€åˆ†
- æ™‚é–“æˆ³è¨˜æ¨™è¨˜
- æ·±è‰²/æ·ºè‰²ä¸»é¡Œåˆ‡æ›
- å®Œæ•´çš„ API æ–‡ä»¶å’Œç¯„ä¾‹

<!-- ![SSE Test Page](https://raw.githubusercontent.com/JiHungLin/llmbrick/main/docs/guides/sse_server_test.png) -->
![SSE Test Page](https://raw.githubusercontent.com/JiHungLin/llmbrick/main/examples/openai_chatbot/openai_chatbot.gif)

## ç¯„ä¾‹

### OpenAI GPT Brick with SSE Server

å®Œæ•´çš„ OpenAI GPT æ•´åˆç¤ºä¾‹ï¼ŒåŒ…å«ï¼š
- SSE æœå‹™å™¨æ•´åˆèˆ‡æ¸¬è©¦é é¢
- ä¸²æµè¼¸å‡ºèˆ‡å³æ™‚ç´¯ç©å›æ‡‰
- è‡ªå‹•ç³»çµ±èªè¨€åµæ¸¬
- æ·±è‰²/æ·ºè‰²ä¸»é¡Œæ”¯æ´

ğŸ‘‰ [æŸ¥çœ‹ç¯„ä¾‹](https://github.com/JiHungLin/llmbrick/blob/main/examples/openai_chatbot/openai_chatbot.py) | [ä½¿ç”¨èªªæ˜](https://github.com/JiHungLin/llmbrick/blob/main/examples/openai_chatbot/README.md)

### æ¨™æº–ç”¨æ³•ç¯„ä¾‹

#### 1. CommonBrick æ¨™æº–ç”¨æ³•

```python
from llmbrick.bricks.common.common import CommonBrick
from llmbrick.core.brick import unary_handler, get_service_info_handler
from llmbrick.protocols.models.bricks.common_types import CommonRequest, CommonResponse, ErrorDetail, ServiceInfoResponse

class SimpleBrick(CommonBrick):
    @unary_handler
    async def process(self, request: CommonRequest) -> CommonResponse:
        return CommonResponse(
            data={"message": f"Hello, {request.data.get('name', 'World')}!"},
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )

    @get_service_info_handler
    async def get_info(self) -> ServiceInfoResponse:
        return ServiceInfoResponse(
            service_name="SimpleBrick",
            version="1.0.0",
            models=[],
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )
```

#### 2. LLMBrick æ¨™æº–ç”¨æ³•

```python
from llmbrick.bricks.llm.base_llm import LLMBrick
from llmbrick.core.brick import unary_handler, output_streaming_handler, get_service_info_handler
from llmbrick.protocols.models.bricks.llm_types import LLMRequest, LLMResponse, Context
from llmbrick.protocols.models.bricks.common_types import ErrorDetail, ServiceInfoResponse

class SimpleLLMBrick(LLMBrick):
    @unary_handler
    async def echo(self, request: LLMRequest) -> LLMResponse:
        return LLMResponse(
            text=f"Echo: {request.prompt}",
            tokens=["echo"],
            is_final=True,
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success"),
        )

    @get_service_info_handler
    async def info(self) -> ServiceInfoResponse:
        return ServiceInfoResponse(
            service_name="SimpleLLMBrick",
            version="1.0.0",
            models=[],
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success"),
        )
```

#### 3. ComposeBrick æ¨™æº–ç”¨æ³•

```python
from llmbrick.bricks.compose.base_compose import ComposeBrick
from llmbrick.core.brick import unary_handler, output_streaming_handler, get_service_info_handler
from llmbrick.protocols.models.bricks.compose_types import ComposeRequest, ComposeResponse
from llmbrick.protocols.models.bricks.common_types import ErrorDetail, ServiceInfoResponse

class SimpleCompose(ComposeBrick):
    @unary_handler
    async def process(self, request: ComposeRequest) -> ComposeResponse:
        return ComposeResponse(
            output={"message": f"æ–‡ä»¶æ•¸é‡: {len(request.input_documents)}"},
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )

    @get_service_info_handler
    async def get_info(self) -> ServiceInfoResponse:
        return ServiceInfoResponse(
            service_name="SimpleCompose",
            version="1.0.0",
            models=[],
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )
```

#### 4. GuardBrick æ¨™æº–ç”¨æ³•

```python
from llmbrick.bricks.guard.base_guard import GuardBrick
from llmbrick.core.brick import unary_handler, get_service_info_handler
from llmbrick.protocols.models.bricks.guard_types import GuardRequest, GuardResponse, GuardResult
from llmbrick.protocols.models.bricks.common_types import ErrorDetail, ServiceInfoResponse

class SimpleGuard(GuardBrick):
    @unary_handler
    async def check(self, request: GuardRequest) -> GuardResponse:
        is_attack = "attack" in (request.text or "").lower()
        result = GuardResult(
            is_attack=is_attack,
            confidence=0.99 if is_attack else 0.1,
            detail="Detected attack" if is_attack else "Safe"
        )
        return GuardResponse(
            results=[result],
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )

    @get_service_info_handler
    async def info(self) -> ServiceInfoResponse:
        return ServiceInfoResponse(
            service_name="SimpleGuard",
            version="1.0.0",
            models=[],
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )
```

#### 5. IntentionBrick æ¨™æº–ç”¨æ³•

```python
from llmbrick.bricks.intention.base_intention import IntentionBrick
from llmbrick.core.brick import unary_handler, get_service_info_handler
from llmbrick.protocols.models.bricks.intention_types import IntentionRequest, IntentionResponse, IntentionResult
from llmbrick.protocols.models.bricks.common_types import ErrorDetail, ServiceInfoResponse

class SimpleIntentionBrick(IntentionBrick):
    @unary_handler
    async def process(self, request: IntentionRequest) -> IntentionResponse:
        return IntentionResponse(
            results=[IntentionResult(intent_category="greet", confidence=1.0)],
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )

    @get_service_info_handler
    async def get_info(self) -> ServiceInfoResponse:
        return ServiceInfoResponse(
            service_name="SimpleIntentionBrick",
            version="1.0.0",
            models=[],
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )
```

#### 6. RectifyBrick æ¨™æº–ç”¨æ³•

```python
from llmbrick.bricks.rectify.base_rectify import RectifyBrick
from llmbrick.core.brick import unary_handler, get_service_info_handler
from llmbrick.protocols.models.bricks.rectify_types import RectifyRequest, RectifyResponse
from llmbrick.protocols.models.bricks.common_types import ErrorDetail, ServiceInfoResponse

class SimpleRectifyBrick(RectifyBrick):
    @unary_handler
    async def rectify_handler(self, request: RectifyRequest) -> RectifyResponse:
        return RectifyResponse(
            corrected_text=request.text.upper(),
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )

    @get_service_info_handler
    async def service_info_handler(self) -> ServiceInfoResponse:
        return ServiceInfoResponse(
            service_name="SimpleRectifyBrick",
            version="1.0.0",
            models=[],
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )
```

#### 7. RetrievalBrick æ¨™æº–ç”¨æ³•

```python
from llmbrick.bricks.retrieval.base_retrieval import RetrievalBrick
from llmbrick.core.brick import unary_handler, get_service_info_handler
from llmbrick.protocols.models.bricks.retrieval_types import RetrievalRequest, RetrievalResponse
from llmbrick.protocols.models.bricks.common_types import ErrorDetail, ServiceInfoResponse

class SimpleRetrievalBrick(RetrievalBrick):
    @unary_handler
    async def search(self, request: RetrievalRequest) -> RetrievalResponse:
        return RetrievalResponse(
            documents=[],
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )

    @get_service_info_handler
    async def info(self) -> ServiceInfoResponse:
        return ServiceInfoResponse(
            service_name="SimpleRetrievalBrick",
            version="1.0.0",
            models=[],
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success")
        )
```

#### 8. TranslateBrick æ¨™æº–ç”¨æ³•

```python
from llmbrick.bricks.translate.base_translate import TranslateBrick
from llmbrick.core.brick import unary_handler, output_streaming_handler, get_service_info_handler
from llmbrick.protocols.models.bricks.translate_types import TranslateRequest, TranslateResponse
from llmbrick.protocols.models.bricks.common_types import ErrorDetail, ServiceInfoResponse

class SimpleTranslator(TranslateBrick):
    @unary_handler
    async def echo_translate(self, request: TranslateRequest) -> TranslateResponse:
        return TranslateResponse(
            text=f"{request.text} (to {request.target_language})",
            tokens=[1, 2, 3],
            language_code=request.target_language,
            is_final=True,
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success"),
        )

    @get_service_info_handler
    async def service_info(self) -> ServiceInfoResponse:
        return ServiceInfoResponse(
            service_name="SimpleTranslator",
            version="1.0.0",
            models=[],
            error=ErrorDetail(code=ErrorCodes.SUCCESS, message="Success"),
        )
```

#### 9. gRPC æœå‹™ç«¯èˆ‡å®¢æˆ¶ç«¯ç¯„ä¾‹

```python
# æœå‹™ç«¯
from llmbrick.servers.grpc.server import GrpcServer
from llmbrick.bricks.llm.base_llm import LLMBrick
import asyncio

brick = LLMBrick(default_prompt="ä½ å¥½")
server = GrpcServer(port=50051)
server.register_service(brick)
server.run()


# å®¢æˆ¶ç«¯
from llmbrick.bricks.llm.base_llm import LLMBrick
from llmbrick.protocols.models.bricks.llm_types import LLMRequest
import asyncio

async def use_grpc_client():
    client_brick = LLMBrick.toGrpcClient(remote_address="127.0.0.1:50051")
    req = LLMRequest(prompt="Test", context=[])
    resp = await client_brick.run_unary(req)
    print(resp)

asyncio.run(use_grpc_client())
```

#### 10. SSE Server æ¨™æº–ç”¨æ³•

```python
from llmbrick.servers.sse.server import SSEServer
from llmbrick.protocols.models.http.conversation import ConversationSSEResponse

server = SSEServer()

@server.handler
async def my_handler(request_data):
    # å›å‚³å¤šå€‹äº‹ä»¶
    yield ConversationSSEResponse(
        id="msg-1",
        type="text",
        text="Hello World",
        progress="IN_PROGRESS"
    )
    yield ConversationSSEResponse(
        id="msg-2",
        type="done",
        progress="DONE"
    )

if __name__ == "__main__":
    server.run(host="0.0.0.0", port=8000)
```

## ğŸ“š æ–‡æª”

- [å®Œæ•´ç·šä¸Šæ–‡æª”ï¼ˆDocusaurusï¼‰](https://jihunglin.github.io/llmbrick/)
  åŒ…å«æ‰€æœ‰æŒ‡å—ã€API åƒè€ƒã€æ•™å­¸èˆ‡éƒ¨ç½²èªªæ˜ï¼Œå»ºè­°å„ªå…ˆæŸ¥é–±ã€‚
- [å¿«é€Ÿé–‹å§‹](https://jihunglin.github.io/llmbrick/docs/quickstart)
  æœ€ç²¾ç°¡çš„å®‰è£èˆ‡ç¬¬ä¸€å€‹ Brick å¯¦ä½œæ­¥é©Ÿã€‚
- [API åƒè€ƒ](https://jihunglin.github.io/llmbrick/docs/documents/api)
  å„é¡ Brick èˆ‡æ ¸å¿ƒæ–¹æ³•çš„ API æ–‡ä»¶ã€‚
- [æ•™å­¸ç¯„ä¾‹](https://jihunglin.github.io/llmbrick/docs/quickstart/examples)
  Step-by-step æ•™å­¸èˆ‡é–‹ç™¼å¯¦ä¾‹ã€‚
- [å…ƒä»¶æŒ‡å—ï¼ˆBrick Guidesï¼‰](https://jihunglin.github.io/llmbrick/docs/category/bricks)
  è©³ç´°èªªæ˜å„é¡ Brickï¼ˆå¦‚ CommonBrickã€LLMBrickã€GuardBrick ç­‰ï¼‰çš„è¨­è¨ˆç†å¿µã€å¯¦ä½œç¯„ä¾‹èˆ‡æœ€ä½³å¯¦è¸ã€‚

> æ–‡æª”çµæ§‹èªªæ˜ï¼š
> - **å¿«é€Ÿé–‹å§‹**ï¼šæ–°æ‰‹å…¥é–€ã€å®‰è£èˆ‡ Hello World
> - **API åƒè€ƒ**ï¼šæŸ¥è©¢å„å…ƒä»¶æ–¹æ³•èˆ‡å‹åˆ¥
> - **æ•™å­¸ç¯„ä¾‹**ï¼šå¯¦æˆ°æ¡ˆä¾‹ã€é€²éšæ‡‰ç”¨
> - **å…ƒä»¶æŒ‡å—**ï¼šæ¯ç¨® Brick çš„è¨­è¨ˆèˆ‡æœ€ä½³å¯¦è¸
> - **å®Œæ•´æ–‡æª”**ï¼šå»ºè­°ç›´æ¥ç€è¦½ Docusaurus ä»¥ç²å¾—æœ€ä½³é–±è®€é«”é©—

## æˆæ¬Š

MIT License
## Metrics Utilities

The `llmbrick.utils.metrics` module provides decorators for monitoring function performance and resource usage. All decorators support both sync and async functions.

### Available Decorators

- **@measure_time**  
  Logs the execution time of the decorated function.

- **@measure_memory**  
  Logs the difference in process memory usage (RSS, MB) before and after the function runs. Requires `psutil`.

- **@measure_peak_memory**  
  Logs the peak memory usage (MB) during function execution using `tracemalloc`.

### Usage Example

```python
from llmbrick.utils.metrics import measure_time, measure_memory, measure_peak_memory

@measure_time
def sync_func(x):
    return x * 2

@measure_memory
async def async_func(x):
    a = [0] * 10000
    return x + 1

@measure_peak_memory
def another_sync_func(x):
    a = [0] * 10000
    return x - 1
```

All decorators will log performance metrics using the standard logging module.  
For async functions, simply decorate as usual.