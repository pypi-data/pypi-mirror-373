---
title: CLI
---

Discover and run benchmarks defined with `@bench` or `Bench`.

## Basic

```bash
pybench <files|directories> [options]
# alias
pyb <...>
```

- Directories expand to `**/*bench.py`.
- Colors enabled on TTY; use `--no-color` to disable.

## Options

```text
-k <word>             # filter by substring in case/file name
-P k=v                # override params: n, repeat, warmup, group and custom params (repeatable)
--no-color            # disable ANSI colors
--sort [group|time]   # sort groups or by avg time within group
--desc                # descending order
--budget 300ms        # per-variant budget (calibration). Accepts ns, ms, s
--max-n 1000000       # cap for calibrated n
--profile [thorough|smoke]
--brief               # compact output: benchmark, time(avg), vs base
--save LABEL          # save this run under .pybenchx/runs with optional label
--save-baseline NAME  # save this run as a named baseline under .pybenchx/baselines
--compare BASE|PATH   # compare current run against a baseline name or JSON file
--fail-on POLICY      # e.g. "mean:7%,p99:12%"; checked when --compare is used
--export FMT[:PATH]   # export as json|md|csv to stdout or a file when a path is given
```

Profiles:
- thorough: `budget≈1s`, `repeat=30`
- smoke (default): no calibration, `repeat=3`, `warmup=0`

## Overrides with -P

```bash
pybench examples/ -P repeat=5 -P n=10000 -P warmup=0
pybench examples/ -P group=strings
pybench examples/ -P sep=":"  # override a case parameter
```

## Sorting and brief mode

```bash
pybench examples/ --sort time --desc
pybench examples/ --brief
```

## Header and table

- Header: CPU, Python, clock resolution, profile.
- Table: mean, iter/s, min…max, p75/p99/p995, baseline and speed vs base. “≈ same” when ≤1% diff.

## Run management

- Runs and baselines are stored under `.pybenchx/` in your project root.
- `--compare` prints a simple diff and applies `--fail-on` thresholds.
- P-values via Mann–Whitney U (approx). `p99` policy uses actual P99 delta.
