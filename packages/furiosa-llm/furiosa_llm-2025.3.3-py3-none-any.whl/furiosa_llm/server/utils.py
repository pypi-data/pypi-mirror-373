import asyncio
from asyncio import FIRST_COMPLETED, ensure_future
import contextlib
import importlib
import json
import os
import sys
from typing import (
    Any,
    AsyncGenerator,
    Awaitable,
    Callable,
    List,
    Literal,
    Optional,
    Tuple,
    TypedDict,
    TypeVar,
    Union,
)
import uuid

from fastapi import HTTPException, Request
import orjson
import partial_json_parser  # type: ignore
from partial_json_parser.core.options import Allow  # type: ignore
from pydantic import BaseModel
from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast
from typing_extensions import Type, TypeIs

T = TypeVar("T")

# TODO: Add MistralTokenizer
AnyTokenizer = Union[PreTrainedTokenizer, PreTrainedTokenizerFast]


def random_uuid() -> str:
    return str(uuid.uuid4().hex)


def random_tool_call_id() -> str:
    return f"chatcmpl-tool-{random_uuid()}"


class ConversationMessage(TypedDict):
    role: str
    content: str


async def merge_async_iterators(
    *iterators: AsyncGenerator[T, None],
    is_cancelled: Optional[Callable[[], Awaitable[bool]]] = None,
) -> AsyncGenerator[Tuple[int, T], None]:
    """Merge multiple asynchronous iterators into a single iterator.

    This method handle the case where some iterators finish before others.
    When it yields, it yields a tuple (i, item) where i is the index of the
    iterator that yields the item.

    It also optionally polls a provided function at least once per second
    to check for client cancellation.
    """

    # Can use anext() in python >= 3.10
    awaits = {ensure_future(pair[1].__anext__()): pair for pair in enumerate(iterators)}
    timeout = None if is_cancelled is None else 1
    try:
        while awaits:
            done, pending = await asyncio.wait(
                awaits.keys(), return_when=FIRST_COMPLETED, timeout=timeout
            )
            if is_cancelled is not None and await is_cancelled():
                raise asyncio.CancelledError("client cancelled")
            for d in done:
                pair = awaits.pop(d)
                try:
                    item = await d
                    i, it = pair
                    awaits[ensure_future(it.__anext__())] = pair
                    yield i, item
                except StopAsyncIteration:
                    pass
    finally:
        # Cancel any remaining iterators
        for f, (_, it) in awaits.items():
            with contextlib.suppress(BaseException):
                f.cancel()
                await it.aclose()


BM = TypeVar("BM", bound=BaseModel)


async def parse_request(raw_request: Request, request_cls: Type[BM]) -> BM:
    if "application/json" not in raw_request.headers.get("Content-Type", ""):
        raise HTTPException(status_code=415, detail="Content-Type must be application/json")
    try:
        body = await raw_request.body()
        data = orjson.loads(body)
        request = request_cls.model_validate(data)
        return request
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


async def handle_disconnect(request: Request, callback: Callable[[], Awaitable[None]]) -> None:
    """Returns if a disconnect message is received"""
    while True:
        message = await request.receive()
        if message["type"] == "http.disconnect":
            break
    await callback()


def import_from_path(module_name: str, file_path: Union[str, os.PathLike]):
    """
    Import a Python file according to its file path.

    Based on the official recipe:
    https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly
    """
    spec = importlib.util.spec_from_file_location(module_name, file_path)
    if spec is None:
        raise ModuleNotFoundError(f"No module named '{module_name}'")

    assert spec.loader is not None

    module = importlib.util.module_from_spec(spec)
    sys.modules[module_name] = module
    spec.loader.exec_module(module)
    return module


def partial_json_loads(input_str: str, flags: Allow) -> Tuple[Any, int]:
    try:
        return (partial_json_parser.loads(input_str, flags), len(input_str))
    except partial_json_parser.JSONDecodeError as e:
        if "Extra data" in e.msg:
            dec = json.JSONDecoder()
            return dec.raw_decode(input_str)
        raise


def is_complete_json(input_str: str) -> bool:
    try:
        orjson.loads(input_str)
        return True
    except orjson.JSONDecodeError:
        return False


def find_common_prefix(s1: str, s2: str) -> str:
    """
    Finds a common prefix that is shared between two strings, if there is one.
    Order of arguments is NOT important.

    This function is provided as a UTILITY for extracting information from JSON
    generated by partial_json_parser, to help in ensuring that the right tokens
    are returned in streaming, so that close-quotes, close-brackets and
    close-braces are not returned prematurely.

    e.g. find_common_prefix('{"fruit": "ap"}', '{"fruit": "apple"}') ->
    '{"fruit": "ap'
    """
    min_length = min(len(s1), len(s2))
    for i in range(0, min_length):
        if s1[i] != s2[i]:
            break
    return s1[:i]


def is_list_of(
    value: object,
    typ: Type[T],
    *,
    check: Literal["first", "all"] = "first",
) -> TypeIs[List[T]]:
    if not isinstance(value, list):
        return False

    if check == "first":
        return len(value) == 0 or isinstance(value[0], typ)
    elif check == "all":
        return all(isinstance(v, typ) for v in value)

    raise ValueError(f"invalid check: {check}")
