"""å­¦ä¹ æŠ¥å‘Šç”Ÿæˆå™¨ã€‚"""

from datetime import datetime
from typing import Dict, Any, List

from .analysis import ErrorAnalyzer


class LearningReportGenerator:
    """å­¦ä¹ æŠ¥å‘Šç”Ÿæˆå™¨ã€‚"""

    def __init__(self, days_back: int = 30):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨ã€‚

        Args:
            days_back: åˆ†ææœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®
        """
        self.analyzer = ErrorAnalyzer(days_back)
        self.days_back = days_back

    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´çš„å­¦ä¹ æŠ¥å‘Šã€‚"""
        # è·å–åˆ†ææ•°æ®
        error_patterns = self.analyzer.analyze_error_patterns()
        skill_assessment = self.analyzer.generate_skill_assessment()
        learning_recommendations = self.analyzer.generate_learning_recommendations()

        # æ„å»ºæŠ¥å‘Š
        report = {
            "report_info": {
                "generated_at": datetime.now().isoformat(),
                "analysis_period": f"æœ€è¿‘{self.days_back}å¤©",
                "report_type": "å­¦ä¹ æˆé•¿æŠ¥å‘Š",
            },
            "error_summary": {
                "total_errors": error_patterns["total_errors"],
                "analysis_period": error_patterns["analysis_period"],
                "most_common_commands": error_patterns["common_commands"][:5],
                "most_common_error_types": error_patterns["error_types"][:5],
            },
            "skill_assessment": skill_assessment,
            "learning_recommendations": learning_recommendations,
            "improvement_insights": self._generate_improvement_insights(error_patterns),
            "next_steps": self._generate_next_steps(learning_recommendations),
        }

        # ç”ŸæˆAIæ´å¯Ÿæ€»ç»“
        try:
            ai_insights = self._generate_ai_insights(report)
            report["ai_insights"] = ai_insights
        except Exception:
            # å¦‚æœAIæ´å¯Ÿç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ€»ç»“
            report["ai_insights"] = self._generate_fallback_insights(report)

        return report

    def _generate_improvement_insights(
        self, error_patterns: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ”¹è¿›æ´å¯Ÿã€‚"""
        insights = []

        total_errors = error_patterns["total_errors"]
        common_commands = error_patterns["common_commands"]
        error_types = error_patterns["error_types"]
        improvement_trend = error_patterns["improvement_trend"]

        # é”™è¯¯é¢‘ç‡æ´å¯Ÿ
        if total_errors > 20:
            insights.append(
                {
                    "type": "é¢‘ç‡è­¦å‘Š",
                    "title": "é”™è¯¯é¢‘ç‡è¾ƒé«˜",
                    "description": (
                        f"åœ¨è¿‡å»{self.days_back}å¤©é‡Œå‘ç”Ÿäº†{total_errors}æ¬¡é”™è¯¯ï¼Œ"
                        "å»ºè®®é‡ç‚¹å…³æ³¨å¸¸è§é”™è¯¯çš„é¢„é˜²ã€‚"
                    ),
                    "severity": "é«˜",
                }
            )
        elif total_errors > 10:
            insights.append(
                {
                    "type": "é¢‘ç‡æé†’",
                    "title": "é”™è¯¯é¢‘ç‡é€‚ä¸­",
                    "description": (
                        f"åœ¨è¿‡å»{self.days_back}å¤©é‡Œå‘ç”Ÿäº†{total_errors}æ¬¡é”™è¯¯ï¼Œ"
                        "æ•´ä½“è¡¨ç°è‰¯å¥½ï¼Œå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚"
                    ),
                    "severity": "ä¸­",
                }
            )
        elif total_errors > 0:
            insights.append(
                {
                    "type": "é¢‘ç‡è‰¯å¥½",
                    "title": "é”™è¯¯é¢‘ç‡è¾ƒä½",
                    "description": (
                        f"åœ¨è¿‡å»{self.days_back}å¤©é‡Œä»…å‘ç”Ÿäº†{total_errors}æ¬¡é”™è¯¯ï¼Œ" "è¡¨ç°ä¼˜ç§€ï¼"
                    ),
                    "severity": "ä½",
                }
            )

        # å‘½ä»¤é›†ä¸­åº¦æ´å¯Ÿ
        if common_commands:
            top_command, top_count = common_commands[0]
            if top_count >= 5:
                insights.append(
                    {
                        "type": "å‘½ä»¤é›†ä¸­",
                        "title": f"{top_command} å‘½ä»¤éœ€è¦é‡ç‚¹å…³æ³¨",
                        "description": (
                            f"ä½ åœ¨ {top_command} å‘½ä»¤ä¸Šå‡ºç°äº† {top_count} æ¬¡é”™è¯¯ï¼Œ"
                            f"å æ€»é”™è¯¯çš„ {top_count / total_errors * 100:.1f}%ã€‚"
                        ),
                        "severity": "é«˜",
                    }
                )

        # é”™è¯¯ç±»å‹åˆ†å¸ƒæ´å¯Ÿ
        if error_types:
            top_error_type, top_error_count = error_types[0]
            if top_error_count >= 3:
                insights.append(
                    {
                        "type": "é”™è¯¯ç±»å‹",
                        "title": f"{top_error_type}æ˜¯ä¸»è¦é—®é¢˜",
                        "description": (
                            f"ä½ é‡åˆ°äº† {top_error_count} æ¬¡{top_error_type}ï¼Œ"
                            "å»ºè®®å­¦ä¹ ç›¸å…³çš„é¢„é˜²æŠ€å·§ã€‚"
                        ),
                        "severity": "ä¸­",
                    }
                )

        # è¶‹åŠ¿æ´å¯Ÿ
        if len(improvement_trend) >= 2:
            recent_errors = improvement_trend[-1]["total_errors"]
            previous_errors = improvement_trend[-2]["total_errors"]

            if recent_errors < previous_errors:
                insights.append(
                    {
                        "type": "è¶‹åŠ¿æ”¹å–„",
                        "title": "é”™è¯¯è¶‹åŠ¿æ­£åœ¨æ”¹å–„",
                        "description": (
                            f"æœ€è¿‘ä¸€å‘¨çš„é”™è¯¯æ•°é‡({recent_errors})æ¯”å‰ä¸€å‘¨"
                            f"({previous_errors})æœ‰æ‰€å‡å°‘ï¼Œç»§ç»­ä¿æŒï¼"
                        ),
                        "severity": "ä½",
                    }
                )
            elif recent_errors > previous_errors:
                insights.append(
                    {
                        "type": "è¶‹åŠ¿è­¦å‘Š",
                        "title": "é”™è¯¯è¶‹åŠ¿éœ€è¦æ³¨æ„",
                        "description": (
                            f"æœ€è¿‘ä¸€å‘¨çš„é”™è¯¯æ•°é‡({recent_errors})æ¯”å‰ä¸€å‘¨"
                            f"({previous_errors})æœ‰æ‰€å¢åŠ ï¼Œéœ€è¦å…³æ³¨ã€‚"
                        ),
                        "severity": "ä¸­",
                    }
                )

        return insights

    def _generate_next_steps(self, recommendations: List[Dict[str, Any]]) -> List[str]:
        """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®ã€‚"""
        if not recommendations:
            return [
                "ç»§ç»­ä¿æŒè‰¯å¥½çš„å‘½ä»¤è¡Œä½¿ç”¨ä¹ æƒ¯",
                "å®šæœŸå›é¡¾å’Œæ€»ç»“ä½¿ç”¨ç»éªŒ",
                "æ¢ç´¢æ–°çš„å‘½ä»¤å’Œå·¥å…·",
                "åˆ†äº«ç»éªŒå¸®åŠ©ä»–äºº",
            ]

        next_steps = []

        # åŸºäºé«˜ä¼˜å…ˆçº§å»ºè®®
        high_priority = [rec for rec in recommendations if rec["priority"] == "é«˜"]
        if high_priority:
            next_steps.append(f"ä¼˜å…ˆå­¦ä¹ ï¼š{high_priority[0]['title']}")
            if len(high_priority) > 1:
                next_steps.append(f"å…¶æ¬¡å…³æ³¨ï¼š{high_priority[1]['title']}")

        # åŸºäºå»ºè®®ç±»å‹
        command_recs = [rec for rec in recommendations if rec["type"] == "å‘½ä»¤æŒæ¡"]
        if command_recs:
            next_steps.append(f"å‘½ä»¤æŠ€èƒ½ï¼š{command_recs[0]['title']}")

        error_recs = [rec for rec in recommendations if rec["type"] == "é”™è¯¯é¢„é˜²"]
        if error_recs:
            next_steps.append(f"é”™è¯¯é¢„é˜²ï¼š{error_recs[0]['title']}")

        # é€šç”¨å»ºè®®
        next_steps.extend(
            [
                "æ¯å¤©ç»ƒä¹ ä½¿ç”¨å‘½ä»¤è¡Œ15-30åˆ†é’Ÿ",
                "é‡åˆ°é”™è¯¯æ—¶ä»”ç»†é˜…è¯»é”™è¯¯ä¿¡æ¯",
                "å»ºç«‹ä¸ªäººçš„å‘½ä»¤è¡Œç¬”è®°å’ŒæŠ€å·§æ”¶é›†",
            ]
        )

        return next_steps[:6]  # è¿”å›æœ€å¤š6ä¸ªæ­¥éª¤

    def format_report_for_display(self, report: Dict[str, Any]) -> str:
        """å°†æŠ¥å‘Šæ ¼å¼åŒ–ä¸ºé€‚åˆæ˜¾ç¤ºçš„å­—ç¬¦ä¸²ã€‚"""
        lines = []

        # æŠ¥å‘Šæ ‡é¢˜
        lines.append("# ğŸ“Š AIS å­¦ä¹ æˆé•¿æŠ¥å‘Š")
        lines.append("")

        # AIæ´å¯Ÿæ€»ç»“ - æ”¾åœ¨æœ€å‰é¢
        if report.get("ai_insights"):
            lines.append("## ğŸ§  AIæ™ºèƒ½æ´å¯Ÿ")
            lines.append(f"> {report['ai_insights']}")
            lines.append("")

        lines.append(f"**åˆ†æå‘¨æœŸ**: {report['report_info']['analysis_period']}")
        generated_time = datetime.fromisoformat(report["report_info"]["generated_at"]).strftime(
            "%Y-%m-%d %H:%M:%S"
        )
        lines.append(f"**ç”Ÿæˆæ—¶é—´**: {generated_time}")
        lines.append("")

        # é”™è¯¯æ¦‚è§ˆ
        error_summary = report["error_summary"]
        lines.append("## ğŸ” é”™è¯¯æ¦‚è§ˆ")
        lines.append(f"- **æ€»é”™è¯¯æ•°**: {error_summary['total_errors']} æ¬¡")

        if error_summary["most_common_commands"]:
            lines.append("- **æœ€å¸¸å‡ºé”™çš„å‘½ä»¤**:")
            for cmd, count in error_summary["most_common_commands"]:
                lines.append(f"  - `{cmd}`: {count} æ¬¡")

        if error_summary["most_common_error_types"]:
            lines.append("- **æœ€å¸¸è§çš„é”™è¯¯ç±»å‹**:")
            for error_type, count in error_summary["most_common_error_types"]:
                lines.append(f"  - {error_type}: {count} æ¬¡")

        lines.append("")

        # æŠ€èƒ½è¯„ä¼°
        skill_assessment = report["skill_assessment"]
        lines.append("## ğŸ’ª æŠ€èƒ½è¯„ä¼°")
        lines.append(f"- **å½“å‰æ°´å¹³**: {skill_assessment['skill_level']}")

        if skill_assessment["strengths"]:
            lines.append("- **ä¼˜åŠ¿é¢†åŸŸ**: " + ", ".join(skill_assessment["strengths"]))

        if skill_assessment["weaknesses"]:
            lines.append("- **éœ€è¦æ”¹è¿›**: " + ", ".join(skill_assessment["weaknesses"]))

        if skill_assessment["knowledge_gaps"]:
            lines.append("- **çŸ¥è¯†ç›²ç‚¹**: " + ", ".join(skill_assessment["knowledge_gaps"]))

        lines.append("")

        # æ”¹è¿›æ´å¯Ÿ
        improvement_insights = report["improvement_insights"]
        if improvement_insights:
            lines.append("## ğŸ’¡ æ”¹è¿›æ´å¯Ÿ")
            for insight in improvement_insights:
                severity_icon = {"é«˜": "ğŸ”¥", "ä¸­": "âš ï¸", "ä½": "âœ“ "}.get(insight["severity"], "ğŸ’¡")
                lines.append(f"### {severity_icon} {insight['title']}")
                lines.append(insight["description"])
                lines.append("")

        # å­¦ä¹ å»ºè®®
        learning_recommendations = report["learning_recommendations"]
        if learning_recommendations:
            lines.append("## ğŸ¯ å­¦ä¹ å»ºè®®")
            for i, rec in enumerate(learning_recommendations, 1):
                priority_icon = {"é«˜": "ğŸ”¥", "ä¸­": "âš ï¸", "ä½": "ğŸ’¡"}.get(rec["priority"], "ğŸ’¡")
                lines.append(f"### {i}. {priority_icon} {rec['title']}")
                lines.append(f"**ç±»å‹**: {rec['type']} | **ä¼˜å…ˆçº§**: {rec['priority']}")
                lines.append(rec["description"])

                if rec["learning_path"]:
                    lines.append("**å­¦ä¹ è·¯å¾„**:")
                    for step in rec["learning_path"]:
                        lines.append(f"- {step}")
                lines.append("")

        # ä¸‹ä¸€æ­¥è¡ŒåŠ¨
        next_steps = report["next_steps"]
        if next_steps:
            lines.append("## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨")
            for i, step in enumerate(next_steps, 1):
                lines.append(f"{i}. {step}")
            lines.append("")

        # ç»“å°¾
        lines.append("---")
        lines.append("ğŸ’¡ **æç¤º**: ä½¿ç”¨ `ais learn <ä¸»é¢˜>` æ·±å…¥å­¦ä¹ ç‰¹å®šä¸»é¢˜")
        lines.append("ğŸ“š **å¸®åŠ©**: ä½¿ç”¨ `ais ask <é—®é¢˜>` è·å–å³æ—¶ç­”æ¡ˆ")
        lines.append("ğŸ“ˆ **è¿›åº¦**: å®šæœŸè¿è¡Œ `ais report` è·Ÿè¸ªå­¦ä¹ è¿›åº¦")

        return "\n".join(lines)

    def _generate_ai_insights(self, report: Dict[str, Any]) -> str:
        """ç”ŸæˆAIæ´å¯Ÿæ€»ç»“"""
        # æ”¶é›†ä¸°å¯Œçš„æ´å¯Ÿæ•°æ®
        insights_data = self._collect_rich_insights_data(report)

        # æ„å»ºå¢å¼ºç‰ˆæç¤ºè¯
        insights_prompt = f"""
è¯·åŸºäºç”¨æˆ·æœ€è¿‘30å¤©çš„è¯¦ç»†å‘½ä»¤è¡Œæ•°æ®ï¼Œç”Ÿæˆä¸€æ®µ3-5å¥è¯çš„æ·±åº¦ä¸ªæ€§åŒ–æ´å¯Ÿæ€»ç»“ã€‚

## ç”¨æˆ·è¯¦ç»†æ•°æ®åˆ†æ

### åŸºç¡€ç»Ÿè®¡
- æ€»é”™è¯¯æ•°ï¼š{insights_data['basic_stats']['total_errors']}æ¬¡
- æŠ€èƒ½æ°´å¹³ï¼š{insights_data['basic_stats']['skill_level']}
- ç‹¬ç‰¹å‘½ä»¤æ•°ï¼š{insights_data['basic_stats']['unique_commands']}ä¸ª

### é”™è¯¯æ¨¡å¼æ·±åº¦åˆ†æ
- æœ€é¢‘ç¹é”™è¯¯ï¼š{insights_data['error_patterns']['top_error_detail']}
- é”™è¯¯ç±»å‹åˆ†å¸ƒï¼š{insights_data['error_patterns']['error_types_summary']}
- æ—¶é—´æ¨¡å¼ï¼š{insights_data['error_patterns']['time_patterns']}

### æŠ€èƒ½æˆé•¿è½¨è¿¹
- ä¼˜åŠ¿æŠ€èƒ½ï¼š{insights_data['skill_analysis']['strengths_detail']}
- æ”¹è¿›é¢†åŸŸï¼š{insights_data['skill_analysis']['improvement_areas']}
- å­¦ä¹ è¿›åº¦ï¼š{insights_data['skill_analysis']['learning_velocity']}

### ç¯å¢ƒå’Œä¸Šä¸‹æ–‡æ´å¯Ÿ
- ä¸»è¦å·¥ä½œç¯å¢ƒï¼š{insights_data['context_insights']['work_environments']}
- é¡¹ç›®ç±»å‹åˆ†å¸ƒï¼š{insights_data['context_insights']['project_types']}
- å¤æ‚åº¦è¶‹åŠ¿ï¼š{insights_data['context_insights']['complexity_trend']}

### è¶‹åŠ¿å’Œè¿›æ­¥æŒ‡æ ‡
- å‘¨è¶‹åŠ¿ï¼š{insights_data['trend_analysis']['weekly_trend']}
- è¿›æ­¥é€Ÿåº¦ï¼š{insights_data['trend_analysis']['improvement_rate']}
- çªå‡ºè¡¨ç°ï¼š{insights_data['trend_analysis']['notable_achievements']}

## æ´å¯Ÿè¦æ±‚
1. å‘ç°æœ€ä»¤äººæƒŠå–œæˆ–æ„å¤–çš„æ•°æ®æ¨¡å¼
2. çªå‡ºç”¨æˆ·ç‹¬ç‰¹çš„å­¦ä¹ ç‰¹å¾å’Œè¿›æ­¥äº®ç‚¹
3. æä¾›å…·ä½“çš„æ•°å­—è¯æ®å’Œå¯¹æ¯”
4. è¯­è°ƒç§¯æé¼“åŠ±ï¼Œä½“ç°ä¸ªæ€§åŒ–å…³æ€€
5. 3-5å¥è¯ï¼Œæ¯å¥è¯éƒ½æœ‰ä»·å€¼å’Œæ´å¯ŸåŠ›
6. é¿å…é€šç”¨å»ºè®®ï¼Œä¸“æ³¨äºç”¨æˆ·ç‰¹æœ‰çš„å‘ç°

è¯·ç”Ÿæˆä¸€æ®µè®©äººçœ¼å‰ä¸€äº®çš„æ·±åº¦æ´å¯Ÿæ€»ç»“ï¼š
"""

        # è°ƒç”¨AIç”Ÿæˆæ´å¯Ÿ
        from ..core.ai import ask_ai
        from ..core.config import get_config

        config = get_config()
        ai_insights = ask_ai(insights_prompt, config)

        return ai_insights.strip()

    def _generate_fallback_insights(self, report: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¤‡ç”¨æ´å¯Ÿï¼ˆAIä¸å¯ç”¨æ—¶ï¼‰"""
        total_errors = report["error_summary"]["total_errors"]
        skill_level = report["skill_assessment"]["skill_level"]
        strengths = report["skill_assessment"]["strengths"]
        weaknesses = report["skill_assessment"]["weaknesses"]
        top_commands = report["error_summary"]["most_common_commands"][:2]

        if total_errors == 0:
            return "ğŸŒŸ å®Œç¾ï¼æœ€è¿‘30å¤©é›¶é”™è¯¯ï¼Œä½ çš„å‘½ä»¤è¡ŒæŠ€èƒ½å·²ç»ç›¸å½“ç†Ÿç»ƒäº†ã€‚è¿™ç§ç¨³å®šçš„è¡¨ç°è¯´æ˜ä½ å·²ç»å»ºç«‹äº†è‰¯å¥½çš„æ“ä½œä¹ æƒ¯ã€‚ç»§ç»­ä¿æŒè¿™ç§æ°´å‡†ï¼Œä½ å·²ç»æ˜¯å‘½ä»¤è¡Œé«˜æ‰‹äº†ï¼"
        elif total_errors < 5:
            insight = f"ğŸ‘ å‡ºè‰²è¡¨ç°ï¼ä»…{total_errors}æ¬¡é”™è¯¯ï¼Œä½ æ­£ç¨³æ­¥å‘å‘½ä»¤è¡Œä¸“å®¶è¿ˆè¿›ã€‚"
            if strengths:
                insight += f"ä½ åœ¨{strengths[0]}æ–¹é¢è¡¨ç°å°¤ä¸ºå‡ºè‰²ã€‚"
            insight += "è¿™ç§ä½é”™è¯¯ç‡åæ˜ äº†æ‰å®çš„åŸºç¡€æŠ€èƒ½ã€‚"
            if weaknesses:
                insight += f"å»ºè®®ç»§ç»­å…³æ³¨{weaknesses[0]}é¢†åŸŸçš„æå‡ã€‚"
            return insight
        elif total_errors < 15:
            insight = (
                f"ğŸ“ˆ ç¨³æ­¥æˆé•¿ä¸­ï¼{total_errors}æ¬¡é”™è¯¯åæ˜ äº†ä½ çš„æ¢ç´¢ç²¾ç¥ï¼Œæ¯æ¬¡é”™è¯¯éƒ½æ˜¯è¿›æ­¥çš„å°é˜¶ã€‚"
            )
            if top_commands:
                top_cmd = top_commands[0][0]
                insight += f"ä½ åœ¨{top_cmd}å‘½ä»¤ä¸Šé‡åˆ°çš„æŒ‘æˆ˜æœ€å¤šï¼Œè¿™æ­£æ˜¯å­¦ä¹ çš„å¥½æœºä¼šã€‚"
            insight += f"å½“å‰{skill_level}æ°´å¹³å¾ˆä¸é”™ï¼Œç»§ç»­ä¿æŒå­¦ä¹ èŠ‚å¥ã€‚"
            if strengths:
                insight += f"ä½ çš„{strengths[0]}æŠ€èƒ½å·²ç»æˆä¸ºä¼˜åŠ¿ã€‚"
            return insight
        else:
            insight = (
                f"ğŸš€ å­¦ä¹ åŠ é€ŸæœŸï¼{total_errors}æ¬¡é”™è¯¯è¯´æ˜ä½ æ­£åœ¨ç§¯ææ¢ç´¢æ–°é¢†åŸŸï¼Œä¿æŒè¿™ç§å­¦ä¹ çƒ­æƒ…ï¼"
            )
            if top_commands:
                top_cmd = top_commands[0][0]
                count = top_commands[0][1]
                insight += f"{top_cmd}å‘½ä»¤å‡ºç°{count}æ¬¡é”™è¯¯ï¼Œå»ºè®®é‡ç‚¹æ”»å…‹ã€‚"
            insight += "é¢‘ç¹çš„å°è¯•æ˜¯æŒæ¡æ–°æŠ€èƒ½çš„å¿…ç»ä¹‹è·¯ã€‚"
            if strengths:
                insight += f"ä½ åœ¨{strengths[0]}æ–¹é¢å·²ç»å±•ç°å‡ºå¤©èµ‹ã€‚"
            insight += "æ¯ä¸ªé”™è¯¯éƒ½åœ¨ä¸ºä½ çš„æŠ€èƒ½å‡çº§ç§¯ç´¯ç»éªŒã€‚"
            return insight

    def _collect_rich_insights_data(self, report: Dict[str, Any]) -> Dict[str, Any]:
        """æ”¶é›†ä¸°å¯Œçš„æ´å¯Ÿæ•°æ®"""
        # è·å–åŸå§‹é”™è¯¯æ—¥å¿—è¿›è¡Œæ·±åº¦åˆ†æ
        error_logs = self.analyzer.get_error_logs()

        return {
            "basic_stats": self._analyze_basic_stats(report, error_logs),
            "error_patterns": self._analyze_error_patterns_deep(report, error_logs),
            "skill_analysis": self._analyze_skill_progression(report, error_logs),
            "context_insights": self._analyze_context_patterns(error_logs),
            "trend_analysis": self._analyze_trends_deep(report, error_logs),
        }

    def _analyze_basic_stats(self, report: Dict[str, Any], error_logs: List) -> Dict[str, Any]:
        """åˆ†æåŸºç¡€ç»Ÿè®¡æ•°æ®"""
        total_errors = report["error_summary"]["total_errors"]
        unique_commands = len(
            set(
                log.original_command.split()[0] if log.original_command.split() else ""
                for log in error_logs
            )
        )

        return {
            "total_errors": total_errors,
            "skill_level": report["skill_assessment"]["skill_level"],
            "unique_commands": unique_commands,
            "error_density": f"{total_errors / 30:.1f}æ¬¡/å¤©" if total_errors > 0 else "0æ¬¡/å¤©",
        }

    def _analyze_error_patterns_deep(
        self, report: Dict[str, Any], error_logs: List
    ) -> Dict[str, Any]:
        """æ·±åº¦åˆ†æé”™è¯¯æ¨¡å¼"""
        if not error_logs:
            return {"top_error_detail": "æ— ", "error_types_summary": "æ— ", "time_patterns": "æ— "}

        # åˆ†ææœ€é¢‘ç¹çš„é”™è¯¯
        top_commands = report["error_summary"]["most_common_commands"]
        top_error_detail = "æ— ç‰¹å®šæ¨¡å¼"
        if top_commands:
            cmd, count = top_commands[0]
            percentage = (count / len(error_logs)) * 100
            top_error_detail = f"{cmd}å‘½ä»¤({count}æ¬¡ï¼Œå {percentage:.1f}%)"

        # é”™è¯¯ç±»å‹æ±‡æ€»
        error_types = report["error_summary"]["most_common_error_types"][:3]
        error_types_summary = (
            ", ".join([f"{etype}({count}æ¬¡)" for etype, count in error_types])
            if error_types
            else "å¤šæ ·åŒ–é”™è¯¯"
        )

        # æ—¶é—´æ¨¡å¼åˆ†æ
        time_patterns = self._analyze_time_patterns(error_logs)

        return {
            "top_error_detail": top_error_detail,
            "error_types_summary": error_types_summary,
            "time_patterns": time_patterns,
        }

    def _analyze_time_patterns(self, error_logs: List) -> str:
        """åˆ†ææ—¶é—´æ¨¡å¼"""
        if not error_logs:
            return "æ— æ˜æ˜¾æ—¶é—´æ¨¡å¼"

        # æŒ‰å°æ—¶åˆ†ç»„
        hour_errors = {}
        for log in error_logs:
            hour = log.timestamp.hour
            hour_errors[hour] = hour_errors.get(hour, 0) + 1

        if not hour_errors:
            return "æ— æ˜æ˜¾æ—¶é—´æ¨¡å¼"

        # æ‰¾å‡ºé«˜å³°æ—¶æ®µ
        peak_hour = max(hour_errors.items(), key=lambda x: x[1])
        total_errors = sum(hour_errors.values())

        if peak_hour[1] / total_errors > 0.3:  # å¦‚æœæŸä¸ªæ—¶æ®µå æ¯”è¶…è¿‡30%
            if 9 <= peak_hour[0] <= 17:
                return f"å·¥ä½œæ—¶é—´({peak_hour[0]}ç‚¹)é”™è¯¯é›†ä¸­({peak_hour[1]}æ¬¡)"
            elif 18 <= peak_hour[0] <= 22:
                return f"æ™šé—´å­¦ä¹ æ—¶æ®µ({peak_hour[0]}ç‚¹)æœ€æ´»è·ƒ({peak_hour[1]}æ¬¡)"
            else:
                return f"æ·±å¤œæ¢ç´¢({peak_hour[0]}ç‚¹)é¢‘ç¹å°è¯•({peak_hour[1]}æ¬¡)"
        else:
            return "é”™è¯¯æ—¶é—´åˆ†å¸ƒå‡åŒ€ï¼Œæ— æ˜æ˜¾é«˜å³°"

    def _analyze_skill_progression(
        self, report: Dict[str, Any], error_logs: List
    ) -> Dict[str, Any]:
        """åˆ†ææŠ€èƒ½è¿›æ­¥è½¨è¿¹"""
        strengths = report["skill_assessment"]["strengths"][:2]
        weaknesses = report["skill_assessment"]["weaknesses"][:2]

        strengths_detail = "ã€".join(strengths) if strengths else "åŸºç¡€æŠ€èƒ½æ‰å®"
        improvement_areas = "ã€".join(weaknesses) if weaknesses else "æŠ€èƒ½å‡è¡¡å‘å±•"

        # è®¡ç®—å­¦ä¹ é€Ÿåº¦
        unique_commands = len(
            set(
                log.original_command.split()[0] if log.original_command.split() else ""
                for log in error_logs
            )
        )
        if unique_commands > 15:
            learning_velocity = "å¿«é€Ÿæ¢ç´¢å‹ï¼ˆæ¶‰åŠå¤šä¸ªé¢†åŸŸï¼‰"
        elif unique_commands > 8:
            learning_velocity = "ç¨³æ­¥å­¦ä¹ å‹ï¼ˆé€æ­¥æ‰©å±•ï¼‰"
        elif unique_commands > 3:
            learning_velocity = "ä¸“æ³¨æ·±å…¥å‹ï¼ˆé‡ç‚¹çªç ´ï¼‰"
        else:
            learning_velocity = "è°¨æ…å­¦ä¹ å‹ï¼ˆç¨³æ‰ç¨³æ‰“ï¼‰"

        return {
            "strengths_detail": strengths_detail,
            "improvement_areas": improvement_areas,
            "learning_velocity": learning_velocity,
        }

    def _analyze_context_patterns(self, error_logs: List) -> Dict[str, Any]:
        """åˆ†æä¸Šä¸‹æ–‡æ¨¡å¼"""
        if not error_logs:
            return {
                "work_environments": "æ— æ•°æ®",
                "project_types": "æ— æ•°æ®",
                "complexity_trend": "æ— æ•°æ®",
            }

        # åˆ†æé¡¹ç›®ç±»å‹ï¼ˆä»context_jsonä¸­æå–ï¼‰
        project_types = {}
        git_usage = 0
        docker_usage = 0

        for log in error_logs:
            if log.context_json:
                try:
                    import json

                    context = json.loads(log.context_json)

                    # é¡¹ç›®ç±»å‹ç»Ÿè®¡
                    project_context = context.get("project_context", {})
                    if project_context:
                        ptype = project_context.get("project_type", "unknown")
                        if ptype != "unknown":
                            project_types[ptype] = project_types.get(ptype, 0) + 1

                    # Gitä½¿ç”¨æƒ…å†µ
                    if context.get("git_branch"):
                        git_usage += 1

                except Exception:
                    pass

            # Dockerä½¿ç”¨æƒ…å†µ
            if "docker" in log.original_command.lower():
                docker_usage += 1

        # å·¥ä½œç¯å¢ƒåˆ†æ
        work_environments = []
        if git_usage > len(error_logs) * 0.3:
            work_environments.append("Gitç‰ˆæœ¬æ§åˆ¶")
        if docker_usage > 0:
            work_environments.append("å®¹å™¨åŒ–å¼€å‘")
        if project_types:
            top_project = max(project_types.items(), key=lambda x: x[1])
            work_environments.append(f"{top_project[0]}é¡¹ç›®")

        work_env_summary = "ã€".join(work_environments) if work_environments else "é€šç”¨å‘½ä»¤è¡Œç¯å¢ƒ"

        # é¡¹ç›®ç±»å‹åˆ†å¸ƒ
        if project_types:
            project_summary = "ã€".join(
                [f"{ptype}({count}æ¬¡)" for ptype, count in project_types.items()]
            )
        else:
            project_summary = "æœªæ£€æµ‹åˆ°ç‰¹å®šé¡¹ç›®ç±»å‹"

        # å¤æ‚åº¦è¶‹åŠ¿
        complexity_indicators = ["docker", "git", "ssh", "chmod", "sudo"]
        complex_commands = sum(
            1
            for log in error_logs
            if any(indicator in log.original_command.lower() for indicator in complexity_indicators)
        )

        if complex_commands > len(error_logs) * 0.5:
            complexity_trend = "é«˜å¤æ‚åº¦æ“ä½œå ä¸»å¯¼"
        elif complex_commands > len(error_logs) * 0.2:
            complexity_trend = "ä¸­ç­‰å¤æ‚åº¦ï¼Œé€æ­¥æå‡"
        else:
            complexity_trend = "åŸºç¡€æ“ä½œä¸ºä¸»"

        return {
            "work_environments": work_env_summary,
            "project_types": project_summary,
            "complexity_trend": complexity_trend,
        }

    def _analyze_trends_deep(self, report: Dict[str, Any], error_logs: List) -> Dict[str, Any]:
        """æ·±åº¦è¶‹åŠ¿åˆ†æ"""
        if not error_logs or len(error_logs) < 7:
            return {
                "weekly_trend": "æ•°æ®ä¸è¶³",
                "improvement_rate": "æ— æ³•è¯„ä¼°",
                "notable_achievements": "ç»§ç»­ç§¯ç´¯",
            }

        # åˆ†æå‘¨è¶‹åŠ¿
        from datetime import datetime, timedelta

        now = datetime.now()
        last_week = now - timedelta(days=7)

        recent_errors = [log for log in error_logs if log.timestamp >= last_week]
        older_errors = [log for log in error_logs if log.timestamp < last_week]

        if older_errors:
            recent_rate = len(recent_errors) / 7
            older_rate = len(older_errors) / min(23, (now - error_logs[-1].timestamp).days)

            if recent_rate < older_rate * 0.7:
                weekly_trend = f"æ˜¾è‘—æ”¹å–„ï¼ˆé”™è¯¯ç‡ä¸‹é™{(1 - recent_rate / older_rate) * 100:.0f}%ï¼‰"
            elif recent_rate > older_rate * 1.3:
                weekly_trend = (
                    f"å­¦ä¹ åŠ é€ŸæœŸï¼ˆæ–°æŒ‘æˆ˜å¢åŠ {(recent_rate / older_rate - 1) * 100:.0f}%ï¼‰"
                )
            else:
                weekly_trend = "ç¨³å®šå‘å±•ä¸­"
        else:
            weekly_trend = "åˆæœŸå­¦ä¹ é˜¶æ®µ"

        # æ”¹è¿›é€Ÿåº¦è¯„ä¼°
        total_errors = len(error_logs)
        days_span = (error_logs[0].timestamp - error_logs[-1].timestamp).days + 1

        if total_errors < days_span * 0.3:
            improvement_rate = "å¿«é€ŸæŒæ¡å‹"
        elif total_errors < days_span * 0.8:
            improvement_rate = "ç¨³æ­¥æå‡å‹"
        else:
            improvement_rate = "æ¢ç´¢å­¦ä¹ å‹"

        # çªå‡ºæˆå°±
        notable_achievements = []
        unique_commands = len(
            set(
                log.original_command.split()[0] if log.original_command.split() else ""
                for log in error_logs
            )
        )

        if unique_commands > 20:
            notable_achievements.append("æŠ€æœ¯æ ˆå¹¿åº¦è¶…è¶Š80%ç”¨æˆ·")
        if total_errors < 5:
            notable_achievements.append("é”™è¯¯æ§åˆ¶èƒ½åŠ›ä¼˜ç§€")
        if any("docker" in log.original_command.lower() for log in error_logs):
            notable_achievements.append("å‹‡äºå°è¯•å®¹å™¨åŒ–æŠ€æœ¯")
        if any("git" in log.original_command.lower() for log in error_logs):
            notable_achievements.append("ç‰ˆæœ¬æ§åˆ¶æŠ€èƒ½å®è·µ")

        achievements_summary = (
            "ã€".join(notable_achievements) if notable_achievements else "ç¨³æ­¥å»ºç«‹æŠ€èƒ½åŸºç¡€"
        )

        return {
            "weekly_trend": weekly_trend,
            "improvement_rate": improvement_rate,
            "notable_achievements": achievements_summary,
        }
