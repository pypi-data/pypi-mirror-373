import os
from typing import Dict, List, Set, Tuple, Optional
from collections import defaultdict, Counter
from difflib import SequenceMatcher
import itertools

from ..helpers import load_tags


def find_duplicate_tags() -> Dict:
    """
    Find files that have identical tag sets.
    
    :return: Dictionary with duplicate analysis results
    """
    data = load_tags()
    
    if not data:
        return {
            'success': False,
            'message': 'No tagged files found',
            'duplicates': {},
            'total_files': 0,
            'duplicate_groups': 0
        }
    
    # Group files by their tag sets (convert to sorted tuple for hashability)
    tag_groups = defaultdict(list)
    
    for file_path, tags in data.items():
        # Sort tags to ensure consistent grouping
        tag_signature = tuple(sorted(tags))
        tag_groups[tag_signature].append(file_path)
    
    # Find groups with more than one file (duplicates)
    duplicates = {
        tag_signature: files 
        for tag_signature, files in tag_groups.items() 
        if len(files) > 1
    }
    
    total_duplicate_files = sum(len(files) for files in duplicates.values())
    
    return {
        'success': True,
        'message': f'Found {len(duplicates)} groups with identical tags ({total_duplicate_files} files total)',
        'duplicates': duplicates,
        'total_files': len(data),
        'duplicate_groups': len(duplicates),
        'duplicate_files_count': total_duplicate_files
    }


def find_orphaned_files() -> Dict:
    """
    Find files that have no tags or empty tag lists.
    
    :return: Dictionary with orphaned files analysis
    """
    data = load_tags()
    
    if not data:
        return {
            'success': False,
            'message': 'No files found in tag system',
            'orphans': [],
            'total_files': 0,
            'orphan_count': 0
        }
    
    # Find files with no tags or empty tag lists
    orphans = []
    for file_path, tags in data.items():
        if not tags or len(tags) == 0:
            orphans.append(file_path)
    
    return {
        'success': True,
        'message': f'Found {len(orphans)} orphaned files (no tags)',
        'orphans': orphans,
        'total_files': len(data),
        'orphan_count': len(orphans)
    }


def calculate_tag_similarity(tags1: List[str], tags2: List[str]) -> float:
    """
    Calculate similarity between two tag sets using Jaccard similarity.
    
    :param tags1: First set of tags
    :param tags2: Second set of tags
    :return: Similarity score between 0 and 1
    """
    if not tags1 and not tags2:
        return 1.0
    
    if not tags1 or not tags2:
        return 0.0
    
    set1 = set(tag.lower() for tag in tags1)
    set2 = set(tag.lower() for tag in tags2)
    
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))
    
    return intersection / union if union > 0 else 0.0


def find_similar_files(target_file: str, similarity_threshold: float = 0.3) -> Dict:
    """
    Find files with similar tags to a target file.
    
    :param target_file: Path to the target file
    :param similarity_threshold: Minimum similarity score (0-1)
    :return: Dictionary with similar files analysis
    """
    data = load_tags()
    
    if not data:
        return {
            'success': False,
            'message': 'No tagged files found',
            'similar_files': [],
            'target_file': target_file,
            'target_tags': []
        }
    
    # Normalize target file path
    target_file = os.path.normpath(target_file)
    
    # Find target file in data (case-insensitive search)
    target_tags = None
    actual_target_path = None
    
    for file_path, tags in data.items():
        if os.path.normpath(file_path).lower() == target_file.lower():
            target_tags = tags
            actual_target_path = file_path
            break
    
    if target_tags is None:
        return {
            'success': False,
            'message': f'Target file not found in tag system: {target_file}',
            'similar_files': [],
            'target_file': target_file,
            'target_tags': []
        }
    
    if not target_tags:
        return {
            'success': False,
            'message': f'Target file has no tags: {target_file}',
            'similar_files': [],
            'target_file': actual_target_path,
            'target_tags': []
        }
    
    # Calculate similarity with all other files
    similar_files = []
    
    for file_path, tags in data.items():
        if file_path == actual_target_path:
            continue  # Skip the target file itself
        
        if not tags:
            continue  # Skip files with no tags
        
        similarity = calculate_tag_similarity(target_tags, tags)
        
        if similarity >= similarity_threshold:
            similar_files.append({
                'file_path': file_path,
                'tags': tags,
                'similarity': similarity,
                'common_tags': list(set(tag.lower() for tag in target_tags).intersection(
                    set(tag.lower() for tag in tags)
                )),
                'unique_tags': list(set(tag.lower() for tag in tags) - 
                                  set(tag.lower() for tag in target_tags))
            })
    
    # Sort by similarity (highest first)
    similar_files.sort(key=lambda x: x['similarity'], reverse=True)
    
    return {
        'success': True,
        'message': f'Found {len(similar_files)} files similar to {os.path.basename(actual_target_path)}',
        'similar_files': similar_files,
        'target_file': actual_target_path,
        'target_tags': target_tags,
        'similarity_threshold': similarity_threshold
    }


def find_tag_clusters(min_cluster_size: int = 2) -> Dict:
    """
    Find clusters of files that share common tags.
    
    :param min_cluster_size: Minimum number of files in a cluster
    :return: Dictionary with cluster analysis
    """
    data = load_tags()
    
    if not data:
        return {
            'success': False,
            'message': 'No tagged files found',
            'clusters': {},
            'total_files': 0
        }
    
    # Count tag occurrences
    tag_to_files = defaultdict(list)
    
    for file_path, tags in data.items():
        for tag in tags:
            tag_to_files[tag.lower()].append(file_path)
    
    # Find clusters (tags with multiple files)
    clusters = {}
    for tag, files in tag_to_files.items():
        if len(files) >= min_cluster_size:
            clusters[tag] = {
                'files': files,
                'file_count': len(files),
                'percentage': (len(files) / len(data)) * 100
            }
    
    # Sort clusters by file count
    sorted_clusters = dict(sorted(clusters.items(), 
                                key=lambda x: x[1]['file_count'], 
                                reverse=True))
    
    return {
        'success': True,
        'message': f'Found {len(sorted_clusters)} tag clusters',
        'clusters': sorted_clusters,
        'total_files': len(data),
        'min_cluster_size': min_cluster_size
    }


def find_isolated_files(max_shared_tags: int = 1) -> Dict:
    """
    Find files that share very few tags with other files (isolated files).
    
    :param max_shared_tags: Maximum number of shared tags to be considered isolated
    :return: Dictionary with isolated files analysis
    """
    data = load_tags()
    
    if not data:
        return {
            'success': False,
            'message': 'No tagged files found',
            'isolated_files': [],
            'total_files': 0
        }
    
    isolated_files = []
    
    for target_file, target_tags in data.items():
        if not target_tags:
            continue
        
        max_shared = 0
        most_similar_file = None
        
        # Compare with all other files
        for other_file, other_tags in data.items():
            if target_file == other_file or not other_tags:
                continue
            
            # Count shared tags (case-insensitive)
            shared_count = len(set(tag.lower() for tag in target_tags).intersection(
                set(tag.lower() for tag in other_tags)
            ))
            
            if shared_count > max_shared:
                max_shared = shared_count
                most_similar_file = other_file
        
        # If this file shares few tags with others, it's isolated
        if max_shared <= max_shared_tags:
            isolated_files.append({
                'file_path': target_file,
                'tags': target_tags,
                'max_shared_tags': max_shared,
                'most_similar_file': most_similar_file
            })
    
    return {
        'success': True,
        'message': f'Found {len(isolated_files)} isolated files',
        'isolated_files': isolated_files,
        'total_files': len(data),
        'max_shared_tags': max_shared_tags
    }


def format_duplicates_result(result: Dict) -> str:
    """Format duplicate tags results for display."""
    output = []
    output.append("ðŸ” Duplicate Tags Analysis")
    output.append("=" * 50)
    output.append("")
    
    if not result['success']:
        output.append(f"âŒ {result['message']}")
        return "\n".join(output)
    
    if result['duplicate_groups'] == 0:
        output.append("âœ… No duplicate tag sets found!")
        output.append(f"ðŸ“Š Analyzed {result['total_files']} files")
        return "\n".join(output)
    
    output.append(f"ðŸ“Š Analysis Summary:")
    output.append(f"   Total files: {result['total_files']}")
    output.append(f"   Duplicate groups: {result['duplicate_groups']}")
    output.append(f"   Files with duplicates: {result['duplicate_files_count']}")
    output.append("")
    
    output.append("ðŸ”„ Duplicate Groups:")
    for i, (tag_signature, files) in enumerate(result['duplicates'].items(), 1):
        tags_display = ", ".join(tag_signature) if tag_signature else "No tags"
        output.append(f"   Group {i}: [{tags_display}]")
        for j, file_path in enumerate(files, 1):
            filename = os.path.basename(file_path)
            output.append(f"      {j}. {filename}")
        output.append("")
    
    return "\n".join(output)


def format_orphans_result(result: Dict) -> str:
    """Format orphaned files results for display."""
    output = []
    output.append("ðŸšï¸  Orphaned Files Analysis")
    output.append("=" * 50)
    output.append("")
    
    if not result['success']:
        output.append(f"âŒ {result['message']}")
        return "\n".join(output)
    
    if result['orphan_count'] == 0:
        output.append("âœ… No orphaned files found!")
        output.append(f"ðŸ“Š All {result['total_files']} files have tags")
        return "\n".join(output)
    
    output.append(f"ðŸ“Š Analysis Summary:")
    output.append(f"   Total files: {result['total_files']}")
    output.append(f"   Orphaned files: {result['orphan_count']}")
    output.append(f"   Percentage orphaned: {(result['orphan_count'] / result['total_files'] * 100):.1f}%")
    output.append("")
    
    output.append("ðŸšï¸  Orphaned Files:")
    for i, file_path in enumerate(result['orphans'], 1):
        filename = os.path.basename(file_path)
        output.append(f"   {i}. {filename}")
        if i >= 20:  # Limit display
            remaining = len(result['orphans']) - 20
            output.append(f"   ... and {remaining} more files")
            break
    
    return "\n".join(output)


def format_similar_result(result: Dict) -> str:
    """Format similar files results for display."""
    output = []
    target_name = os.path.basename(result['target_file']) if result['target_file'] else "Unknown"
    output.append(f"ðŸ”— Similar Files to '{target_name}'")
    output.append("=" * 50)
    output.append("")
    
    if not result['success']:
        output.append(f"âŒ {result['message']}")
        return "\n".join(output)
    
    if not result['similar_files']:
        output.append("âŒ No similar files found!")
        output.append(f"ðŸ“Š Target file tags: {', '.join(result['target_tags'])}")
        return "\n".join(output)
    
    output.append(f"ðŸ“Š Target File: {target_name}")
    output.append(f"ðŸ·ï¸  Target Tags: {', '.join(result['target_tags'])}")
    output.append(f"ðŸŽ¯ Similarity Threshold: {result.get('similarity_threshold', 0.3):.1f}")
    output.append("")
    
    output.append(f"ðŸ”— Similar Files ({len(result['similar_files'])} found):")
    for i, similar in enumerate(result['similar_files'], 1):
        filename = os.path.basename(similar['file_path'])
        similarity_pct = similar['similarity'] * 100
        output.append(f"   {i}. {filename} ({similarity_pct:.1f}% similar)")
        
        if similar['common_tags']:
            output.append(f"      ðŸ¤ Common: {', '.join(similar['common_tags'])}")
        if similar['unique_tags']:
            output.append(f"      âœ¨ Unique: {', '.join(similar['unique_tags'])}")
        output.append("")
        
        if i >= 10:  # Limit display
            remaining = len(result['similar_files']) - 10
            output.append(f"   ... and {remaining} more files")
            break
    
    return "\n".join(output)
