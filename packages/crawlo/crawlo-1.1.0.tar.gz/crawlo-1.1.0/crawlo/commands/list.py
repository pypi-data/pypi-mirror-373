#!/usr/bin/python
# -*- coding: UTF-8 -*-
"""
# @Time    : 2025-08-31 22:33
# @Author  : crawl-coder
# @Desc    : å‘½ä»¤è¡Œå…¥å£ï¼šcrawlo listï¼Œç”¨äºåˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„çˆ¬è™«
"""

import sys
import configparser
from pathlib import Path
from importlib import import_module

from crawlo.crawler import CrawlerProcess
from crawlo.utils.log import get_logger


logger = get_logger(__name__)


def get_project_root():
    """
    è‡ªåŠ¨æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•ï¼šä»å½“å‰ç›®å½•å‘ä¸ŠæŸ¥æ‰¾ crawlo.cfg
    æ‰¾åˆ°åè¿”å›è¯¥ç›®å½•è·¯å¾„ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼Œæœ€å¤šå‘ä¸ŠæŸ¥æ‰¾10å±‚ã€‚
    """
    current = Path.cwd()

    for _ in range(10):
        cfg = current / "crawlo.cfg"
        if cfg.exists():
            return str(current)

        # åˆ°è¾¾æ–‡ä»¶ç³»ç»Ÿæ ¹ç›®å½•
        if current == current.parent:
            break
        current = current.parent

    return None  # æœªæ‰¾åˆ°


def main(args):
    """
    ä¸»å‡½æ•°ï¼šåˆ—å‡ºæ‰€æœ‰å¯ç”¨çˆ¬è™«
    ç”¨æ³•: crawlo list
    """
    if args:
        print("âŒ Usage: crawlo list")
        return 1

    try:
        # 1. æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•
        project_root = get_project_root()
        if not project_root:
            print("âŒ Error: Cannot find 'crawlo.cfg'. Are you in a crawlo project?")
            print("ğŸ’¡ Tip: Run this command inside your project directory, or create a project with 'crawlo startproject'.")
            return 1

        project_root_path = Path(project_root)
        project_root_str = str(project_root_path)

        # 2. å°†é¡¹ç›®æ ¹åŠ å…¥ Python è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥é¡¹ç›®æ¨¡å—
        if project_root_str not in sys.path:
            sys.path.insert(0, project_root_str)

        # 3. è¯»å– crawlo.cfg è·å– settings æ¨¡å—
        cfg_file = project_root_path / "crawlo.cfg"
        config = configparser.ConfigParser()
        config.read(cfg_file, encoding="utf-8")

        if not config.has_section("settings") or not config.has_option("settings", "default"):
            print("âŒ Error: Invalid crawlo.cfg â€” missing [settings] or 'default' option.")
            return 1

        settings_module = config.get("settings", "default")
        project_package = settings_module.split(".")[0]

        # 4. ç¡®ä¿é¡¹ç›®åŒ…å¯å¯¼å…¥ï¼ˆå¯é€‰ï¼šå°è¯•å¯¼å…¥ä»¥è§¦å‘å¼‚å¸¸ï¼‰
        try:
            import_module(project_package)
        except ImportError as e:
            print(f"âŒ Failed to import project package '{project_package}': {e}")
            return 1

        # 5. åˆå§‹åŒ– CrawlerProcess å¹¶åŠ è½½çˆ¬è™«æ¨¡å—
        spider_modules = [f"{project_package}.spiders"]
        process = CrawlerProcess(spider_modules=spider_modules)

        # 6. è·å–æ‰€æœ‰çˆ¬è™«åç§°
        spider_names = process.get_spider_names()
        if not spider_names:
            print("ğŸ“­ No spiders found in 'spiders/' directory.")
            print("ğŸ’¡ Make sure:")
            print("   â€¢ Spider classes inherit from `crawlo.spider.Spider`")
            print("   â€¢ Each spider has a `name` attribute")
            print("   â€¢ Spiders are imported in `spiders/__init__.py` (if using package)")
            return 1

        # 7. è¾“å‡ºçˆ¬è™«åˆ—è¡¨
        print(f"ğŸ“‹ Found {len(spider_names)} spider(s):")
        print("-" * 60)
        for name in sorted(spider_names):
            spider_cls = process.get_spider_class(name)
            module_name = spider_cls.__module__.replace(f"{project_package}.", "")
            print(f"ğŸ•·ï¸  {name:<20} {spider_cls.__name__:<25} ({module_name})")
        print("-" * 60)
        return 0

    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        logger.exception("Exception during 'crawlo list'")
        return 1


if __name__ == "__main__":
    """
    æ”¯æŒç›´æ¥è¿è¡Œï¼š
        python -m crawlo.commands.list
    """
    sys.exit(main(sys.argv[1:]))