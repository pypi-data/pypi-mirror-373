#!/usr/bin/python
# -*- coding:UTF-8 -*-
"""
# @Time    :    2025-08-31 22:33
# @Author  :   crawl-coder
# @Desc    :   å‘½ä»¤è¡Œå…¥å£ï¼šcrawlo listï¼Œç”¨äºåˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„çˆ¬è™«
"""
import sys
import configparser

from crawlo.crawler import CrawlerProcess
from crawlo.utils.project import get_settings
from crawlo.utils.log import get_logger


logger = get_logger(__name__)


def main(args):
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çˆ¬è™«
    ç”¨æ³•: crawlo list
    """
    if args:
        print("Usage: crawlo list")
        return 1

    try:
        # 1. è·å–é¡¹ç›®æ ¹ç›®å½•
        project_root = get_settings().get('PROJECT_ROOT')
        if not project_root:
            print("âŒ Error: Cannot determine project root.")
            return 1

        # å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.path
        project_root_str = str(project_root)
        if project_root_str not in sys.path:
            sys.path.insert(0, project_root_str)

        # 2. è¯»å– crawlo.cfg è·å–é¡¹ç›®åŒ…å
        cfg_file = project_root / 'crawlo.cfg'
        if not cfg_file.exists():
            print(f"âŒ Error: crawlo.cfg not found in {project_root}")
            return 1

        config = configparser.ConfigParser()
        config.read(cfg_file, encoding='utf-8')

        if not config.has_section('settings') or not config.has_option('settings', 'default'):
            print("âŒ Error: Missing [settings] section or 'default' option in crawlo.cfg")
            return 1

        settings_module = config.get('settings', 'default')
        project_package = settings_module.split('.')[0]

        # 3. åˆ›å»º CrawlerProcess å¹¶è‡ªåŠ¨å‘ç°çˆ¬è™«
        spider_modules = [f"{project_package}.spiders"]
        process = CrawlerProcess(spider_modules=spider_modules)

        # 4. è·å–æ‰€æœ‰çˆ¬è™«ä¿¡æ¯
        spider_names = process.get_spider_names()
        if not spider_names:
            print("ğŸ“­ No spiders found.")
            print("ğŸ’¡ Make sure:")
            print("   - Your spider classes inherit from `Spider`")
            print("   - They define a `name` attribute")
            print("   - The modules are imported (e.g. via __init__.py)")
            return 1

        # 5. è¾“å‡ºçˆ¬è™«åˆ—è¡¨
        print(f"ğŸ“‹ Found {len(spider_names)} spider(s):")
        print("-" * 50)
        for name in sorted(spider_names):
            cls = process.get_spider_class(name)
            module = cls.__module__.replace(project_package + ".", "")  # ç®€åŒ–æ¨¡å—å
            print(f"ğŸ•·ï¸  {name:<20} {cls.__name__:<25} ({module})")
        print("-" * 50)
        return 0

    except Exception as e:
        print(f"âŒ Error listing spiders: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    """
    å…è®¸ç›´æ¥è¿è¡Œï¼š
        python -m crawlo.commands.list
    """
    sys.exit(main(sys.argv[1:]))