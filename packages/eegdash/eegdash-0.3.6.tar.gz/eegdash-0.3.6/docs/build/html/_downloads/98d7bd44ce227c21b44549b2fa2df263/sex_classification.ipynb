{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab:\n# `pip install eegdash`\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sex Classification Tutorial\n\nThe code below provides an example of using the *EEGDash* library in combination with PyTorch to develop a deep learning model for detecting sex in a collection of 136 subjects.\n\n1. **Data Retrieval Using EEGDash**: An instance of *EEGDashDataset* is created to search and retrieve resting state data for 136 subjects (dataset ds005505). At this step, only the metadata is transferred.\n\n2. **Data Preprocessing Using BrainDecode**: This process preprocesses EEG data using Braindecode by selecting specific channels, resampling, filtering, and extracting 2-second epochs. This takes about 2 minutes.\n\n3. **Creating a train and testing sets**: The dataset is split into training (80%) and testing (20%) sets with balanced labels--making sure also that we have as many males as females--converted into PyTorch tensors, and wrapped in DataLoader objects for efficient mini-batch training.\n\n4. **Model Definition**: The model is a custom convolutional neural network with 24 input channels (EEG channels), 2 output classes (male and female).\n\n5. **Model Training and Evaluation Process**: This section trains the neural network, normalizes input data, computes cross-entropy loss, updates model parameters, and evaluates classification accuracy over six epochs. This takes less than 10 seconds to a couple of minutes, depending on the device you use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Retrieval Using EEGDash\n\nFirst we find one resting state dataset for a collection of subject. The dataset ds005505 contains 136 subjects with both male and female participants.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "query = {\n    \"dataset\": \"ds005505\",\n    \"task\": \"RestingState\",\n    \"subject\": {\n        \"$in\": [\n            \"NDARCA153NKE\",\n            \"NDARXT792GY8\",\n            \"NDARVU683CTN\",\n            \"NDARJM828PAL\",\n            \"NDARBX121UM9\",\n            \"NDARLF616PBU\",\n            \"NDARPL306LC6\",\n            \"NDARAW320CGR\",\n            \"NDARPX219TW0\",\n            \"NDARWA513WM2\",\n        ]\n    },\n}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from eegdash import EEGDashDataset\n\nds_sexdata = EEGDashDataset(\n    query=query,\n    target_name=\"sex\",\n    cache_dir=X\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing Using Braindecode\n\n[BrainDecode](https://braindecode.org/stable/install/install.html) is a specialized library for preprocessing EEG and MEG data.\n\nWe apply three preprocessing steps in Braindecode:\n1.\t**Selection** of 24 specific EEG channels from the original 128.\n2.\t**Resampling** the EEG data to a frequency of 128 Hz.\n3.\t**Filtering** the EEG signals to retain frequencies between 1 Hz and 55 Hz.\n\nWhen calling the **preprocess** function, the data is retrieved from the remote repository.\n\nFinally, we use **create_windows_from_events** to extract 2-second epochs from the data. These epochs serve as the dataset samples.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.preprocessing import (\n    Preprocessor,\n    create_fixed_length_windows,\n    preprocess,\n)\n\n# Alternatively, if you want to include this as a preprocessing step in a Braindecode pipeline:\npreprocessors = [\n    Preprocessor(\n        \"pick_channels\",\n        ch_names=[\n            \"E22\",\n            \"E9\",\n            \"E33\",\n            \"E24\",\n            \"E11\",\n            \"E124\",\n            \"E122\",\n            \"E29\",\n            \"E6\",\n            \"E111\",\n            \"E45\",\n            \"E36\",\n            \"E104\",\n            \"E108\",\n            \"E42\",\n            \"E55\",\n            \"E93\",\n            \"E58\",\n            \"E52\",\n            \"E62\",\n            \"E92\",\n            \"E96\",\n            \"E70\",\n            \"Cz\",\n        ],\n    ),\n    Preprocessor(\"resample\", sfreq=128),\n    Preprocessor(\"filter\", l_freq=1, h_freq=55),\n]\npreprocess(\n    ds_sexdata, preprocessors, n_jobs=-1\n)  # , save_dir='xxxx'' will save and set preload to false\n\n# extract windows and save to disk\nwindows_ds = create_fixed_length_windows(\n    ds_sexdata,\n    start_offset_samples=0,\n    stop_offset_samples=None,\n    window_size_samples=256,\n    window_stride_samples=256,\n    drop_last_window=True,\n    preload=False,\n)\nos.makedirs(\"data/hbn_preprocessed_restingstate\", exist_ok=True)\nwindows_ds.save(\"data/hbn_preprocessed_restingstate\", overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting a Single Channel for One Sample\n\nIt\u2019s always a good practice to verify that the data has been properly loaded and processed. Here, we plot a single channel from one sample to ensure the signal is present and looks as expected.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(windows_ds[150][0][0, :].transpose())  # first channel of first epoch\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load pre-saved data\n\nIf you have run the previous steps before, the data should be saved and may be reloaded here. If you are simply running this notebook for the first time, there is no need to reload the data, and this step may be skipped. However, it is quick, so you might as well execute the cell; it will have no consequences and will allow you to check that the data was saved properly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.datautil import load_concat_dataset\n\nprint(\"Loading data from disk\")\nwindows_ds = load_concat_dataset(\n    path=\"data/hbn_preprocessed_restingstate\", preload=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a Training and Test Set\n\nThe code below creates a training and test set. We first split the data using the **train_test_split** function and then create a **TensorDataset** for both sets.\n\n1. **Set Random Seed** \u2013 The random seed is fixed using `torch.manual_seed(random_state)` to ensure reproducibility in dataset splitting and model training.\n2. **Get Balanced Indices for Male and Female Subjects** \u2013 We ensure a 50/50 split of male and female subjects in both the training and test sets. Additionally, we prevent subject leakage, meaning the same subjects do not appear in both sets. The dataset is split into training (90%) and testing (10%) subsets using `train_test_split()`, ensuring balanced stratification based on gender.\n3. **Convert Data to PyTorch Tensors** \u2013 The selected training and testing samples are converted into `FloatTensor` for input features and `LongTensor` for labels, making them compatible with PyTorch models.\n4. **Create DataLoaders** \u2013 The datasets are wrapped in PyTorch `DataLoader` objects with a batch size of 100, allowing efficient mini-batch training and shuffling. Although there are only 136 subjects, the dataset contains more than 10,000 2-second samples.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.datasets import BaseConcatDataset\n\n# random seed for reproducibility\nrandom_state = 0\nnp.random.seed(random_state)\ntorch.manual_seed(random_state)\n\n# Get balanced indices for male and female subjects and create a balanced dataset\nmale_subjects = windows_ds.description[\"subject\"][windows_ds.description[\"sex\"] == \"M\"]\nfemale_subjects = windows_ds.description[\"subject\"][\n    windows_ds.description[\"sex\"] == \"F\"\n]\nn_samples = min(len(male_subjects), len(female_subjects))\nbalanced_subjects = np.concatenate(\n    [male_subjects[:n_samples], female_subjects[:n_samples]]\n)\nbalanced_gender = [\"M\"] * n_samples + [\"F\"] * n_samples\ntrain_subj, val_subj, train_gender, val_gender = train_test_split(\n    balanced_subjects,\n    balanced_gender,\n    train_size=0.9,\n    stratify=balanced_gender,\n    random_state=random_state,\n)\n\n# Create datasets\ntrain_ds = BaseConcatDataset(\n    [ds for ds in windows_ds.datasets if ds.description.subject in train_subj]\n)\nval_ds = BaseConcatDataset(\n    [ds for ds in windows_ds.datasets if ds.description.subject in val_subj]\n)\n\n# Create dataloaders\ntrain_loader = DataLoader(train_ds, batch_size=100, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=100, shuffle=True)\n\n# Check the balance of the dataset\nassert len(balanced_subjects) == len(balanced_gender)\nprint(f\"Number of subjects in balanced dataset: {len(balanced_subjects)}\")\nprint(\n    f\"Gender distribution in balanced dataset: {np.unique(balanced_gender, return_counts=True)}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Check labels\n\nIt is good practice to verify the labels and ensure the random seed is functioning correctly. If all labels are 'M' (male) or 'F' (female), it could indicate an issue with data loading or stratification, requiring further investigation.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "get the first batch to check the labels\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataiter = iter(train_loader)\nfirst_item, label, sz = dataiter.__next__()\nnp.array(label).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create model\n\nThe model is a custom convolutional neural network with 24 input channels (EEG channels), 2 output classes (male vs. female), and an input window size of 256 samples (2 seconds of EEG data). See the reference below for more information.\n\n[1] Truong, D., Milham, M., Makeig, S., & Delorme, A. (2021). Deep Convolutional Neural Network Applied to Electroencephalography: Raw Data vs Spectral Features. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2021, 1039\u20131042. https://doi.org/10.1109/EMBC46164.2021.9630708\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "create model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary\n\nmodel = nn.Sequential(\n    # First VGG block\n    nn.Conv2d(1, 16, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.Conv2d(16, 16, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    # Second VGG block\n    nn.Conv2d(16, 32, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.Conv2d(32, 32, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    # Third VGG block\n    nn.Conv2d(32, 64, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    # Flatten and FC layers\n    nn.Flatten(),\n    nn.Linear(64 * 3 * 32, 1024),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(1024, 1024),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(1024, 2),\n)\n\nprint(summary(model, input_size=(1, 1, 24, 256)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training and Evaluation Process\n\nThis section trains the neural network using the Adamax optimizer, normalizes input data, computes cross-entropy loss, updates model parameters, and tracks accuracy across six epochs.\n\n1. **Set Up Optimizer and Learning Rate Scheduler** \u2013 The `Adamax` optimizer initializes with a learning rate of 0.002 and weight decay of 0.001 for regularization.\n\n2. **Allocate Model to Device** \u2013 The model moves to the specified device (CPU, GPU, or MPS for Mac silicon) to optimize computation efficiency.\n\n3. **Normalize Input Data** \u2013 The `normalize_data` function standardizes input data by subtracting the mean and dividing by the standard deviation along the time dimension before transferring it to the appropriate device.\n\n4. **Train the Model for Two Epochs** \u2013 The training loop iterates through data batches with the model in training mode. It normalizes inputs, computes predictions, calculates cross-entropy loss, performs backpropagation, updates model parameters, and steps the learning rate scheduler. It tracks correct predictions to compute accuracy.\n\n5. **Evaluate on Test Data** \u2013 After each epoch, the model runs in evaluation mode on the test set. It computes predictions on normalized data and calculates test accuracy by comparing outputs with actual labels.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n\noptimizer = torch.optim.Adamax(model.parameters(), lr=0.002, weight_decay=0.001)\ndevice = torch.device(\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nmodel.to(device=device)\n\n\ndef normalize_data(x):\n    x = x.reshape(x.shape[0], 1, 24, 256)\n    mean = x.mean(dim=3, keepdim=True)\n    std = x.std(dim=3, keepdim=True) + 1e-7  # add small epsilon for numerical stability\n    x = (x - mean) / std\n    x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n    return x\n\n\n# dictionary of genders for converting sample labels to numerical values\ngender_dict = {\"M\": 0, \"F\": 1}\n\nepochs = 2\nfor e in range(epochs):\n    # training\n    correct_train = 0\n    for t, (x, y, sz) in enumerate(train_loader):\n        model.train()  # put model to training mode\n        scores = model(normalize_data(x))\n        _, preds = scores.max(1)\n        y = torch.tensor(\n            [gender_dict[gender] for gender in y], device=device, dtype=torch.long\n        )\n        correct_train += (preds == y).sum() / len(train_ds)\n\n        # Calculates the cross-entropy loss and performs backpropagation\n        loss = F.cross_entropy(scores, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if t % 50 == 0:\n            print(\"Epoch %d, Iteration %d, loss = %.4f\" % (e, t, loss.item()))\n\n    # validation\n    correct_test = 0\n    for t, (x, y, sz) in enumerate(val_loader):\n        model.eval()  # put model to testing mode\n        scores = model(normalize_data(x))\n        _, preds = scores.max(1)\n        y = torch.tensor(\n            [gender_dict[gender] for gender in y], device=device, dtype=torch.long\n        )\n        correct_test += (preds == y).sum() / len(val_ds)\n\n    print(\n        f\"Epoch {e}, Train accuracy: {correct_train:.2f}, Test accuracy: {correct_test:.2f}\\n\"\n    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}