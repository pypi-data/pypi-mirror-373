{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab:\n# `pip install eegdash`\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Challenge 1: Transfer Learning task\n\n# # Tutorial for Contrast-Change Detection (CCD) Task - EEG 2025 Competition\n# \n# This tutorial demonstrates how to load EEG data for the contrast-change detection (CCD) task from the EEG 2025 competition, extract epochs, and calculate response times and correctness information. We'll use `EEGDash` and `braindecode`.\n# This tutorial does NOT address the use of `SuS` task for challenge 1.\n# \n# ## Key Features:\n# - Load data for subject `NDARAG340ERT` from dataset `ds005507` (This data is available in the R3 minsets as well)\n# - Extract stimulus events (`left_target`, `right_target`) and calculate response times and correctness from button presses and feedback\n# - Epoch the data based on contrast trial start events\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport pandas as pd\nimport numpy as np\nimport mne\nimport matplotlib.pyplot as plt\nfrom eegdash import EEGDashDataset\nfrom braindecode.preprocessing import create_windows_from_events\nimport warnings\nfrom IPython.display import display\n\n# Suppress warnings for cleaner output\nwarnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Loading the Data\n\nWe'll load the data for subject `NDARAG340ERT` from the `ds005507` dataset. `EEGDashDataset` will handle the download and preprocessing automatically.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cache_dir = \"~/.eegdash_cache\"  # keep the cache in the home directory\ndataset_name = \"ds005507\"\ndataset = EEGDashDataset({\n    \"dataset\": dataset_name, \n    \"subject\": \"NDARAG340ERT\",\n    \"task\": \"contrastChangeDetection\", \"run\": 1,\n})\n\n# Get the raw EEG data\nraw = dataset.datasets[0].raw\nprint(f\"Dataset loaded successfully!\")\nprint(f\"Sampling frequency: {raw.info['sfreq']} Hz\")\nprint(f\"Duration: {raw.times[-1]:.1f} seconds\")\nprint(f\"Number of channels: {len(raw.ch_names)}\")\nprint(f\"Channel names: {raw.ch_names[:10]}...\")  # Show first 10 channels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Reading BIDS Events File with Additional Columns\n\nThe power of BIDS-formatted datasets is that they include rich metadata in standardized formats. The events.tsv file contains additional columns like `feedback` that aren't available through MNE's annotation system. Let's read the BIDS events file directly using pandas to access ALL the columns: \n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The key insight: We can read the BIDS events.tsv file directly using pandas!\nThis gives us access to ALL columns including the crucial 'feedback' column\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get the events file path from the EEGDashDataset\nbids_args = dataset.datasets[0].get_raw_bids_args()\nevents_file = os.path.join(cache_dir, dataset_name, f\"sub-{bids_args['subject']}/eeg/sub-{bids_args['subject']}_task-{bids_args['task']}_run-{bids_args['run']}_events.tsv\")\n\n# Read the events.tsv file using pandas\nevents_df = pd.read_csv(events_file, sep='\\t')\n\nprint(\"BIDS Events File Structure:\")\nprint(f\"Shape: {events_df.shape}\")\nprint(f\"Columns: {list(events_df.columns)}\")\nprint(f\"\\nFirst 10 rows:\")\ndisplay(events_df.head(10))\n\nprint(f\"\\nFeedback column unique values:\")\nprint(events_df['feedback'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Calculate Response Times and Correctness from BIDS Events\n\nNow we'll calculate response times and correctness by matching stimulus events with their corresponding button presses and feedback. This approach uses the temporal sequence of events in the BIDS file.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def calculate_behavioral_metrics_from_bids(events_df):\n    \"\"\"\n        Calculate response times and correctness from BIDS events DataFrame.\n        \n        This function matches stimulus events with subsequent button presses and feedback.\n    \"\"\"\n    # Get stimulus events\n    stimuli = events_df[events_df['value'].isin(['left_target', 'right_target'])].copy()\n    \n    # Get button press events\n    responses = events_df[events_df['value'].isin(['left_buttonPress', 'right_buttonPress'])]\n\n    # Get contrast trial start events\n    contrast_trials = events_df[events_df['value'] == 'contrastTrial_start']\n    \n    # Initialize columns\n    stimuli['response_time'] = np.nan\n    stimuli['correct'] = None\n    stimuli['response_type'] = None\n    stimuli['contrast_trial_start'] = None\n    \n    for idx, stimulus in stimuli.iterrows():\n        # Find the next button press after this stimulus, but make sure it is before next 'contrastTrial_start'\n        next_contrast_start = contrast_trials[contrast_trials['onset'] > stimulus['onset']].iloc[0]['onset']\n        future_responses = responses[\n            (responses['onset'] > stimulus['onset']) & \n            (responses['onset'] < next_contrast_start)\n        ]\n        stimuli.loc[idx, 'contrast_trial_start'] = contrast_trials[contrast_trials['onset'] < stimulus['onset']].iloc[-1]['onset']\n        if len(future_responses) > 0:\n            # Get the first (closest) response\n            next_response = future_responses.iloc[0]\n            # Calculate response time\n            response_time = next_response['onset'] - stimulus['onset']\n            stimuli.loc[idx, 'response_time'] = response_time\n            stimuli.loc[idx, 'response_type'] = next_response['value']\n            # We can use the feedback column directly!\n            # Find feedback that corresponds to the button press\n            if len(next_response['feedback']) > 0:\n                feedback = next_response['feedback']\n                # Map feedback to correctness\n                if feedback == 'smiley_face':\n                    stimuli.loc[idx, 'correct'] = True\n                elif feedback == 'sad_face':\n                    stimuli.loc[idx, 'correct'] = False\n        # Note: 'non_target' feedback might indicate a different type of trial\n    return stimuli\n\n\n# Calculate behavioral metrics\nstimulus_metadata = calculate_behavioral_metrics_from_bids(events_df)\nprint(f\"Behavioral Analysis Results:\")\nprint(f\"Total stimulus events: {len(stimulus_metadata)}\")\nprint(f\"Events with responses: {stimulus_metadata['response_time'].notna().sum()}\")\nprint(f\"Correct responses: {stimulus_metadata['correct'].sum()}\")\nprint(f\"Incorrect responses: {stimulus_metadata['response_time'].notna().sum()-stimulus_metadata['correct'].sum()}\")\nprint(f\"Response time statistics:\")\nprint(stimulus_metadata['response_time'].describe())\nprint(f\"First few trials with calculated metrics:\")\ndisplay(stimulus_metadata[['onset', 'value', 'response_time', 'correct', 'response_type', 'contrast_trial_start']].head(8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Creating Epochs with Braindecode and BIDS Metadata\n\nNow we'll create epochs using `braindecode`'s `create_windows_from_events`. According to the EEG 2025 challenge requirements, epochs should start from **contrast trial starts** and be **2 seconds long**. This epoching approach ensures we capture:\n\n- The entire trial from contrast trial start (t=0)\n- The stimulus presentation (usually ~2.8 seconds after trial start)\n- The response window (usually within 2 seconds of stimulus)\n- Full behavioral context for each trial\n\nWe'll use our enhanced metadata that includes the behavioral information extracted from the BIDS events file.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create epochs from contrast trial starts with 2-second duration as per EEG 2025 challenge\nIMPORTANT: Only epoch trials that have valid behavioral data (stimulus + response)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# First, get all contrast trial start events from the BIDS events\nall_contrast_trials = events_df[events_df['value'] == 'contrastTrial_start'].copy()\nprint(f\"Found {len(all_contrast_trials)} total contrast trial start events\")\n\n# Filter to only include contrast trials that have valid behavioral data\n# Get the contrast trial start times that correspond to trials with valid stimulus/response data\nvalid_contrast_times = stimulus_metadata['contrast_trial_start'].dropna().unique()\nprint(f\"Found {len(valid_contrast_times)} contrast trials with valid behavioral data\")\n\n# Filter contrast trial events to only those with valid behavioral data\nvalid_contrast_trials = all_contrast_trials[\n    all_contrast_trials['onset'].isin(valid_contrast_times)\n].copy()\n\nprint(f\"Epoching {len(valid_contrast_trials)} contrast trials (only those with behavioral data)\")\nprint(f\"Excluded {len(all_contrast_trials) - len(valid_contrast_trials)} trials without behavioral data\")\n\n# Convert valid contrast trial start onset times to samples for MNE\nvalid_contrast_trials['sample_mne'] = (valid_contrast_trials['onset'] * raw.info['sfreq']).astype(int)\n\n# Create new events array with valid contrast trial starts only\n# Format: [sample, previous_sample, event_id]\nnew_events = np.column_stack([\n    valid_contrast_trials['sample_mne'].values,\n    np.zeros(len(valid_contrast_trials), dtype=int),\n    np.full(len(valid_contrast_trials), 99, dtype=int)  # Use event_id 99 for contrast_trial_start\n])\n\n# Create new annotations from these events to replace the original annotations\n# This is the key step - we need to replace the annotations in the raw object\nannot_from_events = mne.annotations_from_events(\n    events=new_events,\n    event_desc={99: \"contrast_trial_start\"},\n    sfreq=raw.info['sfreq'],\n    orig_time=raw.info['meas_date']\n)\n\n# Replace the annotations in the raw object\nprint(f\"Original annotations: {len(raw.annotations)} events\")\nraw.set_annotations(annot_from_events)\nprint(f\"New annotations: {len(raw.annotations)} contrast trial start events (valid trials only)\")\n\n# Verify the new annotations\nevents_check, event_id_check = mne.events_from_annotations(raw)\nprint(f\"Events from new annotations: {len(events_check)} events\")\nprint(f\"Event ID mapping: {event_id_check}\")\n\n# Now use braindecode's create_windows_from_events to create 2-second epochs\n# Calculate the window size in samples (2 seconds * sampling rate)\nwindow_size_samples = int(2.0 * raw.info['sfreq'])  # 2 seconds in samples\nprint(f\"Window size: {window_size_samples} samples ({window_size_samples / raw.info['sfreq']:.1f} seconds)\")\n\n# Create 2-second epochs from valid contrast trial starts only\nwindows_dataset = create_windows_from_events(\n    dataset,  # The EEGDashDataset\n    trial_start_offset_samples=0,  # Start from the contrast trial start (no offset)\n    trial_stop_offset_samples=window_size_samples,  # End 2 seconds later\n    preload=True\n)\n\nprint(f\"Created {len(windows_dataset)} epochs with behavioral data\")\nprint(f\"All epochs should now have valid stimulus and response information\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n- The epoched data is now ready under `windows_dataset`.\n- The response time is under `stimulus_metadata['response_time']`. (required for challenge 1 regression task)\n- The correctness is under `stimulus_metadata['correct']`. (required for challenge 1 classification task)\n- The stimulus type (left or right) is under `stimulus_metadata['value']`. (might be useful)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}