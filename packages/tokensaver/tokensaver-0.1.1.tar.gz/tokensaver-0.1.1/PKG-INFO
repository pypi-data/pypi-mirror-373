Metadata-Version: 2.4
Name: tokensaver
Version: 0.1.1
Summary: A lightweight pre-processor to minimize LLM token usage
Home-page: https://github.com/yourusername/tokensaver
Author: Abhijit Chatterjee
Author-email: abhijit@gritt.cloud
License: MIT
Project-URL: Homepage, https://github.com/grittcloud/tokensaver
Project-URL: HuggingFace Space, https://huggingface.co/spaces/grittai/tokensaver
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Dynamic: license-file

# ğŸ’» TokenSaver  

[![PyPI version](https://badge.fury.io/py/tokensaver.svg)](https://pypi.org/project/tokensaver/)  
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)  
[![Hugging Face Space](https://img.shields.io/badge/ğŸ¤—%20HuggingFace-TokenSaver-orange)](https://huggingface.co/spaces/grittai/tokensaver)  

---

## ğŸ“– Overview  

**TokenSaver** is a lightweight Python library + CLI tool to **minimize LLM token usage** before sending prompts to GPT, Claude, Mistral, etc.  

Every unnecessary **newline, space, or repeated entity** increases your LLM bill. TokenSaver preprocesses text and JSON to make them as compact as possible â€” **cutting costs without losing meaning**.  

---

## âœ¨ Features  

- ğŸ§¹ **Text Cleaning** â†’ collapse whitespace, normalize newlines  
- ğŸ“¦ **JSON Minify** â†’ compact JSON into a single line  
- ğŸ· **Entity Compression** â†’ replace long repeated names/entities with short placeholders  

---

## ğŸ“¦ Installation  

```bash
pip install tokensaver
```

---

## ğŸš€ Usage  

### 1. Python API  

```python
from tokensaver import clean_text, minify_json, compress_entities

# --- Text Cleaning ---
messy = "Hello     World   \n\nThis   is   a test.   "
print(clean_text(messy))
# -> "Hello World\nThis is a test."

# --- JSON Minify ---
pretty_json = """{
  "name": "John Doe",
  "age": 30,
  "skills": [
    "Python",
    "AI"
  ]
}"""

print(minify_json(pretty_json))
# -> {
#   'result': {'name': 'John Doe', 'age': 30, 'skills': ['Python', 'AI']},
#   'minified': '{"name":"John Doe","age":30,"skills":["Python","AI"]}'
# }

# --- Entity Compression ---
entity_text = """The International Business Machines Corporation 
makes enterprise software. International Business Machines Corporation 
is also known as IBM."""

print(compress_entities(entity_text))
# -> {
#   'compressed': 'E1 makes enterprise software. E1 is also known as IBM.',
#   'mapping': {'International Business Machines Corporation': 'E1'}
# }
```

---

### 2. CLI Usage  

When installed, TokenSaver also provides a **command-line tool**:

```bash
# Clean messy text
tokensaver clean "Hello     World"
# -> "Hello World"

# Minify JSON
tokensaver json '{"name":"John","age":30}'
# -> {"result": {"name": "John", "age": 30}, "minified": "{\"name\":\"John\",\"age\":30}"}

# Compress repeated entities
tokensaver entities "International Business Machines Corporation makes software. International Business Machines Corporation sells software."
# -> {"compressed": "E1 makes software. E1 sells software.", "mapping": {"International Business Machines Corporation": "E1"}}
```

---

## ğŸ§‘â€ğŸ’» Why TokenSaver?  

Every token costs ğŸ’°. Formatting intended for **humans** (pretty-printed JSON, repeated names, redundant whitespace) doesnâ€™t help AI models â€” but **does** increase token count.  

**TokenSaver** helps you:  
- Minimize cost for API calls  
- Preprocess logs, transcripts, or JSON before sending to LLMs  
- Keep your pipelines fast & efficient  

---

## ğŸ”— Links  

- ğŸ¤— [Hugging Face Demo](https://huggingface.co/spaces/grittai/tokensaver)  
- ğŸ“¦ [PyPI Package](https://pypi.org/project/tokensaver/)  
- ğŸ’» [Source Code](https://github.com/grittcloud/tokensaver)  

---

## ğŸ“ License  

This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.  
