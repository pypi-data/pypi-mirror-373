Metadata-Version: 2.4
Name: lexa-sdk
Version: 1.0.0
Summary: Python SDK for Lexa AI - OpenAI-compatible interface for Lexa's language models
Project-URL: Homepage, https://lexa.chat
Project-URL: Repository, https://github.com/Robi-Labs/lexa-python-sdk
Project-URL: Documentation, https://docs.lexa.chat/
Project-URL: Bug Tracker, https://github.com/Robi-Labs/lexa-python-sdk/issues
Author-email: Robi Labs <lexa@robiai.com>
License: MIT
Keywords: ai,api,chat,completion,lexa,llm,ml
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Requires-Dist: httpx>=0.24.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: requests>=2.25.0
Requires-Dist: typing-extensions>=4.0.0
Description-Content-Type: text/markdown

# Lexa Python SDK

A Python SDK for Lexa AI that provides an OpenAI-compatible interface for easy integration with Lexa's language models.

## Features

- üîó **OpenAI-Compatible**: Drop-in replacement for OpenAI SDK
- üöÄ **Async Support**: Full async/await support for high-performance applications
- üì¶ **Type Safety**: Comprehensive type hints and validation
- üîÑ **Streaming**: Real-time streaming responses
- üõ°Ô∏è **Error Handling**: Robust error handling with custom exceptions
- üìä **Multiple Models**: Support for all Lexa models (lexa-mml, lexa-x1, lexa-rho)

## Installation

```bash
pip install lexa-sdk
```

## Quick Start

```python
from lexa_sdk import Lexa

# Initialize the client
client = Lexa(api_key="your-api-key")

# Simple chat completion
response = client.chat.completions.create(
    model="lexa-mml",
    messages=[
        {"role": "user", "content": "Hello! Tell me a joke."}
    ],
    temperature=0.7,
    max_tokens=100
)

print(response["choices"][0]["message"]["content"])
```

## Available Models

| Model | Description | Context Window | Max Tokens |
|-------|-------------|----------------|------------|
| `lexa-mml` | Multimodal model with vision capabilities | 8,192 | 4,096 |
| `lexa-x1` | Fast, lightweight text-based model | 4,096 | 2,048 |
| `lexa-rho` | Reasoning model with enhanced capabilities | 16,384 | 8,192 |

## Documentation

For complete documentation, examples, and API reference, visit [docs.lexa.chat](https://docs.lexa.chat/).

## License

This project is licensed under the MIT License.
