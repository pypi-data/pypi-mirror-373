#!/usr/bin/env python3
"""
SAGEé«˜æ€§èƒ½é˜Ÿåˆ—ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºåœ¨SAGEç³»ç»Ÿä¸­å¦‚ä½•ä½¿ç”¨mmap_queueè¿›è¡Œé«˜æ•ˆçš„è¿›ç¨‹é—´é€šä¿¡
"""

import sys
import os
import time
import multiprocessing

# æ·»åŠ sage.common.utilsåˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from sage.extensions.sage_queue import SageQueue, SageQueueRef, destroy_queue


class SAGEDataProcessor:
    """SAGEæ•°æ®å¤„ç†ç»„ä»¶ç¤ºä¾‹"""
    
    def __init__(self, processor_id: str):
        self.processor_id = processor_id
        self.processed_count = 0
    
    def process_batch(self, input_queue_name: str, output_queue_name: str, batch_size: int):
        """å¤„ç†ä¸€æ‰¹æ•°æ®"""
        print(f"[{self.processor_id}] å¼€å§‹å¤„ç†æ‰¹æ¬¡ï¼Œå¤§å°: {batch_size}")
        
        input_queue = SageQueue(input_queue_name)
        output_queue = SageQueue(output_queue_name)
        
        try:
            for i in range(batch_size):
                # ä»è¾“å…¥é˜Ÿåˆ—è¯»å–åŸå§‹æ•°æ®
                raw_data = input_queue.get(timeout=5.0)
                
                # æ¨¡æ‹ŸSAGEæ•°æ®å¤„ç†
                processed_data = {
                    'processor_id': self.processor_id,
                    'original_data': raw_data,
                    'processed_timestamp': time.time(),
                    'processing_results': {
                        'feature_vector': [x * 2 for x in raw_data.get('values', [])],
                        'metadata': f"Processed by SAGE component {self.processor_id}",
                        'confidence': 0.95
                    }
                }
                
                # å†™å…¥è¾“å‡ºé˜Ÿåˆ—
                output_queue.put(processed_data)
                self.processed_count += 1
                
                if (i + 1) % 100 == 0:
                    print(f"[{self.processor_id}] å·²å¤„ç† {i + 1}/{batch_size}")
        
        except Exception as e:
            print(f"[{self.processor_id}] å¤„ç†é”™è¯¯: {e}")
        
        finally:
            input_queue.close()
            output_queue.close()
            
        print(f"[{self.processor_id}] æ‰¹å¤„ç†å®Œæˆï¼Œæ€»è®¡: {self.processed_count}")


def sage_data_generator(queue_name: str, data_count: int):
    """SAGEæ•°æ®ç”Ÿæˆå™¨è¿›ç¨‹"""
    print(f"æ•°æ®ç”Ÿæˆå™¨: å¼€å§‹ç”Ÿæˆ {data_count} æ¡æ•°æ®")
    
    queue = SageQueue(queue_name)
    
    try:
        for i in range(data_count):
            # æ¨¡æ‹ŸSAGEç³»ç»Ÿçš„çœŸå®æ•°æ®
            data_item = {
                'id': i,
                'timestamp': time.time(),
                'source': 'SAGE_sensor_array',
                'values': [i + j for j in range(10)],  # 10ç»´ç‰¹å¾å‘é‡
                'metadata': {
                    'sensor_type': 'lidar' if i % 2 == 0 else 'camera',
                    'quality': 'high',
                    'location': f"sensor_{i % 5}"
                }
            }
            
            queue.put(data_item)
            
            if (i + 1) % 200 == 0:
                print(f"æ•°æ®ç”Ÿæˆå™¨: å·²ç”Ÿæˆ {i + 1}/{data_count}")
                
            # æ¨¡æ‹ŸçœŸå®æ•°æ®ç”Ÿæˆé€Ÿç‡
            time.sleep(0.001)
    
    except Exception as e:
        print(f"æ•°æ®ç”Ÿæˆå™¨é”™è¯¯: {e}")
    
    finally:
        queue.close()
    
    print(f"æ•°æ®ç”Ÿæˆå™¨: å®Œæˆï¼Œæ€»è®¡ç”Ÿæˆ {data_count} æ¡æ•°æ®")


def sage_result_collector(queue_name: str, expected_count: int):
    """SAGEç»“æœæ”¶é›†å™¨è¿›ç¨‹"""
    print(f"ç»“æœæ”¶é›†å™¨: å¼€å§‹æ”¶é›†ï¼Œé¢„æœŸ {expected_count} æ¡ç»“æœ")
    
    queue = SageQueue(queue_name)
    results = []
    
    try:
        start_time = time.time()
        
        while len(results) < expected_count:
            try:
                result = queue.get(timeout=2.0)
                results.append(result)
                
                if len(results) % 100 == 0:
                    print(f"ç»“æœæ”¶é›†å™¨: å·²æ”¶é›† {len(results)}/{expected_count}")
                    
            except Exception as e:
                if "timed out" in str(e):
                    elapsed = time.time() - start_time
                    if elapsed > 30:  # 30ç§’è¶…æ—¶
                        print(f"ç»“æœæ”¶é›†å™¨: è¶…æ—¶ï¼Œåªæ”¶é›†åˆ° {len(results)} æ¡ç»“æœ")
                        break
                    continue
                else:
                    raise
        
        # åˆ†æç»“æœ
        processor_stats = {}
        for result in results:
            pid = result.get('processor_id', 'unknown')
            processor_stats[pid] = processor_stats.get(pid, 0) + 1
        
        print(f"ç»“æœæ”¶é›†å™¨: å®Œæˆï¼Œæ”¶é›† {len(results)} æ¡ç»“æœ")
        print(f"å¤„ç†å™¨ç»Ÿè®¡: {processor_stats}")
        
        return results
    
    except Exception as e:
        print(f"ç»“æœæ”¶é›†å™¨é”™è¯¯: {e}")
        return results
    
    finally:
        queue.close()


def demonstration_simple_pipeline():
    """æ¼”ç¤ºç®€å•çš„SAGEæ•°æ®å¤„ç†æµæ°´çº¿"""
    print("\n" + "="*50)
    print("SAGEç®€å•æµæ°´çº¿æ¼”ç¤º")
    print("="*50)
    
    # é˜Ÿåˆ—åç§°
    input_queue_name = "sage_input"
    output_queue_name = "sage_output"
    
    # æ¸…ç†æ—§é˜Ÿåˆ—
    destroy_queue(input_queue_name)
    destroy_queue(output_queue_name)
    
    # åˆ›å»ºé˜Ÿåˆ—
    input_queue = SageQueue(input_queue_name, maxsize=128*1024)
    output_queue = SageQueue(output_queue_name, maxsize=128*1024)
    
    # é…ç½®å‚æ•°
    data_count = 500
    processor_count = 2
    
    print(f"é…ç½®: {data_count} æ¡æ•°æ®, {processor_count} ä¸ªå¤„ç†å™¨")
    
    try:
        # å¯åŠ¨æ•°æ®ç”Ÿæˆå™¨
        generator_process = multiprocessing.Process(
            target=sage_data_generator,
            args=(input_queue_name, data_count)
        )
        generator_process.start()
        
        # å¯åŠ¨å¤„ç†å™¨
        processors = []
        for i in range(processor_count):
            processor = SAGEDataProcessor(f"SAGE_Processor_{i}")
            process = multiprocessing.Process(
                target=processor.process_batch,
                args=(input_queue_name, output_queue_name, data_count // processor_count)
            )
            process.start()
            processors.append(process)
        
        # å¯åŠ¨ç»“æœæ”¶é›†å™¨
        collector_process = multiprocessing.Process(
            target=sage_result_collector,
            args=(output_queue_name, data_count)
        )
        collector_process.start()
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        print("ç­‰å¾…æ•°æ®ç”Ÿæˆå™¨å®Œæˆ...")
        generator_process.join(timeout=30)
        
        print("ç­‰å¾…å¤„ç†å™¨å®Œæˆ...")
        for proc in processors:
            proc.join(timeout=30)
        
        print("ç­‰å¾…ç»“æœæ”¶é›†å™¨å®Œæˆ...")
        collector_process.join(timeout=30)
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        input_stats = input_queue.get_stats()
        output_stats = output_queue.get_stats()
        
        print(f"\nâœ“ æµæ°´çº¿æ¼”ç¤ºå®Œæˆ:")
        print(f"  è¾“å…¥é˜Ÿåˆ—: å†™å…¥ {input_stats['total_bytes_written']} å­—èŠ‚")
        print(f"  è¾“å‡ºé˜Ÿåˆ—: è¯»å– {output_stats['total_bytes_read']} å­—èŠ‚") 
        print(f"  å¤„ç†æ•ˆç‡: {output_stats['utilization']:.2%}")
        
    except Exception as e:
        print(f"âœ— æµæ°´çº¿æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        input_queue.close()
        output_queue.close()
        
        # æ¸…ç†è¿›ç¨‹
        for proc in [generator_process] + processors + [collector_process]:
            if proc.is_alive():
                proc.terminate()


def demonstration_queue_reference():
    """æ¼”ç¤ºé˜Ÿåˆ—å¼•ç”¨åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„ä½¿ç”¨"""
    print("\n" + "="*50)
    print("SAGEé˜Ÿåˆ—å¼•ç”¨æ¼”ç¤º")
    print("="*50)
    
    queue_name = "sage_reference_demo"
    destroy_queue(queue_name)
    
    # ä¸»è¿›ç¨‹åˆ›å»ºé˜Ÿåˆ—
    main_queue = SageQueue(queue_name, maxsize=32*1024)
    print("âœ“ ä¸»è¿›ç¨‹åˆ›å»ºé˜Ÿåˆ—")
    
    # æ·»åŠ ä¸€äº›æµ‹è¯•æ•°æ®
    for i in range(10):
        data = {
            'message_id': i,
            'content': f"SAGE Message {i}",
            'sensor_data': list(range(i*10, (i+1)*10)),
            'timestamp': time.time()
        }
        main_queue.put(data)
    
    print("âœ“ æ·»åŠ æµ‹è¯•æ•°æ®")
    
    # è·å–é˜Ÿåˆ—å¼•ç”¨
    queue_ref = main_queue.get_reference()
    print(f"âœ“ è·å–é˜Ÿåˆ—å¼•ç”¨: {queue_ref}")
    
    # å­è¿›ç¨‹ä½¿ç”¨å¼•ç”¨è®¿é—®é˜Ÿåˆ—
    def worker_process(queue_ref_state, worker_id):
        # ååºåˆ—åŒ–å¼•ç”¨
        import pickle
        ref = pickle.loads(queue_ref_state)
        
        # ä»å¼•ç”¨è·å–é˜Ÿåˆ—å®ä¾‹
        worker_queue = ref.get_queue()
        print(f"å·¥ä½œè¿›ç¨‹{worker_id}: ä»å¼•ç”¨è·å–é˜Ÿåˆ—å®ä¾‹")
        
        # å¤„ç†æ•°æ®
        processed = 0
        try:
            while processed < 5:  # æ¯ä¸ªå·¥ä½œè¿›ç¨‹å¤„ç†5æ¡æ•°æ®
                data = worker_queue.get(timeout=2.0)
                print(f"å·¥ä½œè¿›ç¨‹{worker_id}: å¤„ç†æ¶ˆæ¯ {data['message_id']}")
                processed += 1
        except:
            pass
        
        worker_queue.close()
        print(f"å·¥ä½œè¿›ç¨‹{worker_id}: å¤„ç†å®Œæˆ {processed} æ¡æ•°æ®")
    
    # åºåˆ—åŒ–å¼•ç”¨ç”¨äºè·¨è¿›ç¨‹ä¼ é€’
    import pickle
    queue_ref_state = pickle.dumps(queue_ref)
    
    # å¯åŠ¨å·¥ä½œè¿›ç¨‹
    workers = []
    for i in range(2):
        process = multiprocessing.Process(
            target=worker_process,
            args=(queue_ref_state, i)
        )
        process.start()
        workers.append(process)
    
    # ç­‰å¾…å·¥ä½œè¿›ç¨‹å®Œæˆ
    for process in workers:
        process.join(timeout=10)
    
    # æ£€æŸ¥å‰©ä½™æ•°æ®
    remaining = 0
    while not main_queue.empty():
        try:
            main_queue.get_nowait()
            remaining += 1
        except:
            break
    
    print(f"âœ“ é˜Ÿåˆ—å¼•ç”¨æ¼”ç¤ºå®Œæˆï¼Œå‰©ä½™æ•°æ®: {remaining}")
    main_queue.close()


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("SAGEé«˜æ€§èƒ½å†…å­˜æ˜ å°„é˜Ÿåˆ—ä½¿ç”¨æ¼”ç¤º")
    print("åŸºäºmmapçš„é›¶æ‹·è´è¿›ç¨‹é—´é€šä¿¡è§£å†³æ–¹æ¡ˆ")
    
    try:
        # æ¼”ç¤º1: ç®€å•æµæ°´çº¿
        demonstration_simple_pipeline()
        
        # æ¼”ç¤º2: é˜Ÿåˆ—å¼•ç”¨
        demonstration_queue_reference()
        
        print("\n" + "="*50)
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
        print("SAGEé«˜æ€§èƒ½é˜Ÿåˆ—å¯ä»¥æ˜¾è‘—æå‡åˆ†å¸ƒå¼ç³»ç»Ÿçš„é€šä¿¡æ•ˆç‡")
        print("="*50)
        
    except Exception as e:
        print(f"âœ— æ¼”ç¤ºè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•
    if hasattr(multiprocessing, 'set_start_method'):
        try:
            multiprocessing.set_start_method('spawn')
        except RuntimeError:
            pass
    
    main()
