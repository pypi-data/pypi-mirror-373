#!/usr/bin/env python3
"""
SAGE Memory-Mapped Queue ç»¼åˆæµ‹è¯•å¥—ä»¶  
Comprehensive test suite for SAGE high-performance memory-mapped queue
"""

import os
import sys
import time
import random
import threading
import multiprocessing
import pickle
import gc
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed

# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from sage.extensions.sage_queue.python.sage_queue import SageQueue, SageQueueRef, destroy_queue
    print("âœ“ æˆåŠŸå¯¼å…¥ SageQueue")
except ImportError as e:
    print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·å…ˆè¿è¡Œ ../build.sh ç¼–è¯‘Cåº“")
    sys.exit(1)


class TestResult:
    """æµ‹è¯•ç»“æœè®°å½•ç±»"""
    def __init__(self, name: str):
        self.name = name
        self.start_time = time.time()
        self.end_time = None
        self.passed = False
        self.error = None
        self.stats = {}
    
    def finish(self, passed: bool, error: str = None, stats: dict = None):
        self.end_time = time.time()
        self.passed = passed
        self.error = error
        self.stats = stats or {}
    
    @property
    def duration(self):
        if self.end_time:
            return self.end_time - self.start_time
        return time.time() - self.start_time
    
    def __str__(self):
        status = "âœ“ PASS" if self.passed else "âœ— FAIL"
        duration = f"{self.duration:.3f}s"
        if self.error:
            return f"{status} {self.name} ({duration}) - {self.error}"
        return f"{status} {self.name} ({duration})"


def test_edge_cases() -> TestResult:
    """æµ‹è¯•è¾¹ç•Œæ¡ä»¶å’Œé”™è¯¯å¤„ç†"""
    result = TestResult("è¾¹ç•Œæ¡ä»¶æµ‹è¯•")
    
    try:
        queue_name = f"test_edge_{int(time.time())}"
        destroy_queue(queue_name)
        
        # æµ‹è¯•1: å¤§æ•°æ®å¯¹è±¡
        print("  æµ‹è¯•å¤§æ•°æ®å¯¹è±¡...")
        large_queue = SageQueue(queue_name + "_large")  # 1MB
        
        # ç”Ÿæˆå¤§æ•°æ®
        large_data = {
            'array': list(range(10000)),
            'text': 'A' * 10000,
            'nested': {'level1': {'level2': list(range(1000))}}
        }
        
        large_queue.put(large_data, timeout=5.0)
        retrieved_data = large_queue.get(timeout=5.0)
        assert retrieved_data == large_data, "å¤§æ•°æ®å¯¹è±¡ä¸åŒ¹é…"
        large_queue.close()
        
        # æµ‹è¯•2: ç©ºå€¼å’ŒNone
        print("  æµ‹è¯•ç‰¹æ®Šå€¼...")
        special_queue = SageQueue(queue_name + "_special")
        special_values = [None, "", [], {}, 0, False, b'', set()]
        
        for val in special_values:
            special_queue.put(val)
        
        for expected in special_values:
            actual = special_queue.get()
            if isinstance(expected, set):
                # setåœ¨pickleåå¯èƒ½å˜æˆlist
                continue
            assert actual == expected, f"ç‰¹æ®Šå€¼ä¸åŒ¹é…: expected={expected}, actual={actual}"
        
        special_queue.close()
        
        # æµ‹è¯•3: è¶…æ—¶å¤„ç†
        print("  æµ‹è¯•è¶…æ—¶å¤„ç†...")
        timeout_queue = SageQueue(queue_name + "_timeout")
        
        # æµ‹è¯•getè¶…æ—¶
        start_time = time.time()
        try:
            timeout_queue.get(timeout=0.1)
            assert False, "åº”è¯¥è¶…æ—¶"
        except Exception as e:
            assert "timed out" in str(e).lower(), f"è¶…æ—¶å¼‚å¸¸ä¿¡æ¯ä¸æ­£ç¡®: {e}"
        
        elapsed = time.time() - start_time
        assert 0.08 <= elapsed <= 0.15, f"è¶…æ—¶æ—¶é—´ä¸å‡†ç¡®: {elapsed}"
        
        timeout_queue.close()
        
        # æµ‹è¯•4: ä¸å¯åºåˆ—åŒ–å¯¹è±¡
        print("  æµ‹è¯•ä¸å¯åºåˆ—åŒ–å¯¹è±¡...")
        serial_queue = SageQueue(queue_name + "_serial")
        
        class NotSerializable:
            def __getstate__(self):
                raise Exception("Cannot serialize")
        
        try:
            serial_queue.put(NotSerializable())
            assert False, "åº”è¯¥æŠ›å‡ºåºåˆ—åŒ–å¼‚å¸¸"
        except ValueError as e:
            assert "serialize" in str(e), f"åºåˆ—åŒ–å¼‚å¸¸ä¿¡æ¯ä¸æ­£ç¡®: {e}"
        
        serial_queue.close()
        
        # æ¸…ç†
        for suffix in ["_large", "_special", "_timeout", "_serial"]:
            destroy_queue(queue_name + suffix)
        
        result.finish(True, stats={'large_data_size': len(pickle.dumps(large_data))})
        
    except Exception as e:
        result.finish(False, str(e))
    
    return result


def test_concurrent_access() -> TestResult:
    """æµ‹è¯•å¹¶å‘è®¿é—®"""
    result = TestResult("å¹¶å‘è®¿é—®æµ‹è¯•")
    
    try:
        queue_name = f"test_concurrent_{int(time.time())}"
        destroy_queue(queue_name)
        
        queue = SageQueue(queue_name)
        num_threads = 8
        messages_per_thread = 100
        
        results = {'put': [], 'get': []}
        barrier = threading.Barrier(num_threads * 2)  # writers + readers
        
        def writer_thread(thread_id: int):
            barrier.wait()  # åŒæ­¥å¯åŠ¨
            start = time.time()
            
            for i in range(messages_per_thread):
                message = {
                    'thread_id': thread_id,
                    'message_id': i,
                    'data': f"Thread-{thread_id}-Message-{i}",
                    'timestamp': time.time()
                }
                queue.put(message, timeout=10.0)
            
            end = time.time()
            results['put'].append(end - start)
        
        def reader_thread(thread_id: int):
            barrier.wait()  # åŒæ­¥å¯åŠ¨
            start = time.time()
            messages = []
            
            for i in range(messages_per_thread):
                try:
                    msg = queue.get(timeout=15.0)
                    messages.append(msg)
                except Exception as e:
                    print(f"Reader {thread_id} error at message {i}: {e}")
                    break
            
            end = time.time()
            results['get'].append((end - start, len(messages)))
        
        # åˆ›å»ºçº¿ç¨‹
        threads = []
        
        # å†™çº¿ç¨‹
        for i in range(num_threads):
            t = threading.Thread(target=writer_thread, args=(i,))
            threads.append(t)
            t.start()
        
        # è¯»çº¿ç¨‹
        for i in range(num_threads):
            t = threading.Thread(target=reader_thread, args=(i + num_threads,))
            threads.append(t)
            t.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for t in threads:
            t.join(timeout=20.0)
        
        # éªŒè¯ç»“æœ
        total_put_time = sum(results['put'])
        total_messages_read = sum(count for _, count in results['get'])
        expected_messages = num_threads * messages_per_thread
        
        assert total_messages_read == expected_messages, \
            f"æ¶ˆæ¯æ•°é‡ä¸åŒ¹é…: expected={expected_messages}, actual={total_messages_read}"
        
        queue.close()
        destroy_queue(queue_name)
        
        stats = {
            'threads': num_threads * 2,
            'messages_per_thread': messages_per_thread,
            'total_messages': expected_messages,
            'avg_put_time': total_put_time / num_threads,
            'avg_get_time': sum(time_taken for time_taken, _ in results['get']) / num_threads
        }
        
        result.finish(True, stats=stats)
        
    except Exception as e:
        result.finish(False, str(e))
        try:
            destroy_queue(queue_name)
        except:
            pass
    
    return result


def test_memory_leak() -> TestResult:
    """æµ‹è¯•å†…å­˜æ³„æ¼"""
    result = TestResult("å†…å­˜æ³„æ¼æµ‹è¯•")
    
    try:
        try:
            import psutil
            import gc
        except ImportError:
            result.finish(False, "éœ€è¦å®‰è£… psutil: pip install psutil")
            return result
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        queue_name = f"test_memory_{int(time.time())}"
        destroy_queue(queue_name)
        
        # åˆ›å»ºå¤šä¸ªé˜Ÿåˆ—å¹¶é¢‘ç¹æ“ä½œ
        num_iterations = 100
        messages_per_iteration = 50
        
        for iteration in range(num_iterations):
            current_queue_name = f"{queue_name}_{iteration}"
            queue = SageQueue(current_queue_name)
            
            # å†™å…¥å¤§é‡æ•°æ®
            for i in range(messages_per_iteration):
                data = {
                    'iteration': iteration,
                    'message': i,
                    'payload': list(range(100)),  # ä¸€äº›æ•°æ®
                    'text': f"Iteration {iteration} Message {i}" * 5
                }
                queue.put(data)
            
            # è¯»å–æ‰€æœ‰æ•°æ®
            for i in range(messages_per_iteration):
                queue.get()
            
            # å…³é—­é˜Ÿåˆ—
            queue.close()
            destroy_queue(current_queue_name)
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            if iteration % 20 == 0:
                gc.collect()
                current_memory = process.memory_info().rss / 1024 / 1024
                print(f"  Iteration {iteration}: Memory usage: {current_memory:.1f}MB")
        
        # æœ€ç»ˆå†…å­˜æ£€æŸ¥
        gc.collect()
        time.sleep(0.1)
        final_memory = process.memory_info().rss / 1024 / 1024
        memory_increase = final_memory - initial_memory
        
        print(f"  åˆå§‹å†…å­˜: {initial_memory:.1f}MB")
        print(f"  æœ€ç»ˆå†…å­˜: {final_memory:.1f}MB")
        print(f"  å†…å­˜å¢é•¿: {memory_increase:.1f}MB")
        
        # å…è®¸ä¸€å®šçš„å†…å­˜å¢é•¿ï¼ˆå°äº50MBï¼‰
        assert memory_increase < 50, f"å¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼: å¢é•¿äº†{memory_increase:.1f}MB"
        
        stats = {
            'initial_memory_mb': initial_memory,
            'final_memory_mb': final_memory,
            'memory_increase_mb': memory_increase,
            'iterations': num_iterations,
            'messages_per_iteration': messages_per_iteration
        }
        
        result.finish(True, stats=stats)
        
    except Exception as e:
        result.finish(False, str(e))
    
    return result


def test_persistence() -> TestResult:
    """æµ‹è¯•é˜Ÿåˆ—æŒä¹…æ€§"""
    result = TestResult("æŒä¹…æ€§æµ‹è¯•")
    
    try:
        queue_name = f"test_persistence_{int(time.time())}"
        destroy_queue(queue_name)
        
        test_data = [
            "æŒä¹…æ€§æµ‹è¯•æ•°æ®1",
            {"key": "value", "number": 42},
            [1, 2, 3, 4, 5],
            "æœ€åä¸€æ¡æ¶ˆæ¯"
        ]
        
        # ç¬¬ä¸€é˜¶æ®µï¼šåˆ›å»ºé˜Ÿåˆ—å¹¶å†™å…¥æ•°æ®
        queue1 = SageQueue(queue_name)
        for data in test_data:
            queue1.put(data)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats_before = queue1.get_stats()
        print(f"  å†™å…¥å‰ç»Ÿè®¡: {stats_before}")
        
        # å…³é—­é˜Ÿåˆ—ï¼ˆä½†ä¸é”€æ¯ï¼‰
        queue1.close()
        
        # çŸ­æš‚ç­‰å¾…
        time.sleep(0.1)
        
        # ç¬¬äºŒé˜¶æ®µï¼šé‡æ–°æ‰“å¼€é˜Ÿåˆ—å¹¶è¯»å–æ•°æ®
        queue2 = SageQueue(queue_name)
        
        retrieved_data = []
        for _ in range(len(test_data)):
            data = queue2.get(timeout=5.0)
            retrieved_data.append(data)
        
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        assert retrieved_data == test_data, f"æ•°æ®ä¸ä¸€è‡´: {retrieved_data} != {test_data}"
        
        stats_after = queue2.get_stats()
        print(f"  è¯»å–åç»Ÿè®¡: {stats_after}")
        
        queue2.close()
        destroy_queue(queue_name)
        
        result.finish(True, stats={
            'data_items': len(test_data),
            'bytes_written': stats_before['total_bytes_written'],
            'bytes_read': stats_after['total_bytes_read']
        })
        
    except Exception as e:
        result.finish(False, str(e))
        try:
            destroy_queue(queue_name)
        except:
            pass
    
    return result


def test_stress_performance() -> TestResult:
    """å‹åŠ›æ€§èƒ½æµ‹è¯•"""
    result = TestResult("å‹åŠ›æ€§èƒ½æµ‹è¯•")
    
    try:
        queue_name = f"test_stress_{int(time.time())}"
        destroy_queue(queue_name)
        
        queue = SageQueue(queue_name)  # 100KB buffer
        
        # æµ‹è¯•å‚æ•°
        num_messages = 5000
        message_sizes = [100, 1000, 5000]  # bytes
        
        performance_data = {}
        
        for msg_size in message_sizes:
            print(f"  æµ‹è¯•æ¶ˆæ¯å¤§å°: {msg_size} å­—èŠ‚")
            
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            test_message = {
                'id': 0,
                'data': 'x' * msg_size,
                'timestamp': time.time()
            }
            
            # å†™å…¥æ€§èƒ½æµ‹è¯•
            write_start = time.time()
            write_count = 0
            
            for i in range(num_messages):
                test_message['id'] = i
                test_message['timestamp'] = time.time()
                
                try:
                    queue.put_nowait(test_message)
                    write_count += 1
                except:
                    # é˜Ÿåˆ—æ»¡äº†ï¼Œå…ˆè¯»ä¸€äº›
                    for _ in range(min(100, queue.qsize())):
                        try:
                            queue.get_nowait()
                        except:
                            break
                    
                    try:
                        queue.put_nowait(test_message)
                        write_count += 1
                    except:
                        break
            
            write_time = time.time() - write_start
            
            # è¯»å–æ€§èƒ½æµ‹è¯•
            read_start = time.time()
            read_count = 0
            
            while not queue.empty() and read_count < write_count:
                try:
                    queue.get_nowait()
                    read_count += 1
                except:
                    break
            
            read_time = time.time() - read_start
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            write_rate = write_count / write_time if write_time > 0 else 0
            read_rate = read_count / read_time if read_time > 0 else 0
            throughput_mbps = (write_count * msg_size) / (1024 * 1024) / max(write_time, 0.001)
            
            performance_data[msg_size] = {
                'write_count': write_count,
                'read_count': read_count,
                'write_rate_mps': write_rate,
                'read_rate_mps': read_rate,
                'throughput_mbps': throughput_mbps
            }
            
            print(f"    å†™å…¥: {write_count} æ¶ˆæ¯, {write_rate:.0f} msg/s")
            print(f"    è¯»å–: {read_count} æ¶ˆæ¯, {read_rate:.0f} msg/s")
            print(f"    ååé‡: {throughput_mbps:.1f} MB/s")
        
        queue.close()
        destroy_queue(queue_name)
        
        result.finish(True, stats=performance_data)
        
    except Exception as e:
        result.finish(False, str(e))
        try:
            destroy_queue(queue_name)
        except:
            pass
    
    return result


def test_multiprocess_robustness() -> TestResult:
    """å¤šè¿›ç¨‹å¥å£®æ€§æµ‹è¯•"""
    result = TestResult("å¤šè¿›ç¨‹å¥å£®æ€§æµ‹è¯•")
    
    def worker_process(queue_name: str, worker_id: int, operation_count: int, seed: int):
        """å·¥ä½œè¿›ç¨‹"""
        random.seed(seed + worker_id)
        
        try:
            queue = SageQueue(queue_name)
            operations = ['put', 'get'] * (operation_count // 2)
            random.shuffle(operations)
            
            put_count = 0
            get_count = 0
            
            for op in operations:
                try:
                    if op == 'put':
                        data = "12345"
                        queue.put(data, timeout=1.0)
                        put_count += 1
                    else:
                        queue.get(timeout=1.0)
                        get_count += 1
                    
                    # éšæœºæš‚åœ
                    if random.random() < 0.1:
                        time.sleep(random.uniform(0.001, 0.01))
                        
                except:
                    continue  # å¿½ç•¥è¶…æ—¶ç­‰é”™è¯¯
            
            queue.close()
            return {'worker_id': worker_id, 'put_count': put_count, 'get_count': get_count}
            
        except Exception as e:
            return {'worker_id': worker_id, 'error': str(e)}
    
    try:
        queue_name = f"test_multiproc_{int(time.time())}"
        destroy_queue(queue_name)
        
        # åˆ›å»ºä¸»é˜Ÿåˆ—
        main_queue = SageQueue(queue_name)
        
        # é¢„å¡«å……ä¸€äº›æ•°æ®
        for i in range(100):
            main_queue.put(f"prefill_{i}")
        
        main_queue.close()
        
        # å¯åŠ¨å¤šä¸ªå·¥ä½œè¿›ç¨‹
        num_workers = 6
        operations_per_worker = 200
        seed = int(time.time())
        
        with ProcessPoolExecutor(max_workers=num_workers) as executor:
            futures = []
            for worker_id in range(num_workers):
                future = executor.submit(
                    worker_process,
                    queue_name,
                    worker_id,
                    operations_per_worker,
                    seed
                )
                futures.append(future)
            
            # æ”¶é›†ç»“æœ
            worker_results = []
            for future in as_completed(futures, timeout=30):
                try:
                    result_data = future.result()
                    worker_results.append(result_data)
                except Exception as e:
                    worker_results.append({'error': str(e)})
            print("  å·¥ä½œè¿›ç¨‹ç»“æœ:")
            for r in worker_results:
                print(f"    {r}")
            
        # åˆ†æç»“æœ
        successful_workers = [r for r in worker_results if 'error' not in r]
        total_puts = sum(r['put_count'] for r in successful_workers)
        total_gets = sum(r['get_count'] for r in successful_workers)
        
        print(f"  æˆåŠŸçš„å·¥ä½œè¿›ç¨‹: {len(successful_workers)}/{num_workers}")
        print(f"  æ€»putæ“ä½œ: {total_puts}")
        print(f"  æ€»getæ“ä½œ: {total_gets}")
        
        # æ£€æŸ¥æœ€ç»ˆé˜Ÿåˆ—çŠ¶æ€
        final_queue = SageQueue(queue_name)
        final_size = 0
        try:
            while True:
                final_queue.get_nowait()
                final_size += 1
        except:
            pass
        
        final_queue.close()
        destroy_queue(queue_name)
        
        print(f"  æœ€ç»ˆé˜Ÿåˆ—å¤§å°: {final_size}")
        
        # æˆåŠŸæ¡ä»¶ï¼šè‡³å°‘ä¸€åŠçš„å·¥ä½œè¿›ç¨‹æˆåŠŸå®Œæˆ
        assert len(successful_workers) >= num_workers // 2, \
            f"å¤ªå¤šå·¥ä½œè¿›ç¨‹å¤±è´¥: {num_workers - len(successful_workers)}/{num_workers}"
        
        stats = {
            'workers': num_workers,
            'successful_workers': len(successful_workers),
            'total_puts': total_puts,
            'total_gets': total_gets,
            'final_queue_size': final_size
        }
        
        result.finish(True, stats=stats)
        
    except Exception as e:
        result.finish(False, str(e))
        try:
            destroy_queue(queue_name)
        except:
            pass
    
    return result


def run_comprehensive_tests():
    """è¿è¡Œæ‰€æœ‰ç»¼åˆæµ‹è¯•"""
    print("SAGE Memory-Mapped Queue ç»¼åˆæµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    print()
    
    # å®šä¹‰æµ‹è¯•å‡½æ•°
    test_functions = [
        test_edge_cases,
        test_persistence,
        test_stress_performance,
        test_concurrent_access,
        test_memory_leak,
        test_multiprocess_robustness,
    ]
    
    results = []
    
    for test_func in test_functions:
        print(f"è¿è¡Œ {test_func.__doc__ or test_func.__name__}...")
        try:
            test_result = test_func()
            results.append(test_result)
            print(f"  {test_result}")
            if test_result.stats:
                for key, value in test_result.stats.items():
                    print(f"    {key}: {value}")
            print()
        except Exception as e:
            error_result = TestResult(test_func.__name__)
            error_result.finish(False, f"æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {e}")
            results.append(error_result)
            print(f"  {error_result}")
            print()
    
    # æ±‡æ€»ç»“æœ
    print("=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»:")
    print("-" * 60)
    
    passed = 0
    failed = 0
    total_time = 0
    
    for test_result in results:
        print(f"  {test_result}")
        if test_result.passed:
            passed += 1
        else:
            failed += 1
        total_time += test_result.duration
    
    print("-" * 60)
    print(f"æ€»è®¡: {passed} é€šè¿‡, {failed} å¤±è´¥, è€—æ—¶ {total_time:.1f}ç§’")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†!")
        return True
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥")
        return False


if __name__ == "__main__":
    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•
    if hasattr(multiprocessing, 'set_start_method'):
        try:
            multiprocessing.set_start_method('spawn')
        except RuntimeError:
            pass
    
    success = run_comprehensive_tests()
    sys.exit(0 if success else 1)
