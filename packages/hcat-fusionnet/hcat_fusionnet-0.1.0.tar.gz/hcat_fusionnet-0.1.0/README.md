# HCAT-FusionNet: Multimodal Preprocessing and Fusion for Clinical Outcome Prediction

![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)
![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)
![PyPI Version](https://img.shields.io/pypi/v/hcat-fusionnet.svg) <!-- Placeholder for when it's on PyPI -->

**HCAT-FusionNet** is a state-of-the-art framework for predicting clinical outcomes in head and neck cancer by fusing five distinct data modalities. This repository contains the complete preprocessing pipelines and the advanced training model for the **HANCOCK (Head and Neck Cancer Cohort)** dataset, originally developed for the **Hancothon25 Challenge** at MICCAI 2025.

Our solution introduces novel, clinically-grounded preprocessing techniques and a sophisticated fusion model to predict **5-year survival** and **2-year recurrence** with high accuracy.

## Architecture Overview

The core of our approach is the **Hierarchical Cross-modal Attention Transformer (HCAT)**, which integrates embeddings from five specialized preprocessing pipelines.

*Figure 1: The HCAT-FusionNet architecture, showing the flow from individual modality preprocessing to the final fusion and prediction heads.*

---

## Key Features

- **End-to-End Multimodal Framework**: Processes raw data from five sources into a unified, predictive model.
- **Advanced Preprocessing Pipelines**: Each modality undergoes a specialized, state-of-the-art preprocessing workflow:
  - **Clinical & Pathological**: Probabilistic imputation using a **Variational Autoencoder (VAE)** combined with **Graph Smoothing** to handle missing data with uncertainty.
  - **Temporal (Blood Tests)**: A novel **two-stage imputation** method using clinical reference ranges followed by cohort-level KNN refinement, with embeddings generated by a **Denoising LSTM Encoder**.
  - **Spatial (Histopathology)**: A **Spatially-Aware Transformer** aggregates thousands of WSI patches, using **Monte-Carlo Dropout** to quantify embedding uncertainty.
  - **Semantic (Clinical Notes)**: **Bio_ClinicalBERT** or TF-IDF+SVD pipelines extract meaningful representations from free-text reports, with hierarchical aggregation.
- **Dynamic In-Training Imputation**: The training model features a **Multi-Modal VAE** that can dynamically generate representations for missing modalities on-the-fly, based on the data that is present.
- **High-Performance Results**: Achieves state-of-the-art performance on the HANCOCK dataset.

---

## Installation

You can install the `hcat-fusionnet` package directly from PyPI (once it's published):

```bash
pip install hcat-fusionnet
```

Alternatively, for development purposes, you can clone the repository and install it in editable mode:

```bash
git clone https://github.com/Ragu-123/hcat-fusionnet.git
cd hcat-fusionnet
pip install -e .
```

---

## Usage Guide

This guide demonstrates how to use the preprocessing pipelines to generate embeddings from your own data, which can then be used to train the HCAT model.

### Step 1: Data Preparation

Organize your raw data files into a clear directory structure. For example:

```
/path/to/your/data/
├── clinical_data.json
├── pathological_data.json
├── blood_data.json
├── blood_data_reference_ranges.json
├── text_data/
│   ├── histories/
│   │   ├── patient_001.txt
│   │   └── ...
│   └── reports/
│       ├── patient_001.txt
│       └── ...
└── wsi_h5_data/
    ├── lymph_nodes/
    │   ├── patient_001.h5
    │   └── ...
    └── primary_tumor/
        ├── patient_001.h5
        └── ...
```

### Step 2: Run the Preprocessing Scripts

Execute each preprocessing script, pointing to your input data and a desired output directory.

#### 1. Clinical Data

```bash
python -m hcat_preprocess.clinical \
    --input_json /path/to/your/data/clinical_data.json \
    --out_dir /path/to/your/preprocessed_data/clinical
```

#### 2. Pathological Data

```bash
python -m hcat_preprocess.pathology \
    --input_json /path/to/your/data/pathological_data.json \
    --out_dir /path/to/your/preprocessed_data/pathological
```

#### 3. Temporal Data

```bash
python -m hcat_preprocess.temporal \
    --blood_json /path/to/your/data/blood_data.json \
    --ref_json /path/to/your/data/blood_data_reference_ranges.json \
    --out_dir /path/to/your/preprocessed_data/temporal
```

#### 4. Semantic Data

```bash
python -m hcat_preprocess.semantic \
    --text_dirs /path/to/your/data/text_data/histories /path/to/your/data/text_data/reports \
    --dir_names histories reports \
    --out_dir /path/to/your/preprocessed_data/semantic \
    --use_transformer
```

#### 5. Spatial Data

```bash
python -m hcat_preprocess.spatial \
    --wsi_dirs /path/to/your/data/wsi_h5_data/lymph_nodes /path/to/your/data/wsi_h5_data/primary_tumor \
    --out_dir /path/to/your/preprocessed_data/spatial \
    --use_gpu
```

### Step 3: Train the HCAT-FusionNet Model

After generating all five embedding files, you can use them to train the main fusion model.

```bash
python train.py \
    --clinical /path/to/your/preprocessed_data/clinical/clinical_embedding_512.h5 \
    --pathological /path/to/your/preprocessed_data/pathological/pathological_embedding_512.h5 \
    --temporal /path/to/your/preprocessed_data/temporal/temporal_embedding_512.h5 \
    --semantic /path/to/your/preprocessed_data/semantic/text_semantic_embeddings_512.h5 \
    --spatial /path/to/your/preprocessed_data/spatial/spatial_embedding_512.h5 \
    --outdir ./hcat_checkpoints \
    --epochs 50 \
    --batch 32 \
    --lr 5e-5 \
    --device cuda
```

---

## Results

Our enhanced training pipeline achieved the following performance on the HANCOCK validation set:

| Metric             | F1-Score |
|--------------------|----------|
| 5-Year Survival    | 0.80     |
| 2-Year Recurrence  | 0.95     |
| **Average F1-Score** | **0.875** |

For detailed training logs and configuration, please see the `enhanced_hcat_training_summary.json` file.

---

## Citation

If you use this work in your research, please cite it as follows:

```bibtex
@inproceedings{hcat_fusionnet_2025,
  title={{HCAT-FusionNet: Multimodal Preprocessing and Fusion for Survival and Recurrence Prediction}},
  author={Ragunath, R and Sanjay, S and Harish, G},
  booktitle={MICCAI Hancothon25 Challenge},
  year={2025}
}
```

---

## License

This project is licensed under the GNU General Public License v3.0. See the LICENSE file for details.

---

## Contact

For questions, collaborations, or issues, please contact:

- Harish G ([@Harish2404lll](https://github.com/Harish2404lll))
- Ragunath R ([@Ragu-123](https://github.com/Ragu-123))
- Sanjay S ([@22002102](https://github.com/22002102))
