{
  "name": "default",
  "description": "Standard LLM training project with basic configuration and structure",
  "version": "1.0.0",
  "directories": [
    "data/raw",
    "data/cleaned",
    "data/deduped",
    "data/tokens",
    "data/finetune",
    "exports/checkpoints",
    "exports/tokenizer",
    "exports/gguf",
    "logs",
    "scripts"
  ],
  "files": {
    "requirements.txt": "llmbuilder>=1.0.0\n",
    "train.py": "#!/usr/bin/env python3\n\"\"\"\nBasic training script for LLM project.\n\"\"\"\n\nimport argparse\nfrom pathlib import Path\n\ndef main():\n    parser = argparse.ArgumentParser(description='Train LLM model')\n    parser.add_argument('--config', default='llmbuilder.json', help='Configuration file')\n    parser.add_argument('--data', default='data/tokens', help='Training data directory')\n    parser.add_argument('--output', default='exports/checkpoints', help='Output directory')\n    args = parser.parse_args()\n    \n    print(f\"Starting training with config: {args.config}\")\n    print(f\"Data directory: {args.data}\")\n    print(f\"Output directory: {args.output}\")\n    \n    # TODO: Implement training logic using llmbuilder\n    print(\"Training completed!\")\n\nif __name__ == '__main__':\n    main()\n",
    "scripts/preprocess.py": "#!/usr/bin/env python3\n\"\"\"\nData preprocessing script.\n\"\"\"\n\nimport argparse\nfrom pathlib import Path\n\ndef preprocess_data(input_dir: str, output_dir: str):\n    \"\"\"\n    Preprocess raw data for training.\n    \n    Args:\n        input_dir: Directory containing raw data files\n        output_dir: Directory to save processed data\n    \"\"\"\n    input_path = Path(input_dir)\n    output_path = Path(output_dir)\n    \n    output_path.mkdir(parents=True, exist_ok=True)\n    \n    print(f\"Processing data from: {input_path}\")\n    print(f\"Output directory: {output_path}\")\n    \n    # TODO: Implement preprocessing logic\n    print(\"Preprocessing completed!\")\n\ndef main():\n    parser = argparse.ArgumentParser(description='Preprocess data')\n    parser.add_argument('--input', default='data/raw', help='Input directory')\n    parser.add_argument('--output', default='data/cleaned', help='Output directory')\n    args = parser.parse_args()\n    \n    preprocess_data(args.input, args.output)\n\nif __name__ == '__main__':\n    main()\n"
  },
  "config_overrides": {
    "project": {
      "template": "default"
    }
  },
  "sample_data": {
    "enabled": true,
    "files": [
      {
        "name": "sample_data.txt",
        "content": "This is sample training data for your LLM project.\n\nYou can replace this file with your actual training documents.\n\nThe default template provides:\n- Basic project structure\n- Simple training and preprocessing scripts\n- Standard configuration\n\nTo get started:\n1. Replace this file with your training data\n2. Run: llmbuilder data prepare\n3. Run: llmbuilder train start\n\nGood luck with your project!"
      }
    ]
  }
}