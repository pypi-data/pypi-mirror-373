wandb:
  project: wandb-generic-example
  tags: ["generic-logger", "flexible-variables"]
  notes: "Generic logging - works with ANY variable names from your function"

hyperparameters:
  epochs: 10
  learning_rate: 0.01
  batch_size: 64

sweep:
  method: random
  metric:
    name: loss_value  # Can be ANY variable name from your function
    goal: minimize
  parameters:
    learning_rate:
      values: [0.1, 0.01, 0.001]
    batch_size:
      values: [32, 64, 128]

logger:
  # IMPORTANT: List ANY variable names from your function
  # The logger will automatically capture these variables
  metrics:
    - loss_value         # Traditional loss name
    - epoch_num          # Traditional epoch name
    - x                  # Can use short names (like your original question)
    - y                  # Can use any single letter variables  
    - training_loss      # Can use descriptive names
    - validation_acc     # Any custom metrics you create
    - learning_rate      # Can log hyperparameters too
    - batch_size         # Any other variables from your function
    - accuracy           # Standard ML metrics
    - model_complexity   # Domain-specific metrics
  log_frequency: 1       # Log every iteration

checkpoint:
  name: generic-model
  type: model
  save_frequency: 5
