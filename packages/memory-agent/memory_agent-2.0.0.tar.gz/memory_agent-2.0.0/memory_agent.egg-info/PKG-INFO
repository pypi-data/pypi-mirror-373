Metadata-Version: 2.4
Name: memory_agent
Version: 2.0.0
Summary: A Python library for advanced memory management in AI agent applications
Author-email: Giuseppe Zileni <giuseppe.zileni@gmail.com>
Project-URL: Homepage, https://gzileni.github.io/memory-agent
Project-URL: Repository, https://github.com/gzileni/memory-agent
Keywords: agent,memory
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: OS Independent
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE.md
Requires-Dist: aioboto3>=14.3.0
Requires-Dist: aiobotocore>=2.22.0
Requires-Dist: aiofiles>=24.1.0
Requires-Dist: aiohappyeyeballs>=2.6.1
Requires-Dist: aiohttp>=3.11.18
Requires-Dist: aioitertools>=0.12.0
Requires-Dist: aiosignal>=1.3.2
Requires-Dist: annotated-types>=0.7.0
Requires-Dist: anyio>=4.9.0
Requires-Dist: attrs>=25.3.0
Requires-Dist: backoff>=2.2.1
Requires-Dist: beautifulsoup4>=4.13.4
Requires-Dist: boto3>=1.37.3
Requires-Dist: botocore>=1.37.3
Requires-Dist: build>=1.2.2.post1
Requires-Dist: certifi>=2025.4.26
Requires-Dist: cffi>=1.17.1
Requires-Dist: chardet>=5.2.0
Requires-Dist: charset-normalizer>=3.4.2
Requires-Dist: click>=8.1.3
Requires-Dist: coloredlogs>=15.0.1
Requires-Dist: contourpy>=1.3.2
Requires-Dist: cryptography>=43.0.0
Requires-Dist: cycler>=0.12.1
Requires-Dist: dataclasses-json>=0.6.7
Requires-Dist: distro>=1.9.0
Requires-Dist: docutils>=0.21.2
Requires-Dist: emoji>=2.14.1
Requires-Dist: fastembed>=0.7.0
Requires-Dist: filelock>=3.18.0
Requires-Dist: filetype>=1.2.0
Requires-Dist: flatbuffers>=25.2.10
Requires-Dist: fonttools>=4.58.0
Requires-Dist: fpdf>=1.7.2
Requires-Dist: frozenlist>=1.6.0
Requires-Dist: fsspec>=2024.12.0
Requires-Dist: greenlet>=3.2.2
Requires-Dist: grpcio>=1.74.0
Requires-Dist: h11>=0.16.0
Requires-Dist: h2>=4.2.0
Requires-Dist: hf-xet>=1.1.0
Requires-Dist: hpack>=4.1.0
Requires-Dist: html5lib>=1.1
Requires-Dist: httpcore>=1.0.9
Requires-Dist: httpx>=0.28.1
Requires-Dist: httpx-sse>=0.4.0
Requires-Dist: huggingface-hub>=0.24.0
Requires-Dist: humanfriendly>=10.0
Requires-Dist: hyperframe>=6.1.0
Requires-Dist: id>=1.5.0
Requires-Dist: idna>=3.10
Requires-Dist: iniconfig>=2.1.0
Requires-Dist: jaraco.classes>=3.4.0
Requires-Dist: jaraco.context>=6.0.1
Requires-Dist: jaraco.functools>=4.1.0
Requires-Dist: jiter>=0.9.0
Requires-Dist: jmespath>=1.0.1
Requires-Dist: joblib>=1.5.0
Requires-Dist: json_repair>=0.39.1
Requires-Dist: jsonpatch>=1.33
Requires-Dist: jsonpointer>=2.1
Requires-Dist: keyring>=25.6.0
Requires-Dist: kiwisolver>=1.4.8
Requires-Dist: langdetect>=1.0.9
Requires-Dist: langgraph>=0.4.8
Requires-Dist: langsmith>=0.3.45
Requires-Dist: langchain>=0.3.25
Requires-Dist: langchain-ollama>=0.3.3
Requires-Dist: langcodes>=3.5.0
Requires-Dist: langgraph-checkpoint>=2.0.26
Requires-Dist: language_data>=1.3.0
Requires-Dist: langchain-community>=0.3.25
Requires-Dist: langchain-core>=0.3.65
Requires-Dist: langchain-openai>=0.3.23
Requires-Dist: langchain-qdrant>=0.2.0
Requires-Dist: langchain-text-splitters>=0.3.8
Requires-Dist: langgraph-prebuilt>=0.2.2
Requires-Dist: langgraph-sdk>=0.1.70
Requires-Dist: loguru>=0.7.3
Requires-Dist: loki-logger-handler>=1.1.2
Requires-Dist: lxml>=5.4.0
Requires-Dist: markdown-it-py>=3.0.0
Requires-Dist: marshmallow>=3.26.1
Requires-Dist: matplotlib>=3.10.3
Requires-Dist: mdurl>=0.1.2
Requires-Dist: mmh3>=5.1.0
Requires-Dist: more-itertools>=10.7.0
Requires-Dist: mpmath>=1.3.0
Requires-Dist: multidict>=6.4.4
Requires-Dist: mypy_extensions>=1.1.0
Requires-Dist: narwhals>=1.43.1
Requires-Dist: nest-asyncio>=1.6.0
Requires-Dist: nh3>=0.2.21
Requires-Dist: nltk>=3.9.1
Requires-Dist: numpy>=1.26.4
Requires-Dist: olefile>=0.47
Requires-Dist: ollama>=0.5.1
Requires-Dist: onnxruntime>=1.22.0
Requires-Dist: openai>=1.86.0
Requires-Dist: orjson>=3.10.18
Requires-Dist: ormsgpack>=1.10.0
Requires-Dist: packaging>=24.2
Requires-Dist: pandas>=2.3.0
Requires-Dist: pillow>=11.2.1
Requires-Dist: plotly>=6.1.2
Requires-Dist: pluggy>=1.6.0
Requires-Dist: portalocker>=2.10.1
Requires-Dist: propcache>=0.3.2
Requires-Dist: protobuf>=5.29.4
Requires-Dist: psutil>=7.0.0
Requires-Dist: py_rust_stemmers>=0.1.5
Requires-Dist: pyaws-s3>=1.0.21
Requires-Dist: pycparser>=2.22
Requires-Dist: pydantic>=2.11.6
Requires-Dist: pydantic-settings>=2.9.1
Requires-Dist: pydantic_core>=2.33.2
Requires-Dist: Pygments>=2.19.1
Requires-Dist: pyparsing>=3.2.3
Requires-Dist: pypdf>=5.6.0
Requires-Dist: pyproject_hooks>=1.2.0
Requires-Dist: pytest>=8.4.1
Requires-Dist: python-dateutil>=2.9.0.post0
Requires-Dist: python-dotenv>=1.1.0
Requires-Dist: python-iso639>=2025.2.18
Requires-Dist: python-magic>=0.4.27
Requires-Dist: python-oxmsg>=0.0.2
Requires-Dist: pytz>=2025.2
Requires-Dist: PyYAML>=6.0.2
Requires-Dist: qdrant-client>=1.14.2
Requires-Dist: RapidFuzz>=3.13.0
Requires-Dist: readme_renderer>=44.0
Requires-Dist: redis>=6.2.0
Requires-Dist: regex>=2024.11.6
Requires-Dist: reportlab>=4.4.2
Requires-Dist: requests>=2.32.4
Requires-Dist: requests-toolbelt>=1.0.0
Requires-Dist: rfc3986>=2.0.0
Requires-Dist: rich>=14.0.0
Requires-Dist: s3transfer>=0.11.3
Requires-Dist: setuptools>=80.9.0
Requires-Dist: six>=1.17.0
Requires-Dist: sniffio>=1.3.1
Requires-Dist: soupsieve>=2.7
Requires-Dist: SQLAlchemy>=2.0.41
Requires-Dist: sympy>=1.14.0
Requires-Dist: tenacity>=9.1.2
Requires-Dist: tiktoken>=0.9.0
Requires-Dist: tokenizers>=0.21.1
Requires-Dist: tqdm>=4.67.1
Requires-Dist: twine>=6.1.0
Requires-Dist: types-PyYAML>=6.0.12.20250516
Requires-Dist: typing-inspect>=0.9.0
Requires-Dist: typing-inspection>=0.4.1
Requires-Dist: typing_extensions>=4.14.0
Requires-Dist: tzdata>=2025.2
Requires-Dist: unstructured>=0.17.2
Requires-Dist: unstructured-client>=0.36.0
Requires-Dist: urllib3>=2.4.0
Requires-Dist: webencodings>=0.5.1
Requires-Dist: wheel>=0.45.1
Requires-Dist: wrapt>=1.17.2
Requires-Dist: xxhash>=3.5.0
Requires-Dist: yarl>=1.20.1
Requires-Dist: zstandard>=0.23.0
Dynamic: license-file

[![View on GitHub](https://img.shields.io/badge/View%20on-GitHub-181717?style=for-the-badge&logo=github)](https://github.com/gzileni/memory-agent)
[![GitHub stars](https://img.shields.io/github/stars/gzileni/memory-agent?style=social)](https://github.com/gzileni/memory-agent/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/gzileni/memory-agent?style=social)](https://github.com/gzileni/memory-agent/network)

The library allows you to manage both [persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/) and [**memory**](https://langchain-ai.github.io/langgraph/concepts/memory/#what-is-memory) for a LangGraph agent.

**memory-agent** uses [Redis](https://redis.io/) as the short-term memory database and [QDrant](https://qdrant.tech/) for long-term persistence.

## Table of Contents

* [Key Features](#key-features)
* [Memory vs Persistence](#memory-vs-persistence)
  * [Persistence](#persistence)
  * [Memory](#memory)
* [Recommended Architecture](#recommended-architecture)
* [Installation](#installation)
* [Usage Example (Redis + LangGraph)](#usage-example-redis--langgraph)
* [Ollama — MemoryOllama](#ollama--memoryollama)
* [Vector Database (QDrant)](#vector-database-qdrant)
* [Custom Text Embedding Model](#custom-text-embedding-model)
* [Docker Compose (Redis + Qdrant)](#docker-compose-redis--qdrant)
* [Grafana Logging](#grafana-logging)

---

## Key Features

* **Clear separation** between short-term memory (Redis) and long-term persistence (Qdrant).
* **LangGraph integration** for building LLM-based agents.
* **Redis for memory**:

  * Super-fast in-memory performance.
  * Multi-process support and distributed scalability.
  * TTL and automatic data expiration.
* **Qdrant for persistence**:

  * Vector similarity search (text, images, embeddings).
  * Advanced queries with filters, payloads, and metadata.
  * Scales to millions of vectors.
* **LLM support**: OpenAI and **Ollama**.
* **Easy installation** via `pip`.
* **Grafana/Loki compatible logging** for observability.
* **Local Hugging Face embeddings support** for air-gapped environments.

---

## Memory vs Persistence

When developing agents with LangGraph (or LLM-based systems in general), it’s crucial to distinguish between **memory** and **persistence**.

### Persistence

**Definition:** Permanent/long-term storage of information that can be retrieved across sessions.

**Examples:**

* Conversation history
* Vector embeddings and knowledge bases
* Agent logs and audits

**Characteristics:**

* Non-volatile (survives crashes and restarts)
* Searchable and queryable across history
* Scalable for long-term growth

**Why Qdrant for persistence?**

* Specialized vector engine (similarity search)
* Reliable disk persistence
* Powerful API with filtering, metadata, and payloads
* Handles millions of vectors efficiently

---

### Memory

**Definition:** Temporary, session-specific information kept only during the task lifecycle.

**Examples:**

* Current conversation state
* Temporary variables
* Volatile graph step context

**Characteristics:**

* Volatile (lost on restart)
* Extremely fast (RAM-based)
* Can be shared across multiple processes/instances

**Why Redis for memory?**

* High-performance in-RAM operations
* Multi-worker scalability
* Simple API
* TTL with auto-cleaning

---

## Recommended Architecture

| Function        | Recommended Database | Main Reason                                      |
| --------------- | -------------------- | ------------------------------------------------ |
| **Memory**      | Redis                | Performance, simplicity, TTL, multi-process      |
| **Persistence** | Qdrant               | Vector search, reliable persistence, scalability |

---

## Installation

```bash
pip install memory-agent
```

---

## Usage Example (Redis + LangGraph)

```python
from memory_agent import MemoryCheckPointer
from memory_agent.openai import MemoryOpenAI
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langchain.chat_models import init_chat_model
import os

os.environ["OPENAI_API_KEY"] = "sk-..."
llm = init_chat_model("openai:gpt-4.1")

class State(TypedDict):
    messages: Annotated[list, add_messages]

def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}

graph_builder = StateGraph(State)
graph_builder.add_node("chatbot", chatbot)
graph_builder.add_edge(START, "chatbot")

async def main(user_input, thread_id):
    mem = MemoryOpenAI(
        model_embedding_name="text-embedding-3-small",
        qdrant_url="http://localhost:6333",
        key_search="memory_agent"
    )

    # Redis as checkpoint manager (temporary memory)
    async with MemoryCheckpointer.from_conn_info(
        host="localhost", port=6379, db=0
    ) as checkpointer:

        # Delete checkpoints older than 15 minutes
        await checkpointer.adelete_by_thread_id(
            thread_id=thread_id,
            filter_minutes=15
        )

        graph = graph_builder.compile(
            checkpointer=checkpointer,               # Persistence of checkpoints
            store=mem.get_in_memory_store(),         # Long-term memory store
        )
        graph.name = "ChatBot"

        result = await graph.ainvoke(
            {"messages": [{"role": "human", "content": user_input}]},
            config={"configurable": {"thread_id": thread_id}, "recursion_limit": 25}
        )
        print(result)
```

The `key_search` parameter specifies a unique search key that identifies an agent’s message context. When the library is used by multiple agents, provide distinct `key_search` values to keep each agent’s memory separate.

---

## Ollama — MemoryOllama

If you use [Ollama](https://ollama.com/) (or want a local embeddings server), you can initialize **MemoryOllama** like this:

```python
from memory_agent.ollama import MemoryOllama

memory_store = MemoryOllama(
    model_embedding_name="nomic-embed-text",
    model_embedding_url="http://localhost:11434",
    qdrant_url="http://localhost:6333",
    key_search="memory_agent"
)
```

> Use `model_embedding_name` to select the embedding model available on Ollama (e.g., `nomic-embed-text`) and `model_embedding_url` to point to your local instance.

---

## Vector Database (QDrant)

You can use QDrant directly as a vector store (synchronous or asynchronous), even without Redis:

```python
from memory_agent import MemoryPersistence

qdrant = MemoryPersistence(
    model_embedding_vs_name="BAAI/bge-large-en-v1.5",
    qdrant_url="http://localhost:6333"
)
client = qdrant.get_client()
client_async = qdrant.get_client_async()
```

`model_embedding_vs_name` specifies the embedding model used by QDrant (default: `BAAI/bge-large-en-v1.5`).
For available embedding models, see QDrant’s embeddings documentation.

---

## Custom Text Embedding Model

For better performance or air-gapped environments, you can download Hugging Face embedding models locally and configure QDrant to use them.

**1) Install Hugging Face client**

```bash
pip install --upgrade huggingface_hub
```

**2) Create model directories**

```bash
mkdir -p /models/multilingual-e5-large
mkdir -p /models/bge-small-en-v1.5
mkdir -p /models/bge-large-en-v1.5
```

**3) Download models**

```bash
huggingface-cli download intfloat/multilingual-e5-large --local-dir /models/multilingual-e5-large
huggingface-cli download BAAI/bge-small-en-v1.5 --local-dir /models/bge-small-en-v1.5
huggingface-cli download BAAI/bge-large-en-v1.5 --local-dir /models/bge-large-en-v1.5
```

**4) Configure QDrant to use local models**

```python
from memory_agent import MemoryPersistence

qdrant = MemoryPersistence(
    model_embedding_vs_name="BAAI/bge-large-en-v1.5",
    model_embedding_vs_path="/models/bge-large-en-v1.5",
    model_embedding_vs_type="local",
    qdrant_url="http://localhost:6333"
)
client = qdrant.get_client()
client_async = qdrant.get_client_async()
```

---

## [Docker](./docker/README.md)
