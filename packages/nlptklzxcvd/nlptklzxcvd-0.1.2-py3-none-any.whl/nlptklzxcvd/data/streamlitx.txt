import streamlit as st
import nltk
import spacy
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer, WordNetLemmatizer

# Download NLTK data if not already present


# Download NLTK data if not already present
nltk.download('punkt')
nltk.download('punkt_tab')   # <-- add this line
nltk.download('wordnet')

import spacy
from spacy.cli import download

try:
    nlp = spacy.load("en_core_web_sm")
except OSError:
    # Auto-download if missing
    download("en_core_web_sm")
    nlp = spacy.load("en_core_web_sm")
# Streamlit UI
st.title("NLP Processing Tool")

st.write("Choose a task: Tokenization, Stemming & Lemmatization, or Named Entity Recognition (NER)")

# Text input box
user_text = st.text_area("Enter Text")

# Radio buttons for task selection
task = st.radio(
    "Select a Task",
    ("Tokenization", "Stemming & Lemmatization", "Named Entity Recognition (NER)")
)

if st.button("SUBMIT"):
    if user_text.strip() == "":
        st.warning("⚠️ Please enter some text first.")
    else:
        if task == "Tokenization":
            tokens = word_tokenize(user_text)
            st.subheader("Output Text")
            st.write(tokens)

        elif task == "Stemming & Lemmatization":
            ps = PorterStemmer()
            lemmatizer = WordNetLemmatizer()
            tokens = word_tokenize(user_text)
            stemmed = [ps.stem(w) for w in tokens]
            lemmatized = [lemmatizer.lemmatize(w) for w in tokens]

            st.subheader("Output Text")
            st.write("**Stemmed:** ", stemmed)
            st.write("**Lemmatized:** ", lemmatized)

        elif task == "Named Entity Recognition (NER)":
            doc = nlp(user_text)
            entities = [(ent.text, ent.label_) for ent in doc.ents]

            st.subheader("Output Text")
            if entities:
                st.write(entities)
            else:
                st.write("No entities found.")
