{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1Yh9i9SlaTq"
   },
   "source": [
    "***ML LAB CIA 2***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEflBCT-lgmq"
   },
   "source": [
    "**Q1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjDqH0JGlZlk",
    "outputId": "b476e41f-2c27-413b-a6f9-a118f9bc0b05"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features (sepal/petal dimensions)\n",
    "y = iris.target  # Labels (species: 0, 1, 2)\n",
    "\n",
    "# Preprocess data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = to_categorical(y)  # One-hot encode labels for SoftMax\n",
    "\n",
    "# Split data into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to build and evaluate the model\n",
    "def train_model(activation='softmax'):\n",
    "    model = Sequential([\n",
    "        Dense(16, activation='relu', input_shape=(4,)),  # Hidden layer\n",
    "        Dense(3, activation=activation)  # Output layer (SoftMax or Sigmoid)\n",
    "    ])\n",
    "\n",
    "    # Compile with categorical crossentropy for SoftMax, binary for Sigmoid\n",
    "    loss = 'categorical_crossentropy' if activation == 'softmax' else 'binary_crossentropy'\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(X_train, y_train, epochs=50, validation_split=0.2, verbose=0)\n",
    "\n",
    "    # Evaluate\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Activation: {activation}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Compare SoftMax vs. Sigmoid\n",
    "train_model(activation='softmax')  # Use this for multi-class (correct)\n",
    "train_model(activation='sigmoid')  # Incorrect for multi-class (for comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEFVF5sllivC"
   },
   "source": [
    "**Q2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "pQrKim1ylkGy",
    "outputId": "e2c55935-21c9-402a-aa00-03cbcffec7d3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(1000, 5)  # 5 socio-economic features\n",
    "y = X.dot(np.random.rand(5)) + np.random.rand(1000) * 0.1  # Grades (0-1 scale)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build model (with optional regularization)\n",
    "def build_model(use_regularization=False):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(5,)))  # Explicit input layer\n",
    "\n",
    "    # Hidden layers with conditional L2/dropout\n",
    "    reg = l2(0.01) if use_regularization else None\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=reg))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=reg))\n",
    "    if use_regularization:\n",
    "        model.add(Dropout(0.5))  # Only add dropout if regularization is enabled\n",
    "\n",
    "    model.add(Dense(1))  # Output layer (linear for regression)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Train without regularization (overfit)\n",
    "model_no_reg = build_model(use_regularization=False)\n",
    "history_no_reg = model_no_reg.fit(X_train, y_train, epochs=100,\n",
    "                                 validation_split=0.2, verbose=0)\n",
    "\n",
    "# Train with dropout + L2 (regularized)\n",
    "model_with_reg = build_model(use_regularization=True)\n",
    "history_with_reg = model_with_reg.fit(X_train, y_train, epochs=100,\n",
    "                                     validation_split=0.2, verbose=0)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_no_reg.history['val_loss'], label='No Regularization', linestyle='--')\n",
    "plt.plot(history_with_reg.history['val_loss'], label='With Dropout + L2', linestyle='--')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.title('Overfitting Mitigation with Regularization')\n",
    "plt.show()\n",
    "\n",
    "# Test performance\n",
    "print(\"Test MAE (No Regularization):\", model_no_reg.evaluate(X_test, y_test, verbose=0)[1])\n",
    "print(\"Test MAE (With Regularization):\", model_with_reg.evaluate(X_test, y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd5WFd9TloOS"
   },
   "source": [
    "**Q3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "vx4k9Z8-lprC",
    "outputId": "6de49e13-d025-453c-f84c-f316bea51680"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic insurance claim data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "X = np.random.rand(n_samples, 10)  # 10 features (e.g., age, BMI, medical history)\n",
    "y = X.dot(np.random.rand(10)) * 10000 + np.random.randn(n_samples) * 500  # Claim amounts ($)\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Function to build and train the model\n",
    "def train_model(use_regularization=False):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    if use_regularization:\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    else:\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))  # Output layer for regression\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=100,\n",
    "                       validation_split=0.2, verbose=0)\n",
    "    return model, history\n",
    "\n",
    "# Intentionally overfit (no regularization)\n",
    "model_overfit, history_overfit = train_model(use_regularization=False)\n",
    "\n",
    "# Apply regularization (dropout + L2)\n",
    "model_reg, history_reg = train_model(use_regularization=True)\n",
    "\n",
    "# Plot training vs validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_overfit.history['loss'], label='Train (Overfit)')\n",
    "plt.plot(history_overfit.history['val_loss'], label='Validation (Overfit)', linestyle='--')\n",
    "plt.plot(history_reg.history['val_loss'], label='Validation (Regularized)', linestyle='--')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.title('Overfitting vs. Regularization')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test data\n",
    "print(\"Test MAE (Overfit Model): ${:,.2f}\".format(model_overfit.evaluate(X_test, y_test, verbose=0)[1]))\n",
    "print(\"Test MAE (Regularized Model): ${:,.2f}\".format(model_reg.evaluate(X_test, y_test, verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNu_4025lsQZ"
   },
   "source": [
    "**Q4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0uyyJUlltZy",
    "outputId": "fa5a6938-fd8e-4873-b45c-974b776b3eaf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the hidden states and observations\n",
    "states = [\"Cooking\", \"Sleeping\", \"Watching TV\"]\n",
    "observations = [\"kitchen\", \"bedroom\", \"living room\"]\n",
    "\n",
    "# Create simulated sensor data sequences\n",
    "# Each sequence is a day's worth of room observations\n",
    "room_sequences = [\n",
    "    ['kitchen', 'bedroom', 'living room', 'kitchen', 'bedroom'],\n",
    "    ['kitchen', 'living room', 'living room', 'bedroom', 'bedroom'],\n",
    "    ['living room', 'kitchen', 'bedroom', 'kitchen', 'bedroom'],\n",
    "    ['bedroom', 'bedroom', 'living room', 'kitchen', 'living room']\n",
    "]\n",
    "\n",
    "# Convert observations to numerical values\n",
    "obs_map = {obs: i for i, obs in enumerate(observations)}\n",
    "num_sequences = len(room_sequences)\n",
    "sequence_lengths = [len(seq) for seq in room_sequences]\n",
    "X = np.concatenate([[obs_map[obs] for obs in seq] for seq in room_sequences]).reshape(-1, 1)\n",
    "\n",
    "# Build and train the HMM\n",
    "model = hmm.CategoricalHMM(n_components=len(states), random_state=42)\n",
    "model.fit(X, lengths=sequence_lengths)\n",
    "\n",
    "# Print learned parameters\n",
    "print(\"Start Probabilities:\", model.startprob_)\n",
    "print(\"\\nTransition Matrix:\")\n",
    "print(model.transmat_)\n",
    "print(\"\\nEmission Probabilities:\")\n",
    "print(model.emissionprob_)\n",
    "\n",
    "# Predict activities for a new sequence\n",
    "new_sequence = ['kitchen', 'living room', 'bedroom', 'kitchen']\n",
    "numeric_seq = np.array([obs_map[obs] for obs in new_sequence]).reshape(-1, 1)\n",
    "predicted_states = model.predict(numeric_seq)\n",
    "\n",
    "print(\"\\nPredicted Activities:\")\n",
    "for obs, state in zip(new_sequence, predicted_states):\n",
    "    print(f\"{obs} -> {states[state]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbmjRZU6lvOB"
   },
   "source": [
    "**Q5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4WLDsM_lyk6",
    "outputId": "5c54c8ac-8e0b-4c81-c5a0-b77cdb01af4f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# Define states and observations\n",
    "states = [\"Genuine\", \"Intruder\"]\n",
    "observations = [\"early\", \"mid\", \"late\"]  # Login times\n",
    "\n",
    "# Simulated login sequences (each sequence is a separate user's login pattern)\n",
    "sequences = [\n",
    "    ['early', 'early', 'mid', 'early', 'mid'],      # Genuine user 1\n",
    "    ['late', 'late', 'early', 'late', 'late'],      # Intruder 1\n",
    "    ['early', 'mid', 'early', 'mid', 'early'],      # Genuine user 2\n",
    "    ['mid', 'late', 'late', 'mid', 'late'],         # Intruder 2\n",
    "    ['early', 'early', 'early', 'mid', 'early'],    # Genuine user 3\n",
    "    ['late', 'mid', 'late', 'late', 'mid']          # Intruder 3\n",
    "]\n",
    "\n",
    "# Convert to numerical values and proper format\n",
    "obs_map = {obs: i for i, obs in enumerate(observations)}\n",
    "X = np.concatenate([[[obs_map[obs]] for obs in seq] for seq in sequences])\n",
    "lengths = [len(seq) for seq in sequences]  # All lengths are 5 in this case\n",
    "\n",
    "# Train HMM\n",
    "model = hmm.CategoricalHMM(\n",
    "    n_components=len(states),\n",
    "    random_state=42  # Increased iterations for better convergence\n",
    ")\n",
    "model.fit(X, lengths=lengths)\n",
    "\n",
    "# Print learned parameters\n",
    "print(\"Start Probabilities (Genuine vs Intruder):\\n\", model.startprob_)\n",
    "print(\"\\nTransition Matrix:\\n\", model.transmat_)\n",
    "print(\"\\nEmission Probabilities (Time of Day):\\n\", model.emissionprob_)\n",
    "\n",
    "# Predict on new sequences\n",
    "test_sequences = [\n",
    "    ['early', 'mid', 'early', 'mid', 'early'],    # Likely genuine\n",
    "    ['late', 'late', 'mid', 'late', 'late'],      # Likely intruder\n",
    "]\n",
    "\n",
    "for seq in test_sequences:\n",
    "    numeric_seq = np.array([[obs_map[obs]] for obs in seq])\n",
    "    logprob, state_sequence = model.decode(numeric_seq)\n",
    "    print(f\"\\nSequence: {seq}\")\n",
    "    print(\"Predicted States:\", [states[i] for i in state_sequence])\n",
    "    print(\"Log Probability:\", logprob)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
