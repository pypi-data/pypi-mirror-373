{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae20948",
   "metadata": {},
   "source": [
    "# This is DEV test notebook, not much useful around here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78882d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml4fmri imported from: /Users/ppopov1/meanMLP/src/ml4fmri\n",
      "ml4fmri ready\n"
     ]
    }
   ],
   "source": [
    "# module reloading script, fetches updates to ml4fmri package\n",
    "import sys, importlib\n",
    "from pathlib import Path\n",
    "\n",
    "PKG = \"ml4fmri\"\n",
    "# adjust as needed; this assumes your repo root is the CWD and sources are in ../src\n",
    "SRC = Path().joinpath(\"../src\").resolve()\n",
    "\n",
    "def _ensure_src_on_path():\n",
    "    p = str(SRC)\n",
    "    if p not in sys.path:\n",
    "        sys.path.insert(0, p)\n",
    "\n",
    "def fresh_import_ml4fmri():\n",
    "    \"\"\"\n",
    "    Remove any cached ml4fmri modules and import from SRC.\n",
    "    Returns the ml4fmri module and (if available) meanMLP class.\n",
    "    \"\"\"\n",
    "    _ensure_src_on_path()\n",
    "\n",
    "    # purge previous imports so code changes take effect\n",
    "    to_delete = [k for k in list(sys.modules) if k == PKG or k.startswith(PKG + \".\")]\n",
    "    for k in to_delete:\n",
    "        del sys.modules[k]\n",
    "\n",
    "    importlib.invalidate_caches()\n",
    "\n",
    "    ml4fmri = __import__(PKG)\n",
    "    meanMLP = None\n",
    "    try:\n",
    "        from ml4fmri.models import meanMLP \n",
    "    except Exception as e:\n",
    "        print(\"Note: could not import meanMLP yet:\", e)\n",
    "\n",
    "    try:\n",
    "        import inspect\n",
    "        print(\"ml4fmri imported from:\", Path(inspect.getfile(ml4fmri)).parent)\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(\"ml4fmri ready\")\n",
    "    return ml4fmri\n",
    "\n",
    "# --- first import (or manual reload later) ---\n",
    "ml4fmri = fresh_import_ml4fmri()\n",
    "\n",
    "# get sample data for experiments\n",
    "from abide import load_data as load_abide\n",
    "from cobre import load_data as load_cobre\n",
    "\n",
    "data, labels = load_abide()\n",
    "data.shape, labels.shape\n",
    "\n",
    "data, labels = data[:100], labels[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b5a71b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abide import load_data as load_abide\n",
    "from cobre import load_data as load_cobre\n",
    "\n",
    "data, labels = load_abide()\n",
    "DATA, LABELS = data, labels\n",
    "data.shape, labels.shape\n",
    "\n",
    "data, labels = data[50:150], labels[50:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml4fmri = fresh_import_ml4fmri()\n",
    "from ml4fmri import cvbench # runs CV experiments with implemented models on the given data\n",
    "report = cvbench(data, labels, n_folds=10)\n",
    "# report = cvbench(data, labels, models='lite', n_folds=2)\n",
    "# report = cvbench(data, labels, models='LR', n_folds=2)\n",
    "report.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14efaa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report.plot_scores_h()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1e336",
   "metadata": {},
   "source": [
    "# test cvbench model socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aac320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.nn.functional import cross_entropy, mse_loss\n",
    "\n",
    "from ml4fmri.models.helper_functions import basic_ce_loss, basic_handle_batch, basic_dataloader, basic_Adam_optimizer, BasicTrainer\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    TIME SERIES MODEL\n",
    "\n",
    "    Vanilla-style LSTM classifier for fMRI data from https://doi.org/10.1016/j.neuroimage.2024.120909.\n",
    "    Expected input shape: [batch_size, time_length, input_feature_size].\n",
    "    Output: [batch_size, n_classes]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size: int,\n",
    "            output_size: int,\n",
    "            hidden_size: int = 210,\n",
    "            num_layers: int = 1,\n",
    "            bidirectional: bool = False,\n",
    "            dropout: float = 0.5,\n",
    "            lr: float = 4e-5,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize LSTM model.\n",
    "        Args:\n",
    "            input_size (int): Size of the vector at each time step in the input time series. \\\n",
    "                Common to all models, for FNC models it is the number of nodes (width or length) in the FNC matrix.\n",
    "            output_size (int): Number of classes for classification. \\\n",
    "                Common to all models.\n",
    "            hidden_size (int, hyperparameter): LSTM hidden size. Defaults to 210.\n",
    "            num_layers (int, hyperparameter): Number of LSTM layers. Defaults to 1.\n",
    "            bidirectional (bool, hyperparameter): Whether to use a bidirectional LSTM. Defaults to True.\n",
    "            dropout (float, hyperparameter): Dropout rate for classifier. Defaults to 0.5.\n",
    "            lr (float, hyperparameter): Learning rate for the optimizer. Defaults to 4e-5. \\\n",
    "                Common to all models. Isn't used by the model per se, presented as a reference LR from the paper. \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lr = lr  # learning rate used in the paper. Defined like this in every model for reference.\n",
    "\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "\n",
    "        lstm_output_size = 2 * hidden_size if bidirectional else hidden_size\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(\n",
    "                lstm_output_size,\n",
    "                lstm_output_size,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(\n",
    "                lstm_output_size,\n",
    "                input_size,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(\n",
    "                lstm_output_size,\n",
    "                output_size,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_output, _ = self.lstm(x)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            out_forward = lstm_output[:, -1, : self.hidden_size]\n",
    "            out_reverse = lstm_output[:, 0, self.hidden_size :]\n",
    "            lstm_output_clf = torch.cat((out_forward, out_reverse), 1)\n",
    "        else:\n",
    "            lstm_output_clf = lstm_output[:, -1, :]\n",
    "\n",
    "        preds = self.predictor(lstm_output[:, :-1, :])\n",
    "        origs = x[:, 1:, :]\n",
    "\n",
    "        ts_logits = self.clf(lstm_output)\n",
    "        logits = ts_logits.mean(axis=1)\n",
    "\n",
    "        return logits, {\"logits\": logits, \"preds\": preds, \"origs\": origs, \"ts_logits\": ts_logits}\n",
    "\n",
    "    #### Helper functions for model training and evaluation ####\n",
    "\n",
    "    def compute_loss(self, loss_load, targets):\n",
    "        \"\"\"\n",
    "        Standard loss computation routine for models.\n",
    "        Args:\n",
    "            loss_load (dict): Forward's second output for the batch.\n",
    "            targets (torch.Tensor): True labels for the batch.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor\n",
    "            Loss for backpropagation.\n",
    "        logs : dict\n",
    "            Dictionary containing the loss components for logs.\n",
    "        \"\"\"\n",
    "\n",
    "        ce_loss = cross_entropy(loss_load[\"logits\"], targets)\n",
    "        pred_loss = mse_loss(loss_load[\"preds\"], loss_load[\"origs\"])\n",
    "\n",
    "        loss = ce_loss + pred_loss\n",
    "\n",
    "        return loss, {\"CE_loss\": float(ce_loss.detach().cpu().item()), \"Pred_loss\": float(pred_loss.detach().cpu().item())}\n",
    "\n",
    "    def handle_batch(self, batch):\n",
    "        \"\"\"\n",
    "        Standard batch handling routine for models. \n",
    "        Returns loss for backprop and a dictionary of classification metrics and losses for logs.\n",
    "        \n",
    "        Args:\n",
    "            batch (tuple): A batch containing the time series data and labels as a tuple.\n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor\n",
    "            Loss for backpropagation.\n",
    "        batch_log : dict\n",
    "            Dictionary of classification metrics and losses for logs.\n",
    "        \"\"\"\n",
    "\n",
    "        loss, batch_log = basic_handle_batch(self, batch)\n",
    "        return loss, batch_log\n",
    "    \n",
    "    def get_optimizer(self, lr=None):\n",
    "        \"\"\"\n",
    "        Standard optimizer getter routine for models.\n",
    "        \"\"\"\n",
    "        if lr is None:\n",
    "            lr = self.lr\n",
    "        return basic_Adam_optimizer(self, lr)\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_dataloader(data,\n",
    "                           labels,\n",
    "                           batch_size: int = 64,\n",
    "                           shuffle: bool = True):\n",
    "        \"\"\"\n",
    "        Returns torch DataLoader that produces appropriate batches for the model (can pass to `handle_batch`)\n",
    "        Args:\n",
    "            data (array-like): Time series data of shape (B, T, D).\n",
    "            labels (array-like): Class labels for the data.\n",
    "            batch_size (int, optional): Batch size for the DataLoader. Defaults to 64.\n",
    "            shuffle (bool, optional): Whether to shuffle batching in the DataLoader. Defaults to True.\n",
    "        \n",
    "        Returns:\n",
    "            DataLoader: A PyTorch DataLoader generating the batches of time series data and labels. \n",
    "        \"\"\"\n",
    "        return basic_dataloader(data,\n",
    "                                labels,\n",
    "                                type=\"TS\",\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=shuffle)\n",
    "    \n",
    "    def train_model(self,\n",
    "              train_loader,\n",
    "              val_loader,\n",
    "              test_loader,\n",
    "              epochs: int = 200,\n",
    "              lr: float = None,\n",
    "              device: str = None,\n",
    "              patience: int = 30,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Standard model training routine.\n",
    "        Args:\n",
    "            train_loader (DataLoader): DataLoader for the training set. Used for training.\n",
    "            val_loader (DataLoader): DataLoader for the validation set. Used during training to find most generalizable model.\n",
    "            test_loader (DataLoader): DataLoader for the test set.\n",
    "            epochs (int, optional): Number of training epochs. Defaults to 200.\n",
    "            lr (float, optional): Optimizer learning rate (default: use model's self.lr).\n",
    "            device (str, optional): Device to train the model on: \"cuda\", \"mps\", or \"cpu\". Default: auto-detect (cuda -> mps -> cpu).\n",
    "            patience (int, optional): Early stopping patience (in epochs). Defaults to 30.\n",
    "        Returns\n",
    "        -------\n",
    "        (train_logs, test_logs)\n",
    "            Training and test dataframes containing loss and accuracy metrics.\n",
    "        \"\"\"\n",
    "        \n",
    "        trainer = BasicTrainer(\n",
    "            model=self,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            epochs=epochs,\n",
    "            lr=lr,\n",
    "            device=device,\n",
    "            patience=patience,\n",
    "        )\n",
    "\n",
    "        train_logs, test_logs = trainer.run()\n",
    "        return train_logs, test_logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb84d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml4fmri = fresh_import_ml4fmri()\n",
    "from ml4fmri import cvbench # runs CV experiments with implemented models on the given data\n",
    "# report = cvbench(data, labels, n_folds=10)\n",
    "report = cvbench(data, labels, models=[\"meanMLP\", \"LSTM\"], custom_models=[LSTM], n_folds=5)\n",
    "# report = cvbench(data, labels, models=[\"meanMLP\", \"LSTM\"], n_folds=5)\n",
    "report.plot_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb82cb",
   "metadata": {},
   "source": [
    "# test cvbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a00df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cvbench INFO: Got DATA in shape (569, 140, 53) and LABELS in shape (569,)\n",
      "cvbench INFO: Unique labels: [0 1], Counts: [255 314]\n",
      "cvbench INFO: Using device: <built-in function all>\n",
      "cvbench INFO: Running models: ['LR', 'meanMLP', 'MILC', 'Transformer', 'meanTransformer', 'BNT', 'BrainNetCNN', 'LSTM', 'meanLSTM', 'FBNetGen', 'DICE', 'Glacier', 'BolT']\n",
      "cvbench INFO: Training model: LR\n",
      "cvbench.LR INFO: Fold 01/02: Train/Val/Test AUC 1.000/1.000/0.707: Time elapsed 0.13 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml4fmri imported from: /Users/ppopov1/meanMLP/src/ml4fmri\n",
      "ml4fmri ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cvbench.LR INFO: Fold 02/02: Train/Val/Test AUC 1.000/1.000/0.718: Time elapsed 0.11 s\n",
      "cvbench INFO: Training model: meanMLP\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "device() received an invalid combination of arguments - got (builtin_function_or_method), but expected one of:\n * (torch.device device)\n      didn't match because some of the arguments have invalid types: (!builtin_function_or_method!)\n * (str type, int index = -1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml4fmri\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cvbench \u001b[38;5;66;03m# runs CV experiments with implemented models on the given data\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# report = cvbench(data, labels, n_folds=10)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m report = \u001b[43mcvbench\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mall\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m report.plot_scores()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/meanMLP/src/ml4fmri/cvreport.py:257\u001b[39m, in \u001b[36mcvbench\u001b[39m\u001b[34m(data, labels, models, custom_models, n_folds, val_ratio, random_state, epochs, lr, device, patience)\u001b[39m\n\u001b[32m    254\u001b[39m model = model_class(input_size=D, output_size=C)\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m train_df, test_df = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m time_elapsed = time.time() - start\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# Annotate and save logs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/meanMLP/src/ml4fmri/models/meanMLP.py:174\u001b[39m, in \u001b[36mmeanMLP.train_model\u001b[39m\u001b[34m(self, train_loader, val_loader, test_loader, epochs, lr, device, patience)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    150\u001b[39m           train_loader,\n\u001b[32m    151\u001b[39m           val_loader,\n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m           patience: \u001b[38;5;28mint\u001b[39m = \u001b[32m30\u001b[39m,\n\u001b[32m    157\u001b[39m     ):\n\u001b[32m    158\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    Standard model training routine.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    171\u001b[39m \u001b[33;03m        Training and test dataframes containing loss and accuracy metrics.\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     trainer = \u001b[43mBasicTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     train_logs, test_logs = trainer.run()\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_logs, test_logs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/meanMLP/src/ml4fmri/models/helper_functions.py:252\u001b[39m, in \u001b[36mBasicTrainer.__init__\u001b[39m\u001b[34m(self, model, train_loader, val_loader, test_loader, epochs, lr, device, patience)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28mself\u001b[39m.lr = lr\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     \u001b[38;5;28mself\u001b[39m.device = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    254\u001b[39m     \u001b[38;5;28mself\u001b[39m.device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \\\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m torch.device(\u001b[33m\"\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch.backends.mps.is_available() \\\n\u001b[32m    256\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: device() received an invalid combination of arguments - got (builtin_function_or_method), but expected one of:\n * (torch.device device)\n      didn't match because some of the arguments have invalid types: (!builtin_function_or_method!)\n * (str type, int index = -1)\n"
     ]
    }
   ],
   "source": [
    "ml4fmri = fresh_import_ml4fmri()\n",
    "from ml4fmri import cvbench # runs CV experiments with implemented models on the given data\n",
    "# report = cvbench(data, labels, n_folds=10)\n",
    "report = cvbench(data, labels, device=all, n_folds=2)\n",
    "report.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2aa9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml4fmri = fresh_import_ml4fmri()\n",
    "from ml4fmri import cvbench # runs CV experiments with implemented models on the given data\n",
    "# report = cvbench(data, labels, n_folds=10)\n",
    "report = cvbench(data, labels, device=\"mps\", n_folds=10)\n",
    "report.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.plot_scores_h(metric='test_f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8755cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract report dataframes\n",
    "\n",
    "test_df = report.get_test_dataframe() # returns dataframe with test metrics: \n",
    "# classification metrics and loss on the test data and training time per fold for each model.\n",
    "# Useful for model comparison.\n",
    "\n",
    "train_df = report.get_train_dataframe() # returns dataframe with training logs: \n",
    "# losses and classification metrics on the training and validation data per fold for each model. \n",
    "# Useful for training inspection.\n",
    "\n",
    "meta_df = report.get_meta() # dictionary with metadata about the training process:\n",
    "# ['models', 'n_folds', 'val_ratio', 'random_state', 'input_size', 'n_classes', 'train_indices', 'val_indices', 'test_indices']\n",
    "# the last 3 give you CV indices per fold, so that you can potentially replicate the splits in your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ebdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.plot_training_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4246653",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = report.get_train_dataframe()\n",
    "test_df = report.get_test_dataframe()\n",
    "meta = report.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ebf969",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.save() # saves the report to disk: \n",
    "# cvbench_train.csv with train dataframe, \n",
    "# cvbench_test.csv with test dataframe,\n",
    "# cvbench_meta.json with metadata,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meanmlp-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
