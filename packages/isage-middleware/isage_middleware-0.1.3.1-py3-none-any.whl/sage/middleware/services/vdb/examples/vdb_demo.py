"""
VDB Service API ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•æ­£ç¡®ä½¿ç”¨VDBå¾®æœåŠ¡çš„APIæ¥å£è¿›è¡Œå‘é‡å­˜å‚¨å’Œç›¸ä¼¼æ€§æœç´¢
"""
import numpy as np
from sage.core.api.local_environment import LocalEnvironment
from sage.middleware.services.vdb import create_vdb_service_factory
from sage.middleware.api.vdb_api import VDBServiceAPI


def test_vdb_service_api():
    """æµ‹è¯•VDBæœåŠ¡APIçš„æ­£ç¡®ä½¿ç”¨æ–¹å¼"""
    print("ğŸš€ VDB Service API Demo")
    print("=" * 50)
    
    # åˆ›å»ºç¯å¢ƒ
    env = LocalEnvironment("vdb_service_demo")
    
    # æ³¨å†ŒVDBæœåŠ¡ - FAISSåç«¯
    vdb_factory = create_vdb_service_factory(
        service_name="demo_vdb_service",
        embedding_dimension=384,
        index_type="IndexFlatL2",  # ç²¾ç¡®æœç´¢
        max_vectors=100000,
        similarity_threshold=0.8
    )
    env.register_service_factory("demo_vdb_service", vdb_factory)
    
    print("âœ… VDB Service registered with FAISS backend")
    print("   - Index: IndexFlatL2 (ç²¾ç¡®L2è·ç¦»)")
    print("   - Dimension: 384")
    print("   - Max vectors: 100,000")
    print("   - Similarity threshold: 0.8")
    
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä½ éœ€è¦å¯åŠ¨ç¯å¢ƒå¹¶è·å–æœåŠ¡ä»£ç†
    # env.submit()  # å¯åŠ¨ç¯å¢ƒ
    # vdb_service = env.get_service_proxy("demo_vdb_service")
    
    # è¿™é‡Œæˆ‘ä»¬æ¼”ç¤ºAPIæ¥å£çš„é¢„æœŸä½¿ç”¨æ–¹å¼
    demonstrate_vdb_api_usage()


def demonstrate_vdb_api_usage():
    """æ¼”ç¤ºVDBæœåŠ¡APIçš„æ ‡å‡†ä½¿ç”¨æ¨¡å¼"""
    print("\nğŸ“ VDB Service API Usage Patterns:")
    print("-" * 40)
    
    # å±•ç¤ºAPIæ¥å£
    print("ğŸ’¡ VDB Service API Interface:")
    print("   class VDBServiceAPI:")
    print("     - add_vectors(documents: List[Dict]) -> List[str]")
    print("     - search(query_vector, top_k, threshold) -> List[Dict]")
    print("     - get_vector(doc_id: str) -> Optional[Dict]")
    print("     - delete_vectors(doc_ids: List[str]) -> bool")
    print("     - update_vector(doc_id: str, document: Dict) -> bool")
    print("     - count() -> int")
    print("     - save_index(path: str) -> bool")
    print("     - load_index(path: str) -> bool")
    
    print("\nğŸ“‹ Standard Usage Example:")
    usage_code = '''
# 1. è·å–æœåŠ¡ä»£ç†
vdb_service = env.get_service_proxy("demo_vdb_service")

# 2. å‡†å¤‡å‘é‡æ–‡æ¡£
documents = [
    {
        "id": "doc_001",
        "vector": np.random.random(384).tolist(),  # 384ç»´å‘é‡
        "text": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€",
        "metadata": {
            "category": "programming", 
            "language": "python",
            "topic": "introduction"
        }
    },
    {
        "id": "doc_002", 
        "vector": np.random.random(384).tolist(),
        "text": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯",
        "metadata": {
            "category": "ai",
            "topic": "machine_learning"
        }
    }
]

# 3. æ·»åŠ å‘é‡åˆ°æ•°æ®åº“
doc_ids = vdb_service.add_vectors(documents)
print(f"Added documents: {doc_ids}")

# 4. å‘é‡ç›¸ä¼¼æ€§æœç´¢
query_vector = np.random.random(384).tolist()
search_results = vdb_service.search(
    query_vector=query_vector,
    top_k=5,
    similarity_threshold=0.8
)

# 5. è·å–ç‰¹å®šæ–‡æ¡£
document = vdb_service.get_vector("doc_001")

# 6. æ›´æ–°æ–‡æ¡£
updated_doc = {
    "id": "doc_001",
    "vector": np.random.random(384).tolist(),
    "text": "Pythonæ˜¯ä¸€ç§å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºæ•°æ®ç§‘å­¦",
    "metadata": {"category": "programming", "updated": True}
}
success = vdb_service.update_vector("doc_001", updated_doc)

# 7. ç®¡ç†æ“ä½œ
total_count = vdb_service.count()
saved = vdb_service.save_index("/path/to/index")
'''
    print(usage_code)
    
    # æ¨¡æ‹Ÿæ‰§è¡Œç»“æœ
    print("ğŸ¯ Expected Results:")
    operations = [
        ("add_vectors(documents)", "['doc_001', 'doc_002']"),
        ("search(query_vector, top_k=5)", "[{'id': 'doc_001', 'score': 0.92, ...}]"),
        ("get_vector('doc_001')", "{'id': 'doc_001', 'vector': [...], 'text': '...'}"),
        ("update_vector('doc_001', updated_doc)", "True"),
        ("count()", "2"),
        ("save_index('/path/to/index')", "True"),
    ]
    
    for operation, result in operations:
        print(f"   {operation:<35} -> {result}")


def demonstrate_semantic_search_patterns():
    """æ¼”ç¤ºè¯­ä¹‰æœç´¢çš„é«˜çº§æ¨¡å¼"""
    print("\nğŸ” Semantic Search Patterns:")
    print("-" * 40)
    
    search_patterns = '''
# 1. å¤šæ¨¡æ€æ–‡æ¡£æœç´¢
class DocumentSearchEngine:
    def __init__(self, vdb_service: VDBServiceAPI):
        self.vdb = vdb_service
    
    def index_document(self, doc_id: str, title: str, content: str, 
                      title_embedding: List[float], content_embedding: List[float]):
        """ç´¢å¼•æ–‡æ¡£çš„æ ‡é¢˜å’Œå†…å®¹"""
        # ç´¢å¼•æ ‡é¢˜
        title_doc = {
            "id": f"{doc_id}_title",
            "vector": title_embedding,
            "text": title,
            "metadata": {"type": "title", "parent_doc": doc_id}
        }
        
        # ç´¢å¼•å†…å®¹
        content_doc = {
            "id": f"{doc_id}_content", 
            "vector": content_embedding,
            "text": content,
            "metadata": {"type": "content", "parent_doc": doc_id}
        }
        
        return self.vdb.add_vectors([title_doc, content_doc])
    
    def semantic_search(self, query_embedding: List[float], doc_type=None):
        """è¯­ä¹‰æœç´¢"""
        results = self.vdb.search(
            query_vector=query_embedding,
            top_k=20,
            similarity_threshold=0.7
        )
        
        # æŒ‰æ–‡æ¡£ç±»å‹è¿‡æ»¤
        if doc_type:
            results = [r for r in results if r["metadata"]["type"] == doc_type]
        
        return results

# 2. åˆ†å±‚æ£€ç´¢
class HierarchicalRetrieval:
    def __init__(self, vdb_service: VDBServiceAPI):
        self.vdb = vdb_service
    
    def coarse_to_fine_search(self, query_vector: List[float]):
        """ç²—åˆ°ç»†çš„æ£€ç´¢ç­–ç•¥"""
        # ç¬¬ä¸€é˜¶æ®µï¼šç²—ç²’åº¦æœç´¢ï¼ˆæ›´å¤šç»“æœï¼Œè¾ƒä½é˜ˆå€¼ï¼‰
        coarse_results = self.vdb.search(
            query_vector=query_vector,
            top_k=100,
            similarity_threshold=0.6
        )
        
        # ç¬¬äºŒé˜¶æ®µï¼šç»†ç²’åº¦é‡æ’åºï¼ˆåŸºäºæ›´å¤æ‚çš„ç›¸ä¼¼æ€§è®¡ç®—ï¼‰
        fine_results = self.rerank_results(query_vector, coarse_results)
        
        return fine_results[:10]  # è¿”å›top 10
    
    def rerank_results(self, query_vector, candidates):
        """é‡æ’åºå€™é€‰ç»“æœ"""
        # è¿™é‡Œå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ç›¸ä¼¼æ€§è®¡ç®—
        # ä¾‹å¦‚ï¼šè€ƒè™‘metadataæƒé‡ã€æ—¶é—´è¡°å‡ç­‰
        return sorted(candidates, key=lambda x: x["score"], reverse=True)

# 3. å®æ—¶æ›´æ–°ç´¢å¼•
class RealTimeIndex:
    def __init__(self, vdb_service: VDBServiceAPI):
        self.vdb = vdb_service
        self.pending_updates = []
    
    def add_document_async(self, document: Dict):
        """å¼‚æ­¥æ·»åŠ æ–‡æ¡£"""
        self.pending_updates.append(('add', document))
        
        # æ‰¹é‡å¤„ç†
        if len(self.pending_updates) >= 100:
            self.flush_updates()
    
    def flush_updates(self):
        """æ‰¹é‡æ‰§è¡Œæ›´æ–°"""
        add_docs = [doc for action, doc in self.pending_updates if action == 'add']
        
        if add_docs:
            self.vdb.add_vectors(add_docs)
        
        self.pending_updates.clear()
'''
    print(search_patterns)


def demonstrate_vector_management():
    """æ¼”ç¤ºå‘é‡ç®¡ç†çš„æœ€ä½³å®è·µ"""
    print("\nğŸ—‚ï¸ Vector Management Best Practices:")
    print("-" * 40)
    
    management_patterns = '''
# 1. å‘é‡ç‰ˆæœ¬ç®¡ç†
class VectorVersionManager:
    def __init__(self, vdb_service: VDBServiceAPI):
        self.vdb = vdb_service
    
    def add_versioned_vector(self, base_id: str, vector: List[float], 
                           text: str, version: int = 1):
        """æ·»åŠ å¸¦ç‰ˆæœ¬çš„å‘é‡"""
        doc_id = f"{base_id}_v{version}"
        document = {
            "id": doc_id,
            "vector": vector,
            "text": text,
            "metadata": {
                "base_id": base_id,
                "version": version,
                "is_latest": True
            }
        }
        
        # å°†æ—§ç‰ˆæœ¬æ ‡è®°ä¸ºéæœ€æ–°
        old_versions = self.get_all_versions(base_id)
        for old_doc in old_versions:
            old_doc["metadata"]["is_latest"] = False
            self.vdb.update_vector(old_doc["id"], old_doc)
        
        return self.vdb.add_vectors([document])
    
    def get_latest_version(self, base_id: str):
        """è·å–æœ€æ–°ç‰ˆæœ¬"""
        # è¿™éœ€è¦ç»“åˆmetadataæœç´¢åŠŸèƒ½
        pass

# 2. ç´¢å¼•ä¼˜åŒ–
class IndexOptimizer:
    def __init__(self, vdb_service: VDBServiceAPI):
        self.vdb = vdb_service
    
    def optimize_index(self):
        """ä¼˜åŒ–ç´¢å¼•æ€§èƒ½"""
        # ä¿å­˜å½“å‰ç´¢å¼•
        backup_path = f"/backup/index_{int(time.time())}"
        self.vdb.save_index(backup_path)
        
        # é‡å»ºç´¢å¼•ï¼ˆå¦‚æœæ”¯æŒï¼‰
        # self.vdb.rebuild_index()
        
        print(f"Index optimized, backup saved to {backup_path}")
    
    def cleanup_old_vectors(self, retention_days: int = 30):
        """æ¸…ç†æ—§å‘é‡"""
        cutoff_time = time.time() - (retention_days * 24 * 3600)
        
        # è¿™éœ€è¦ç»“åˆtimestamp metadata
        # old_docs = self.find_vectors_before(cutoff_time)
        # self.vdb.delete_vectors([doc["id"] for doc in old_docs])

# 3. ç›‘æ§å’Œåº¦é‡
class VDBMonitor:
    def __init__(self, vdb_service: VDBServiceAPI):
        self.vdb = vdb_service
    
    def get_health_metrics(self):
        """è·å–å¥åº·åº¦é‡"""
        return {
            "total_vectors": self.vdb.count(),
            "index_size": "è®¡ç®—ç´¢å¼•å¤§å°",
            "average_query_time": "æŸ¥è¯¢å¹³å‡è€—æ—¶",
            "memory_usage": "å†…å­˜ä½¿ç”¨æƒ…å†µ"
        }
'''
    print(management_patterns)
    
    # æ¨¡æ‹Ÿå‘é‡æ•°æ®
    print("\nğŸ“ VDB Operations Demo:")
    
    # ç”Ÿæˆç¤ºä¾‹å‘é‡
    vectors = []
    for i in range(5):
        vector = np.random.random(384).tolist()
        vectors.append({
            "id": f"doc_{i}",
            "vector": vector,
            "text": f"è¿™æ˜¯ç¬¬{i}ä¸ªæ–‡æ¡£çš„å†…å®¹",
            "metadata": {
                "source": "demo",
                "type": "document",
                "index": i
            }
        })
    
    print(f"  add_vectors({len(vectors)} docs) -> âœ… Added 5 vectors")
    
    # æœç´¢ç¤ºä¾‹
    query_vector = np.random.random(384).tolist()
    print(f"  search_vectors(query, top_k=3) -> ğŸ“– Found 3 similar documents")
    print(f"    - doc_2 (distance: 0.89)")
    print(f"    - doc_1 (distance: 0.91)")
    print(f"    - doc_4 (distance: 0.93)")
    
    # å…¶ä»–æ“ä½œ
    print(f"  get_vector('doc_1') -> ğŸ“– Retrieved document")
    print(f"  count() -> ğŸ“Š 5 vectors")
    print(f"  delete_vectors(['doc_0']) -> ğŸ—‘ï¸  Deleted 1 vector")
    print(f"  list_vectors(filter={{'type': 'document'}}) -> ğŸ“‹ 4 documents")
    
    print("\nğŸ’¡ VDB Service Features:")
    print("   - FAISSé«˜æ€§èƒ½å‘é‡æ£€ç´¢")
    print("   - å¤šç§ç´¢å¼•ç±»å‹ (Flat, HNSW, IVF, PQ)")
    print("   - å…ƒæ•°æ®è¿‡æ»¤")
    print("   - å‘é‡æŒä¹…åŒ–")
    print("   - ç›¸ä¼¼åº¦æœç´¢")


def test_vdb_index_types():
    """æ¼”ç¤ºä¸åŒçš„FAISSç´¢å¼•ç±»å‹"""
    print("\nğŸ”§ FAISS Index Types:")
    
    index_configs = {
        "IndexFlatL2": {
            "description": "ç²¾ç¡®L2è·ç¦»æœç´¢ï¼Œé€‚åˆå°æ•°æ®é›†",
            "config": {}
        },
        "IndexHNSWFlat": {
            "description": "HNSWå›¾ç´¢å¼•ï¼Œå¿«é€Ÿè¿‘ä¼¼æœç´¢",
            "config": {
                "HNSW_M": 32,
                "HNSW_EF_CONSTRUCTION": 200,
                "HNSW_EF_SEARCH": 50
            }
        },
        "IndexIVFFlat": {
            "description": "IVFå€’æ’ç´¢å¼•ï¼Œé€‚åˆå¤§æ•°æ®é›†",
            "config": {
                "IVF_NLIST": 100,
                "IVF_NPROBE": 10
            }
        },
        "IndexIVFPQ": {
            "description": "IVF+PQé‡åŒ–ï¼Œå†…å­˜é«˜æ•ˆ",
            "config": {
                "IVF_NLIST": 100,
                "IVF_NPROBE": 10,
                "PQ_M": 8,
                "PQ_NBITS": 8
            }
        }
    }
    
    for index_type, info in index_configs.items():
        vdb_factory = create_vdb_service_factory(
            service_name=f"vdb_{index_type.lower()}",
            embedding_dimension=384,
            index_type=index_type,
            faiss_config=info["config"]
        )
        print(f"âœ… {index_type}: {info['description']}")


def test_vdb_applications():
    """æ¼”ç¤ºVDBæœåŠ¡çš„åº”ç”¨åœºæ™¯"""
    print("\nğŸ¯ VDB Service Applications:")
    
    applications = [
        {
            "name": "è¯­ä¹‰æœç´¢",
            "config": {
                "embedding_dimension": 768,
                "index_type": "IndexHNSWFlat",
                "faiss_config": {"HNSW_M": 64}
            },
            "description": "æœç´¢è¯­ä¹‰ç›¸ä¼¼çš„æ–‡æ¡£"
        },
        {
            "name": "æ¨èç³»ç»Ÿ",
            "config": {
                "embedding_dimension": 256,
                "index_type": "IndexIVFPQ",
                "faiss_config": {"IVF_NLIST": 1000, "PQ_M": 16}
            },
            "description": "åŸºäºç”¨æˆ·å‘é‡æ¨èç›¸ä¼¼ç‰©å“"
        },
        {
            "name": "å›¾åƒæ£€ç´¢",
            "config": {
                "embedding_dimension": 2048,
                "index_type": "IndexFlatL2"
            },
            "description": "æŸ¥æ‰¾è§†è§‰ç›¸ä¼¼çš„å›¾åƒ"
        },
        {
            "name": "çŸ¥è¯†åº“æ£€ç´¢",
            "config": {
                "embedding_dimension": 384,
                "index_type": "IndexIVFFlat",
                "faiss_config": {"IVF_NLIST": 500}
            },
            "description": "RAGåº”ç”¨ä¸­çš„çŸ¥è¯†æ£€ç´¢"
        }
    ]
    
    for app in applications:
        print(f"  ğŸ“š {app['name']}: {app['description']}")
        print(f"      é…ç½®: {app['config']}")


if __name__ == "__main__":
    test_vdb_service_api()
    demonstrate_semantic_search_patterns()
    demonstrate_vector_management()
    print("\nğŸ¯ VDB Service API demo completed!")
    print("\nğŸ“š Next: Check Memory service API examples")
