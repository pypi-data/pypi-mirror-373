Metadata-Version: 2.1
Name: netspresso
Version: 1.16.1
Summary: PyNetsPresso
Home-page: https://github.com/Nota-NetsPresso/PyNetsPresso
Author: NetsPresso
Author-email: netspresso@nota.ai
License: UNKNOWN
Platform: UNKNOWN
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: urllib3
Requires-Dist: requests
Requires-Dist: loguru>=0.7.0
Requires-Dist: PyJWT>=2.7.0
Requires-Dist: email-validator>=2.0.0
Requires-Dist: pytz>=2023.3
Requires-Dist: netspresso-trainer==1.3.1
Requires-Dist: PyGithub>=2.1.1
Requires-Dist: matplotlib>=3.7.4
Requires-Dist: aenum>=3.1.15
Requires-Dist: requests-toolbelt>=1.0.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: netspresso-inference-package==0.1.4
Requires-Dist: scipy
Requires-Dist: qai-hub==0.29.0

<div align=right>
  <a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2FNota-NetsPresso%2Fnetspresso-python&count_bg=%2323E7E7E7&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>
</div>

<div align="center">
    <a href="https://netspresso.ai/?utm_source=git&utm_medium=banner_py&utm_campaign=np_renew" target="_blank"><img src="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/banner/NetsPresso2.0_banner.png"/>
</div>
</br>

<div align="center">
    <p align="center">
        <a href="https://www.python.org/downloads/" target="_blank"><img src="https://img.shields.io/badge/python-3.8%20%7C%203.9%20%7C%203.10-blue?style=flat&logo=python&logoColor=blue" />
        <a href="https://pytorch.org/" target="_blank"><img src="https://img.shields.io/badge/PyTorch-1.11.x ~ 1.13.x.-EE4C2C?style=flat&logo=pytorch&logoColor=#EE4C2C"/></a>
        <a href="https://www.tensorflow.org/install/pip" target="_blank"><img src="https://img.shields.io/badge/TensorFlow-2.3.x ~ 2.8.x.-FF6F00?style=flat&logo=tensorflow&logoColor=#FF6F00&link=https://www.tensorflow.org/install/pip"/></a>
        <br>
        <a href="https://netspresso.ai/?utm_source=git&utm_medium=badge&utm_campaign=np_renew"><img src="https://img.shields.io/badge/NetsPresso-Open in Website-1BD2EB?style=flat&link=https://netspresso.ai/"/></a>
    </p>
</div>
</br>

<div align="center">
  <a href="https://netspresso.ai/?utm_source=git&utm_medium=text_signup&utm_campaign=np_renew"> Sign Up </a>
    | <a href="https://nota-netspresso.github.io/PyNetsPresso"> Docs </a> 
</div>
</br>

<div align="center">
  ü§ù Collaboration with partners ü§ù <br>
</div>

<div align="center">
  <a href="https://colab.research.google.com/drive/10lLpgnJaRVkYIYFr0ga6FP238haUs4Ol">Qualcomm AI Hub x NetsPresso</a>
</div>

<div align="center">
  <a href="https://github.com/STMicroelectronics/stm32ai-modelzoo"> STM32 x NetsPresso</a>
</div>
</br>

<div align="center">
  ‚òÄÔ∏è NetsPresso Model Zoo ‚òÄÔ∏è <br>
      <a href="https://github.com/Nota-NetsPresso/ModelZoo-YOLOFastest-for-ARM-U55-M85"> YOLO Fastest </a>
    | <a href="https://github.com/Nota-NetsPresso/yolox_nota"> YOLOX </a>
    | <a href="https://github.com/Nota-NetsPresso/ultralytics_nota"> YOLOv8 </a> 
    | <a href="https://github.com/Nota-NetsPresso/ModelZoo-YOLOv7"> YOLOv7 </a> 
    | <a href="https://github.com/Nota-NetsPresso/yolov5_nota"> YOLOv5 </a> 
    | <a href="https://github.com/Nota-NetsPresso/PIDNet_nota"> PIDNet </a>     
    | <a href="https://github.com/Nota-NetsPresso/pytorch-cifar-models_nota"> PyTorch-CIFAR-Models</a>
</div>
</br>


<div align="center">
  üî• NetsPresso Model Optimization Tutorials üî• <br>
    <a href="https://colab.research.google.com/drive/1pmauCnWLYog3iW0Km6ZsLD1G5rnm9Bcd"> A Practical Guide to Using NetsPresso's Optimizer and Simulator Modules</a></br>  
    <a href="https://colab.research.google.com/drive/1XxkFWcoVQrIrUI8PlAlToWg3PQw1MHD1"> A Practical Guide to Using NetsPresso's Compressor Module </a></br>
    <a href="https://colab.research.google.com/drive/1DTmxfSVWiAOxRGrKd0FtLBv6pYFryj_o"> A Practical Guide to Using NetsPresso's Quantizer Module </a></br>
</div>
</br>


Use **NetsPresso** for a seamless model optimization process. 
NetsPresso resolves AI-related constraints in business use cases and enables cost-efficiency and enhanced performance by removing the requirement for high-spec servers and network connectivity and preventing high latency and personal data breaches.

Easily compress various models with our resources. Please browse the [Docs] for details, and join our [Discussion Forum] for providing feedback or sharing your use cases.

To get started with NetsPresso, you'll need to sign up [here](https://netspresso.ai/?utm_source=git&utm_medium=text_signup&utm_campaign=np_renew).

We offer a comprehensive guide to walk you through the process of optimizing an AI model using NetsPresso. A full tutorial can be found [Google Colab](https://colab.research.google.com/drive/1XxkFWcoVQrIrUI8PlAlToWg3PQw1MHD1).
</br>
</br>

<div align="center">
  <a href="https://github.com/Nota-NetsPresso" style="text-decoration:none;">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/github_white.png">
      <source media="(prefers-color-scheme: light)" srcset="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/github.png">
      <img alt="github" src="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/github.png" width="3%">
    </picture>
  </a>
  <img src="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/logo-transparent.png" width="3%" alt="" />
  <a href="https://www.facebook.com/NotaAI" style="text-decoration:none;">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/facebook_white.png">
      <source media="(prefers-color-scheme: light)" srcset="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/facebook.png">
      <img alt="facebook" src="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/facebook.png" width="3%">
    </picture>
  </a>
  <img src="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/logo-transparent.png" width="3%" alt="" />
  <a href="https://twitter.com/nota_ai" style="text-decoration:none;">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/twitter_white.png">
      <source media="(prefers-color-scheme: light)" srcset="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/twitter.png">
      <img alt="twitter" src="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/twitter.png" width="3%">
    </picture>
  </a>
  <img src="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/logo-transparent.png" width="3%" alt="" />
  <a href="https://www.youtube.com/channel/UCeewYFAqb2EqwEXZCfH9DVQ" style="text-decoration:none;">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/youtube_white.png">
      <source media="(prefers-color-scheme: light)" srcset="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/youtube.png">
      <img alt="youtube" src="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/youtube.png" width="3%">
    </picture>
  </a>
  <img src="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/logo-transparent.png" width="3%" alt="" />
  <a href="https://www.linkedin.com/company/nota-incorporated" style="text-decoration:none;">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/linkedin_white.png">
      <source media="(prefers-color-scheme: light)" srcset="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/linkedin.png">
      <img alt="youtube" src="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/common/linkedin.png" width="3%">
    </picture>
  </a>
</div>
</br>
</br>

<div align="center">
    <img width="100%" src="https://netspresso-docs-imgs.s3.ap-northeast-2.amazonaws.com/imgs/banner/github_pipeline_temp.png">
</div>
</br>

<div width="9%" align="center">
  <table width="90%" align="center">
      <tr>
          <th>Step</th>
          <th>Type</th>
          <th>Description</th>
      </tr>
      <tr>
          <td width="30%" align="center" rowspan="2">Train</td>
          <td width="30%" align="center">np.trainer</td>
          <td width="40%" align="center" rowspan="2">Build and train a model.</td>
      </tr>
      <tr>
          <td width="30%" align="center">
            <details>
              <summary>Model Zoo</summary>
              <details>
                  <summary>Image Classification</summary>
                  <a href="https://github.com/Nota-NetsPresso/pytorch-cifar-models_nota">PyTorch-CIFAR-Models</a>
              </details>
              <details>
                  <summary>Object Detection</summary>
                  <a href="https://github.com/Nota-NetsPresso/ModelZoo-YOLOFastest-for-ARM-U55-M85">YOLO Fastest</a><br>
                  <a href="https://github.com/Nota-NetsPresso/yolox_nota">YOLOX</a><br>
                  <a href="https://github.com/Nota-NetsPresso/yolov5_nota">YOLOv5</a><br>
                  <a href="https://github.com/Nota-NetsPresso/ModelZoo-YOLOv7">YOLOv7</a>
              </details>
              <details>
                  <summary>Semantic Segmentation</summary>
                  <a href="https://github.com/Nota-NetsPresso/PIDNet_nota">PIDNet</a>
              </details>
              <details>
                  <summary>Pose Estimation</summary>
                  <a href="https://github.com/Nota-NetsPresso/ultralytics_nota">YOLOv8</a>
              </details>
            </details>
          </td>
      </tr>
      <tr>
          <td width="30%" align="center">Compress</td>
          <td width="30%" align="center">np.compressor</td>
          <td width="40%" align="center">Compress the user‚Äôs model.</td>
      </tr>
      <tr>
          <td width="30%" align="center">Optimize</td>
          <td width="30%" align="center">np.optimizer</td>
          <td width="40%" align="center">Optimize the user‚Äôs model.</td>
      </tr>
      <tr>
          <td width="30%" align="center">Simulate</td>
          <td width="30%" align="center">np.simulator</td>
          <td width="40%" align="center">Simulate the user‚Äôs model.</td>
      </tr>
      <tr>
          <td width="30%" align="center">Quantize</td>
          <td width="30%" align="center">np.quantizer</td>
          <td width="40%" align="center">Quantize the user‚Äôs model.</td>
      </tr>
      <tr>
          <td width="30%" align="center">Convert</td>
          <td width="30%" align="center">np.converter</td>
          <td width="40%" align="center">Convert and quantize the user‚Äôs model to run efficiently on device.</td>
      </tr>
      <tr>
          <td width="30%" align="center">Profile</td>
          <td width="30%" align="center">np.profiler</td>
          <td width="40%" align="center">Profile the user's model to measure model inference speed on diverse device.</td>
      </tr>
  </table>
</div>

## Installation

### Prerequisites

- Python¬†`3.8`¬†|¬†`3.9`¬†|¬†`3.10`
- PyTorch¬†`1.13.0`¬†(recommended) (compatible with:¬†`1.11.x`¬†-¬†`1.13.x`)
- TensorFlow `2.8.0` (recommended) (compatible with:¬†`2.3.x`¬†-¬†`2.8.x`)

### Install with PyPI (stable)

```bash
pip install netspresso
```

To use **editable mode** or **docker**, see [INSTALLATION.md](INSTALLATION.md).

## Getting started

### Login

Log-in to your netspresso account. Please sign-up [here](https://netspresso.ai/?utm_source=git&utm_medium=text_signup2&utm_campaign=np_renew) if you need one.

```python
from netspresso import NetsPresso

# Login with API key (recommended)
# Get your API token from: https://account.netspresso.ai/api-token
netspresso = NetsPresso(api_key="YOUR_API_KEY")

# Note: Email/password login will be deprecated soon
netspresso = NetsPresso(email="YOUR_EMAIL", password="YOUR_PASSWORD")
```

### Quantizer

#### Automatic quantization

To start quantize a model, enter the model path, dataset path, and the desired quantization precision.

The quantized model will be saved to the specified output directory (`output_dir`).

```python
from netspresso.enums import QuantizationPrecision, SimilarityMetric

# 1. Declare quantizer
quantizer = netspresso.quantizer()

# 2. Run automatic quantization
quantization_result = quantizer.automatic_quantization(
    input_model_path="./examples/sample_models/test.onnx",
    output_dir="./outputs/quantized/automatic_quantization",
    dataset_path="./examples/sample_datasets/pickle_calibration_dataset_128x128.npy",
    weight_precision=QuantizationPrecision.INT8,
    activation_precision=QuantizationPrecision.INT8,
    threshold=0,
)
```

#### Custom precision quantization by layer name

This method enables you to apply precision settings tailored to each layer, based on the recommendations, to optimize model.

Or, you can modify it to your desired precision and optimize it.

```python
from netspresso.enums import QuantizationPrecision

# 1. Declare quantizer
quantizer = netspresso.quantizer()

# 2. Recommendation precision
metadata = quantizer.get_recommendation_precision(
    input_model_path="./examples/sample_models/test.onnx",
    output_dir="./outputs/quantized/recommendation",
    dataset_path="./examples/sample_datasets/pickle_calibration_dataset_128x128.npy",
    weight_precision=QuantizationPrecision.INT8,
    activation_precision=QuantizationPrecision.INT8,
    threshold=0,
)
recommendation_precisions = quantizer.load_recommendation_precision_result(metadata.recommendation_result_path)

# 2. Run quantization by layer name
quantization_result = quantizer.custom_precision_quantization_by_layer_name(
    input_model_path="./examples/sample_models/test.onnx",
    output_dir="./outputs/quantized/custom_precision_quantization_by_layer_name",
    precision_by_layer_name=recommendation_precisions.layers,
    dataset_path="./examples/sample_datasets/pickle_calibration_dataset_128x128.npy",
)
```


### Trainer

#### Train

To start training a model, first select a task. 

Then configure the dataset, model, augmentation, and hyperparameters. 

Once setup is finished, enter the GPU number and project name for training.

```python
from netspresso.enums import Task
from netspresso.trainer.optimizers import AdamW
from netspresso.trainer.schedulers import CosineAnnealingWarmRestartsWithCustomWarmUp
from netspresso.trainer.augmentations import Resize


# 1. Declare trainer
trainer = netspresso.trainer(task=Task.OBJECT_DETECTION)  # IMAGE_CLASSIFICATION, OBJECT_DETECTION, SEMANTIC_SEGMENTATION

# 2. Set config for training
# 2-1. Data
trainer.set_dataset_config(
    name="traffic_sign_config_example",
    root_path="/root/traffic-sign",
    train_image="images/train",
    train_label="labels/train",
    valid_image="images/valid",
    valid_label="labels/valid",
    id_mapping=["prohibitory", "danger", "mandatory", "other"],
)

# 2-2. Model
print(trainer.available_models)  # ['YOLOX-S', 'YOLOX-M', 'YOLOX-L', 'YOLOX-X']
trainer.set_model_config(model_name="YOLOX-S", img_size=512)

# 2-3. Augmentation
trainer.set_augmentation_config(
    train_transforms=[Resize()],
    inference_transforms=[Resize()],
)

# 2-4. Training
optimizer = AdamW(lr=6e-3)
scheduler = CosineAnnealingWarmRestartsWithCustomWarmUp(warmup_epochs=10)
trainer.set_training_config(
    epochs=40,
    batch_size=16,
    optimizer=optimizer,
    scheduler=scheduler,
)

# 3. Train
training_result = trainer.train(gpus="0, 1", project_name="PROJECT_TRAIN_SAMPLE")
```

#### Retrain

To start retraining a model, use `hparams.yaml` file which is one of the artifacts generated during the training of the original model.

Then, enter the compressed model path, which is an artifact of the compressor in fx_model_path.

Adjust the training hyperparameters as needed. (See 2-2. for detailed code.)

```python
from netspresso.trainer.optimizers import AdamW

# 1. Declare trainer
trainer = netspresso.trainer(yaml_path="./temp/hparams.yaml")

# 2. Set config for retraining
# 2-1. FX Model
trainer.set_fx_model(fx_model_path="./temp/FX_MODEL_PATH.pt")

# 2-2. Training
optimizer = AdamW(lr=6e-3)
trainer.set_training_config(
    epochs=30,
    batch_size=16,
    optimizer=optimizer,
)

# 3. Train
retraining_result = trainer.train(gpus="0, 1", project_name="PROJECT_RETRAIN_SAMPLE")
```

### Compressor

#### Compress (Automatic compression)

To start compressing a model, enter the model path to compress and the appropriate compression ratio.

The compressed model will be saved in the specified output directory (`output_dir`).

```python
# 1. Declare compressor
compressor = netspresso.compressor_v2()

# 2. Run automatic compression
compression_result = compressor.automatic_compression(
    input_shapes=[{"batch": 1, "channel": 3, "dimension": [224, 224]}],
    input_model_path="./examples/sample_models/graphmodule.pt",
    output_dir="./outputs/compressed/pytorch_automatic_compression",
    compression_ratio=0.5,
)
```

### Converter

#### Convert

To start converting a model, enter the model path to convert and the target framework and device name.

For NVIDIA GPUs and Jetson devices, enter the software version additionally due to the jetpack version.

The converted model will be saved in the specified output directory (`output_dir`).

```python
from netspresso.enums import DeviceName, Framework, SoftwareVersion

# 1. Declare converter
converter = netspresso.converter_v2()

# 2. Run convert
conversion_result = converter.convert_model(
    input_model_path="./examples/sample_models/test.onnx",
    output_dir="./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1",
    target_framework=Framework.TENSORRT,
    target_device_name=DeviceName.JETSON_AGX_ORIN,
    target_software_version=SoftwareVersion.JETPACK_5_0_1,
)
```

### Profiler

#### Profile

To start profiling a model, enter the model path to profile and the target device name.

For NVIDIA GPUs and Jetson devices, device name and software version have to be matched with the target device of the conversion.

TensorRT Model has strong dependency with the device type and its jetpack version.

```python
from netspresso.enums import DeviceName, SoftwareVersion

# 1. Declare profiler
profiler = netspresso.profiler_v2()

# 2. Run profile
profile_result = profiler.profile_model(
    input_model_path="./outputs/converted/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1/TENSORRT_JETSON_AGX_ORIN_JETPACK_5_0_1.trt",
    target_device_name=DeviceName.JETSON_AGX_ORIN,
    target_software_version=SoftwareVersion.JETPACK_5_0_1,
)
print(f"model inference latency: {profile_result.profile_result.latency} ms")
print(f"model gpu memory footprint: {profile_result.profile_result.memory_footprint_gpu} MB")
print(f"model cpu memory footprint: {profile_result.profile_result.memory_footprint_cpu} MB")
```

<details open>
  <summary>Supported options for Converter & Profier</summary>
  <div markdown="1">

  ### Frameworks that support conversion for model's framework

  | Target / Source Framework | ONNX | TENSORFLOW_KERAS | TENSORFLOW |
  |:--------------------------|:----:|:----------------:|:----------:|
  | TENSORRT                  |  ‚úîÔ∏è  |                  |            |
  | DRPAI                     |  ‚úîÔ∏è  |                  |            |
  | OPENVINO                  |  ‚úîÔ∏è  |                  |            |
  | TENSORFLOW_LITE           |  ‚úîÔ∏è  |        ‚úîÔ∏è        |     ‚úîÔ∏è     |

  ### Devices that support profiles for model's framework

  | Device / Framework           | ONNX | TENSORRT | TENSORFLOW_LITE | DRPAI | OPENVINO |
  |:-----------------------------|:----:|:--------:|:---------------:|:-----:|:--------:|
  | RASPBERRY_PI_5               |  ‚úîÔ∏è  |          |       ‚úîÔ∏è        |       |          |
  | RASPBERRY_PI_4B              |  ‚úîÔ∏è  |          |       ‚úîÔ∏è        |       |          |
  | RASPBERRY_PI_3B_PLUS         |  ‚úîÔ∏è  |          |       ‚úîÔ∏è        |       |          |
  | RASPBERRY_PI_ZERO_W          |  ‚úîÔ∏è  |          |       ‚úîÔ∏è        |       |          |
  | RASPBERRY_PI_ZERO_2W         |  ‚úîÔ∏è  |          |       ‚úîÔ∏è        |       |          |
  | ARM_ETHOS_U_SERIES           |      |          |  ‚úîÔ∏è(only INT8)  |       |          |
  | ALIF_ENSEMBLE_E7_DEVKIT_GEN2 |      |          |  ‚úîÔ∏è(only INT8)  |       |          |
  | RENESAS_RA8D1                |      |          |  ‚úîÔ∏è(only INT8)  |       |          |
  | NXP_iMX93                    |      |          |  ‚úîÔ∏è(only INT8)  |       |          |
  | ARDUINO_NICLA_VISION         |      |          |  ‚úîÔ∏è(only INT8)  |       |          |
  | RENESAS_RZ_V2L               |  ‚úîÔ∏è  |          |                 |  ‚úîÔ∏è   |          |
  | RENESAS_RZ_V2M               |  ‚úîÔ∏è  |          |                 |  ‚úîÔ∏è   |          |
  | JETSON_NANO                  |  ‚úîÔ∏è  |    ‚úîÔ∏è    |                 |       |          |
  | JETSON_TX2                   |  ‚úîÔ∏è  |    ‚úîÔ∏è    |                 |       |          |
  | JETSON_XAVIER                |  ‚úîÔ∏è  |    ‚úîÔ∏è    |                 |       |          |
  | JETSON_NX                    |  ‚úîÔ∏è  |    ‚úîÔ∏è    |                 |       |          |
  | JETSON_AGX_ORIN              |  ‚úîÔ∏è  |    ‚úîÔ∏è    |                 |       |          |
  | JETSON_ORIN_NANO             |  ‚úîÔ∏è  |    ‚úîÔ∏è    |                 |       |          |
  | AWS_T4                       |  ‚úîÔ∏è  |    ‚úîÔ∏è    |                 |       |          |
  | INTEL_XEON_W_2233            |      |          |                 |       |    ‚úîÔ∏è    |

  ### Software versions that support conversions and profiles for specific devices 

  Software Versions requires for Jetson Device. If you are using a different device, you do not need to enter it.

  | Software Version / Device | JETSON_NANO | JETSON_TX2 | JETSON_XAVIER | JETSON_NX | JETSON_AGX_ORIN | JETSON_ORIN_NANO |
  |:--------------------------|:-----------:|:----------:|:-------------:|:---------:|:---------------:|:----------------:|
  | JETPACK_4_4_1             |     ‚úîÔ∏è      |            |               |           |                 |                  |
  | JETPACK_4_6               |     ‚úîÔ∏è      |     ‚úîÔ∏è     |      ‚úîÔ∏è       |    ‚úîÔ∏è     |                 |                  |
  | JETPACK_5_0_1             |             |            |               |           |       ‚úîÔ∏è        |                  |
  | JETPACK_5_0_2             |             |            |               |    ‚úîÔ∏è     |                 |                  |
  | JETPACK_6_1               |             |            |               |           |                 |        ‚úîÔ∏è        |

  The code below is an example of using software version.

  ```python
  conversion_result = converter.convert_model(
      input_model_path=INPUT_MODEL_PATH,
      output_dir=OUTPUT_DIR,
      target_framework=Framework.TENSORRT,
      target_device_name=DeviceName.JETSON_AGX_ORIN,
      target_software_version=SoftwareVersion.JETPACK_5_0_1,
  )
  profile_result = profiler.profile_model(
      input_model_path=CONVERTED_MODEL_PATH,
      target_device_name=DeviceName.JETSON_AGX_ORIN,
      target_software_version=SoftwareVersion.JETPACK_5_0_1,
  )
  ```

  ### Hardware type that support profiles for specific devices

  Profile and compare models with and without Arm Helium.

  `RENESAS_RA8D1` and `ALIF_ENSEMBLE_E7_DEVKIT_GEN2` are available for use.

  The profile results with Helium can be up to twice as fast as without Helium.

  The code below is an example of using hardware type.

  ```python
  profile_result = profiler.profile_model(
      input_model_path=CONVERTED_MODEL_PATH,
      target_device_name=DeviceName.RENESAS_RA8D1,
      target_data_type=DataType.INT8,
      target_hardware_type=HardwareType.HELIUM
  )
  ```
  </div>
</details>


## Guide to Credit Consumption by Module

<table width="90%">
  <tr>
      <th>Module</th>
      <th>Feature</th>
      <th>Credit</th>
  </tr>
  <tr>
      <td align="center" rowspan="2">Compressor</td>
      <td align="center">Automatic compression</td>
      <td align="center">25</td>
  </tr>
  <tr>
      <td align="center">Advanced compression</td>
      <td align="center">50</td>
  </tr>
  <tr>
      <td align="center">Converter</td>
      <td align="center">Convert</td>
      <td align="center">50</td>
  </tr>
  <tr>
      <td align="center">Profiler</td>
      <td align="center">Profile</td>
      <td align="center">25</td>
  </tr>
</table>

## Contact

Join our [Discussion Forum] for providing feedback or sharing your use cases, and if you want to talk more with Nota, please contact us [here].</br>
Or you can also do it via email([netspresso@nota.ai]) or phone(+82 2-555-8659)!


[Docs]: https://nota-netspresso.github.io/PyNetsPresso
[Discussion Forum]: https://github.com/orgs/Nota-NetsPresso/discussions
[NetsPresso]: https://netspresso.ai?utm_source=git_comp&utm_medium=text_np&utm_campaign=py_launch
[NetsPresso-Sign-Up]: https://netspresso.ai/signup
[here]: https://www.nota.ai/contact-us
[netspresso@nota.ai]: mailto:netspresso@nota.ai


