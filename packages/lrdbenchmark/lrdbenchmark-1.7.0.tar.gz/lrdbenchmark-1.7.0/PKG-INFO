Metadata-Version: 2.4
Name: lrdbenchmark
Version: 1.7.0
Summary: Long-Range Dependence Benchmarking Toolkit with Working ML and Neural Network Estimators - 4x More Accurate Than Classical Methods
Author-email: LRDBench Development Team <lrdbench@example.com>
License: MIT
Project-URL: Homepage, https://github.com/dave2k77/LRDBenchmark
Project-URL: Documentation, https://lrdbenchmark.readthedocs.io/
Project-URL: Repository, https://github.com/dave2k77/LRDBenchmark.git
Project-URL: Issues, https://github.com/dave2k77/LRDBenchmark/issues
Project-URL: Download, https://pypi.org/project/lrdbenchmark/
Project-URL: Source, https://github.com/dave2k77/LRDBenchmark
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: Topic :: Scientific/Engineering :: Physics
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.21.0
Requires-Dist: scipy>=1.7.0
Requires-Dist: scikit-learn>=1.0.0
Requires-Dist: pandas>=1.3.0
Requires-Dist: torch>=1.9.0
Requires-Dist: jax>=0.3.0
Requires-Dist: jaxlib>=0.3.0
Requires-Dist: numba>=0.56.0
Requires-Dist: pywavelets>=1.3.0
Requires-Dist: matplotlib>=3.5.0
Requires-Dist: seaborn>=0.11.0
Requires-Dist: psutil>=5.8.0
Requires-Dist: networkx>=2.6.0
Requires-Dist: optuna>=3.0.0
Requires-Dist: numpyro>=0.12.0
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: pytest-cov>=2.12; extra == "dev"
Requires-Dist: black>=21.0; extra == "dev"
Requires-Dist: flake8>=3.9; extra == "dev"
Requires-Dist: mypy>=0.910; extra == "dev"
Provides-Extra: docs
Requires-Dist: sphinx>=4.0; extra == "docs"
Requires-Dist: sphinx-rtd-theme>=0.5; extra == "docs"
Requires-Dist: myst-parser>=0.15; extra == "docs"
Provides-Extra: dashboard
Requires-Dist: streamlit>=1.28.0; extra == "dashboard"
Requires-Dist: plotly>=5.15.0; extra == "dashboard"
Dynamic: license-file

# ğŸš€ **LRDBenchMark: Long-Range Dependence Benchmarking Toolkit**

A comprehensive Python package for benchmarking long-range dependence estimators on synthetic and real-world time series data. LRDBench provides ready-to-use implementations of classical, machine learning, and neural network estimators with built-in analytics and performance monitoring.

## ğŸ¯ **What is LRDBench?**

LRDBench is designed for researchers, data scientists, and practitioners who need to:
- **Compare different long-range dependence estimation methods**
- **Generate synthetic data from stochastic processes**
- **Benchmark estimator performance across various data types**
- **Monitor usage patterns and performance metrics**
- **Use pre-trained models without additional training**

## âœ¨ **Key Features**

### **ğŸ”¬ 18 Built-in Estimators**
- **Temporal Methods**: DFA, DMA, Higuchi, R/S (4 estimators)
- **Spectral Methods**: Periodogram, Whittle, GPH (3 estimators)
- **Wavelet Methods**: CWT, Wavelet Variance, Wavelet Log Variance, Wavelet Whittle (4 estimators)
- **Multifractal Methods**: MFDFA (1 estimator)
- **ğŸ¤– Machine Learning**: Random Forest, SVR, Gradient Boosting (3 estimators)
- **ğŸ§  Neural Networks**: CNN, LSTM, GRU, Transformer (4 estimators)
- **ğŸš€ Auto-Optimized**: All estimators with NUMBA/JAX performance optimizations

### **ğŸ“Š 5 Stochastic Data Models**
- **FBMModel**: Fractional Brownian Motion
- **FGNModel**: Fractional Gaussian Noise
- **ARFIMAModel**: AutoRegressive Fractionally Integrated Moving Average
- **MRWModel**: Multifractal Random Walk
- **Neural fSDE**: Neural network-based fractional SDEs

### **âš¡ High Performance**
- **JAX Optimization**: GPU acceleration for large-scale computations
- **Numba JIT**: Just-in-time compilation for critical loops
- **Parallel Processing**: Multi-core benchmark execution
- **Memory Efficient**: Optimized data structures and algorithms

### **ğŸ¯ Production Ready**
- **Pre-trained Models**: All ML and neural models work immediately
- **No Training Required**: Models ready to use after installation
- **Built-in Analytics**: Usage tracking and performance monitoring
- **Robust Error Handling**: Graceful fallbacks and comprehensive reporting
- **ğŸ§ª Data Contamination**: Comprehensive contamination testing system for robustness analysis
- **ğŸŒ Web Dashboard**: Interactive Streamlit interface with real-time benchmarking

## ğŸ† **Latest Benchmark Results**

Our latest comprehensive benchmark shows:

- **ML Estimators are 4x more accurate** than classical methods (MSE: 0.061 vs 0.245)
- **100% success rate** across all 98 test cases
- **Top performers**: DFA (32.5% error), DMA (39.8% error), Random Forest (74.8% error)
- **All estimators working correctly** with unified interfaces and graceful fallbacks

## ğŸš€ **Quick Start**

### **Installation**

```bash
pip install lrdbench
```

### **Basic Usage**

```python
import lrdbench

# Generate synthetic data
from lrdbench import FBMModel
fbm = FBMModel(H=0.7, sigma=1.0)
data = fbm.generate(1000)

# Run comprehensive benchmark
from lrdbench import ComprehensiveBenchmark
benchmark = ComprehensiveBenchmark()
results = benchmark.run_comprehensive_benchmark()

# Get analytics summary
summary = lrdbench.get_analytics_summary()
print(summary)
```

### **Enhanced ML and Neural Network Estimators**

```python
# Import enhanced estimators directly
from lrdbench import CNNEstimator, LSTMEstimator, GRUEstimator, TransformerEstimator

# Use CNN estimator
cnn_estimator = CNNEstimator()
hurst_cnn = cnn_estimator.estimate(data)

# Use LSTM estimator
lstm_estimator = LSTMEstimator()
hurst_lstm = lstm_estimator.estimate(data)

# Use GRU estimator
gru_estimator = GRUEstimator()
hurst_gru = gru_estimator.estimate(data)

# Use Transformer estimator
transformer_estimator = TransformerEstimator()
hurst_transformer = transformer_estimator.estimate(data)
```

### **Simple Benchmark: Classical vs. ML**

```python
# Run focused benchmark comparing classical and ML estimators
from lrdbench import SimpleBenchmark

benchmark = SimpleBenchmark()
results = benchmark.run_benchmark()
analysis = benchmark.analyze_results(results)

# Results show ML estimators significantly outperform classical methods
print(f"ML MSE: {analysis['ml_mse']:.6f}")
print(f"Classical MSE: {analysis['classical_mse']:.6f}")
```

### **Advanced Usage**

```python
# Generate data with contamination
from lrdbench import FGNModel
from lrdbench.models.contamination.contamination_models import ContaminationModel

fgn = FGNModel(H=0.6, sigma=1.0)
clean_data = fgn.generate(1000)

# Add comprehensive contamination
contamination_model = ContaminationModel()
contaminated_data = contamination_model.add_noise_gaussian(clean_data, std=0.1)
contaminated_data = contamination_model.add_trend_linear(contaminated_data, slope=0.01)

# Run comprehensive benchmark with contamination analysis
results = benchmark.run_comprehensive_benchmark()
```

## ğŸ“š **Documentation**

- **ğŸ“– [User Guide](documentation/user_guides/getting_started.md)**: Getting started tutorial
- **ğŸš€ [Web Dashboard](documentation/user_guides/web_dashboard.md)**: Complete web dashboard guide
- **ğŸ§ª [Contamination System](documentation/api_reference/contamination.md)**: Data contamination documentation
- **ğŸ”§ [API Reference](documentation/api_reference/README.md)**: Complete API documentation
- **ğŸ¤– [Enhanced Neural Models](ENHANCED_NEURAL_MODELS.md)**: Complete guide to ML and neural estimators
- **ğŸ“Š [Examples](examples/)**: Usage examples and demonstrations
- **ğŸ”¬ [Model Theory](documentation/technical/model_theory.md)**: Mathematical foundations

## ğŸŒ **Web Dashboard**

**ğŸš€ Interactive Web Interface**: Access LRDBenchmark through a modern web dashboard built with Streamlit.

### **Features**
- **ğŸ“ˆ Interactive Data Generation**: Generate synthetic time series with configurable parameters
- **ğŸ”¬ Real-time Benchmarking**: Run comprehensive benchmarks with all 18 estimators
- **ï¿½ï¿½ Data Contamination**: Add various contamination types and analyze robustness
- **ğŸ“Š Rich Visualizations**: Interactive plots and charts using Plotly
- **ğŸ“ˆ Performance Analytics**: Track estimator performance and robustness metrics
- **ğŸ“¥ Results Export**: Download benchmark results in JSON format with proper serialization

### **Quick Start**
```bash
# Navigate to web dashboard
cd web_dashboard

# Install dependencies
pip install -r requirements.txt

# Run the dashboard
streamlit run streamlit_app.py
```

### **Deploy Online**
- **Streamlit Cloud**: Free hosting at [share.streamlit.io](https://share.streamlit.io)
- **Local Development**: Run locally for development and testing
- **Docker**: Containerized deployment option available

### **Documentation**
- **ğŸ“– [Dashboard README](web_dashboard/README.md)**: Complete dashboard documentation
- **ğŸ§ª [Test Suite](web_dashboard/test_dashboard.py)**: Verify dashboard functionality

## ğŸ§ª **Examples & Demos**

### **Quick Examples**
- **Basic Usage**: `examples/quick_start_demo.py`
- **Comprehensive API**: `examples/comprehensive_api_demo.py`
- **Benchmark Examples**: `examples/benchmark_examples.py`
- **Enhanced ML Estimators**: `examples/enhanced_ml_estimators_demo.py`

### **Advanced Demos**
- **CPU-based**: `demos/cpu_based/`
- **GPU-based**: `demos/gpu_based/`
- **Performance Comparison**: `demos/gpu_based/high_performance_comparison_demo.py`

## ğŸ“Š **Analytics & Monitoring**

LRDBench includes a built-in analytics system that tracks:
- **Usage Patterns**: Which estimators are used most
- **Performance Metrics**: Execution times and resource usage
- **Error Analysis**: Failure patterns and reliability scores
- **Workflow Insights**: Common usage sequences and patterns

```python
# Enable analytics (enabled by default)
lrdbench.enable_analytics(True, privacy_mode=True)

# Get usage summary
summary = lrdbench.get_analytics_summary()

# Generate comprehensive report
report_path = lrdbench.generate_analytics_report(days=30)
```

## ğŸ”§ **Configuration & Customization**

### **Analytics Settings**
```python
# Disable analytics
lrdbench.enable_analytics(False)

# Configure privacy mode
lrdbench.enable_analytics(True, privacy_mode=True)
```

### **Benchmark Configuration**
```python
# Customize benchmark parameters
benchmark = ComprehensiveBenchmark(
    data_lengths=[500, 1000, 2000],
    contamination_levels=[0.0, 0.1, 0.2],
    estimators=['classical', 'ml', 'neural']
)
```

## ğŸ† **Performance Benchmarks**

LRDBench has been extensively tested and optimized:
- **Data Generation**: < 10ms for 1000 points
- **Estimation**: < 100ms for most estimators
- **Memory Usage**: Optimized for large datasets
- **GPU Acceleration**: Available for JAX-based methods
- **Neural Networks**: Pre-trained models for immediate use

### **Latest Performance Results**
- **Overall Success Rate**: 100% (98/98 tests)
- **ML Estimators**: 4x more accurate than classical methods
- **Classical Estimators**: DFA and DMA show best performance
- **Unified Framework**: All estimators work seamlessly with graceful fallbacks

## ğŸ¤ **Contributing**

We welcome contributions! Please see our [Development Guide](DEVELOPMENT.md) for:
- Development setup instructions
- Contributing guidelines
- Testing procedures
- Code review process

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» **Author**

**Davian R. Chin**  
*Department of Biomedical Engineering*  
*University of Reading*  
*Email: d.r.chin@pgr.reading.ac.uk*

## ğŸ“š **References**

### **Core Research Papers**
- Beran, J. (1994). Statistics for Long-Memory Processes.
- Mandelbrot, B. B. (1982). The Fractal Geometry of Nature.
- Abry, P., & Veitch, D. (1998). Wavelet analysis of long-range-dependent traffic.
- Muzy, J. F., Bacry, E., & Arneodo, A. (1991). Wavelets and multifractal formalism for singular signals.

### **Neural Network Innovations**
- Hayashi, K., & Nakagawa, K. (2022). fSDE-Net: Generating Time Series Data with Long-term Memory.
- Nakagawa, K., & Hayashi, K. (2024). Lf-Net: Generating Fractional Time-Series with Latent Fractional-Net.
- Li, Z., et al. (2020). Fourier Neural Operator for Parametric Partial Differential Equations.
- Raissi, M., et al. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems.

---

**For questions, contributions, or collaboration opportunities, please refer to our comprehensive documentation or create an issue on GitHub.**
