"""
Interactive Video QA System for YouTube analysis with Gemini AI.
Professional video analysis with question-answering capabilities.
"""
import asyncio
import json
import tempfile
import base64
import os
import re
import sys
import shutil
import subprocess
import platform
from typing import List, Dict, Any, Optional
import yt_dlp
import ffmpeg
import whisper
import google.generativeai as genai
from PIL import Image
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.prompt import Prompt, Confirm
from rich.text import Text
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.align import Align
from rich import box
import click

from .config_manager import ConfigManager
from .gemini_batch_predictor import GeminiBatchPredictor
from .transcript_utils import chunk_transcript, find_relevant_chunk

console = Console()

# Package version
__version__ = "1.0.7"

HALO_BANNER = r'''
[bold blue]
........................................................................
.  _   _    _    _     ___   
. | | | |  / \  | |   / _ \  
. | |_| | / _ \ | |  | | | | 
. |  _  |/ ___ \| |__| |_| | 
. |_| |_/_/   \_\____|\___/  
........................................................................
[/bold blue]
'''

WELCOME_MESSAGE = """
[bold magenta]üé• HALO: Interactive Video QA System[/bold magenta]

[bold green]üöÄ AI-Powered YouTube Video Analysis[/bold green]

[yellow]Built by Jeet Dekivadia during Google Summer of Code at Google DeepMind[/yellow]
[blue]Powered by Google Gemini Vision API[/blue]

[white]Interactive Video QA System for analyzing YouTube videos and answering 
questions about their content using advanced AI technology.[/white]

[blue]üìã Prerequisites:[/blue]
‚Ä¢ Google Gemini API key (free at https://makersuite.google.com/app/apikey)
‚Ä¢ FFmpeg (will be auto-installed if missing)

[yellow]üåü GitHub Repository:[/yellow] [blue]https://github.com/jeet-dekivadia/google-deepmind[/blue]
"""

# Helper: Estimate tokens (roughly 1 token ‚âà 4 chars)
def estimate_tokens(text: str) -> int:
    return max(1, len(text) // 4)

# Helper: Check if FFmpeg is available
def check_ffmpeg() -> bool:
    """Check if FFmpeg is available in the system"""
    return shutil.which('ffmpeg') is not None

# Helper: Install FFmpeg using imageio-ffmpeg as fallback
def install_ffmpeg_fallback():
    """Install FFmpeg using imageio-ffmpeg as a fallback"""
    try:
        import imageio_ffmpeg as ffmpeg_download
        ffmpeg_download.get_ffmpeg_exe()
        console.print("[green]‚úÖ FFmpeg installed successfully via imageio-ffmpeg![/green]")
        return True
    except Exception as e:
        console.print(f"[red]‚ùå Failed to install FFmpeg: {e}[/red]")
        return False

# Helper: Guide user to install FFmpeg manually
def guide_ffmpeg_installation():
    """Provide platform-specific FFmpeg installation instructions"""
    system = platform.system().lower()
    
    console.print(Panel(
        f"""[bold red]FFmpeg is required but not found![/bold red]

[yellow]Please install FFmpeg for your system:[/yellow]

[bold cyan]macOS (using Homebrew):[/bold cyan]
  brew install ffmpeg

[bold cyan]Ubuntu/Debian:[/bold cyan]
  sudo apt update && sudo apt install ffmpeg

[bold cyan]Windows (using Chocolatey):[/bold cyan]
  choco install ffmpeg

[bold cyan]Or download directly:[/bold cyan]
  https://ffmpeg.org/download.html

[dim]After installation, restart your terminal and run 'halo-video' again.[/dim]
""", 
        title="[red]FFmpeg Installation Required[/red]",
        box=box.DOUBLE
    ))

# Helper: Ensure FFmpeg is available
def ensure_ffmpeg() -> bool:
    """Ensure FFmpeg is available, try to install if missing"""
    if check_ffmpeg():
        console.print("[green]‚úÖ FFmpeg is available[/green]")
        return True
    
    console.print("[yellow]FFmpeg not found. Installing automatically...[/yellow]")
    
    # Try imageio-ffmpeg fallback
    try:
        import imageio_ffmpeg as ffmpeg_download
        console.print("Installing FFmpeg via imageio-ffmpeg...")
        ffmpeg_download.get_ffmpeg_exe()
        console.print("[green]‚úÖ FFmpeg installed successfully![/green]")
        return True
    except Exception as e:
        console.print(f"[red]Automatic installation failed: {e}[/red]")
        guide_ffmpeg_installation()
        return False

# Helper: Download YouTube video and extract audio
def extract_video_id(youtube_url: str) -> str:
    """Extracts the video ID from a YouTube URL."""
    match = re.search(r"(?:v=|youtu.be/)([\w-]+)", youtube_url)
    return match.group(1) if match else "unknown"

def get_video_info(youtube_url: str) -> Dict[str, Any]:
    """Get video information including title, duration, and thumbnail"""
    try:
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
        }
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=False)
            return {
                'title': info.get('title', 'Unknown Title'),
                'duration': info.get('duration', 0),
                'thumbnail': info.get('thumbnail', ''),
                'uploader': info.get('uploader', 'Unknown'),
                'view_count': info.get('view_count', 0),
                'upload_date': info.get('upload_date', ''),
            }
    except Exception as e:
        console.print(f"[yellow]Warning: Could not fetch video info: {e}[/yellow]")
        return {
            'title': 'Unknown Video',
            'duration': 0,
            'thumbnail': '',
            'uploader': 'Unknown',
            'view_count': 0,
            'upload_date': '',
        }

def show_video_preview(video_info: Dict[str, Any], video_id: str):
    """Display a preview of the video information"""
    duration_min = video_info['duration'] // 60
    duration_sec = video_info['duration'] % 60
    
    # Format view count
    views = video_info['view_count']
    if views >= 1000000:
        view_str = f"{views / 1000000:.1f}M views"
    elif views >= 1000:
        view_str = f"{views / 1000:.1f}K views"
    else:
        view_str = f"{views} views"
    
    preview_content = f"""[bold white]üì∫ Video Preview[/bold white]

[bold cyan]Title:[/bold cyan] {video_info['title']}
[bold yellow]Channel:[/bold yellow] {video_info['uploader']}
[bold green]Duration:[/bold green] {duration_min:02d}:{duration_sec:02d}
[bold blue]Views:[/bold blue] {view_str}
[bold purple]Video ID:[/bold purple] {video_id}

[dim]Ready to analyze this video with AI-powered question answering![/dim]"""
    
    console.print(Panel(
        preview_content,
        title="[bold magenta]üé¨ YouTube Video Detected[/bold magenta]",
        box=box.ROUNDED,
        style="cyan"
    ))

async def download_youtube_audio(youtube_url: str, output_dir: str) -> str:
    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': os.path.join(output_dir, '%(id)s.%(ext)s'),
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'wav',
            'preferredquality': '192',
        }],
        'quiet': True,
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(youtube_url, download=True)
        audio_path = ydl.prepare_filename(info).rsplit('.', 1)[0] + '.wav'
    return audio_path

# Helper: Extract frames every 15 seconds directly from stream (no video file saved)
def extract_frames_from_url(youtube_url: str, output_dir: str) -> List[str]:
    frame_pattern = os.path.join(output_dir, "frame_%04d.jpg")
    try:
        # First try with imageio-ffmpeg if available
        try:
            import imageio_ffmpeg as ffmpeg_download
            ffmpeg_exe = ffmpeg_download.get_ffmpeg_exe()
            console.print(f"[dim]Using imageio-ffmpeg: {ffmpeg_exe}[/dim]")
            
            # Use imageio-ffmpeg executable directly
            import subprocess
            cmd = [
                ffmpeg_exe,
                '-i', youtube_url,
                '-vf', 'fps=1/15',
                '-f', 'image2',
                '-vcodec', 'mjpeg',
                '-y',  # Overwrite output files
                frame_pattern
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode != 0:
                console.print(f"[yellow]imageio-ffmpeg failed: {result.stderr[:200]}[/yellow]")
                raise Exception("imageio-ffmpeg extraction failed")
                
        except Exception as e:
            console.print(f"[dim]imageio-ffmpeg not available, trying system ffmpeg: {e}[/dim]")
            
            # Fallback to system ffmpeg or ffmpeg-python
            try:
                (
                    ffmpeg
                    .input(youtube_url)
                    .output(frame_pattern, vf='fps=1/15', format='image2', vcodec='mjpeg')
                    .run(quiet=True, overwrite_output=True, timeout=60)
                )
            except Exception as e2:
                console.print(f"[yellow]ffmpeg-python failed: {str(e2)[:200]}[/yellow]")
                
                # Last resort: try direct system ffmpeg call
                import subprocess
                cmd = [
                    'ffmpeg',
                    '-i', youtube_url,
                    '-vf', 'fps=1/15',
                    '-f', 'image2',
                    '-vcodec', 'mjpeg',
                    '-y',
                    frame_pattern
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
                if result.returncode != 0:
                    raise Exception(f"System ffmpeg failed: {result.stderr[:200]}")
        
        # Collect all frame file paths
        frames = []
        if os.path.exists(output_dir):
            frames = sorted([
                os.path.join(output_dir, fname)
                for fname in os.listdir(output_dir)
                if fname.startswith("frame_") and fname.endswith(".jpg") and os.path.getsize(os.path.join(output_dir, fname)) > 1024  # At least 1KB
            ])
        
        if frames:
            console.print(f"[green]‚úÖ Successfully extracted {len(frames)} frames (every 15 seconds)[/green]")
        else:
            console.print("[yellow]‚ö†Ô∏è  No frames were extracted[/yellow]")
            
        return frames
        
    except subprocess.TimeoutExpired:
        console.print("[yellow]‚ö†Ô∏è  Frame extraction timed out after 60 seconds[/yellow]")
        return []
    except Exception as e:
        console.print(f"[yellow]‚ö†Ô∏è  Frame extraction failed: {str(e)[:200]}[/yellow]")
        console.print("[dim]Continuing with audio-only analysis...[/dim]")
        return []

# Helper: Describe an image frame using Gemini Vision API
async def describe_image(image_path: str, frame_number: int, timestamp: float, model=None) -> str:
    try:
        # Use provided model or create new one
        if model is None:
            config_manager = ConfigManager()
            api_key = config_manager.get_api_key()
            if not api_key:
                raise ValueError("No API key configured")
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')
        
        # Load and prepare the image
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Frame file not found: {image_path}")
            
        # Check file size
        file_size = os.path.getsize(image_path)
        if file_size < 1024:  # Less than 1KB
            raise ValueError(f"Frame file too small: {file_size} bytes")
            
        img = Image.open(image_path)
        
        # Verify image loaded properly
        if img.size[0] < 10 or img.size[1] < 10:
            raise ValueError(f"Invalid image dimensions: {img.size}")
        
        # Create a detailed prompt for image description
        minutes = int(timestamp // 60)
        seconds = int(timestamp % 60)
        
        prompt = f"""Analyze this video frame captured at {minutes:02d}:{seconds:02d}. Describe what you see in ONE concise sentence focusing on:
        - People and their actions/expressions
        - Objects, text, or graphics visible
        - Setting/environment details
        - Colors and composition
        
        Be factual and specific - this will help answer questions about the video content."""
        
        # Generate description using Gemini Vision
        response = model.generate_content([prompt, img])
        
        # Check if response is valid
        if not response or not hasattr(response, 'text') or not response.text:
            raise Exception("Empty response from Gemini Vision API")
            
        description = response.text.strip()
        
        # Ensure we got a meaningful response
        if not description or len(description) < 10 or description.lower() in ['', 'none', 'n/a', 'error']:
            raise Exception("Invalid or too short description received")
        
        return f"[{minutes:02d}:{seconds:02d}] {description}"
        
    except Exception as e:
        # Fallback description if API fails
        minutes = int(timestamp // 60)
        seconds = int(timestamp % 60)
        console.print(f"[yellow]‚ö†Ô∏è  Frame analysis failed for frame {frame_number} at {minutes:02d}:{seconds:02d}: {str(e)[:100]}[/yellow]")
        return f"[{minutes:02d}:{seconds:02d}] Video frame captured (visual analysis unavailable: {str(e)[:50]})"

# Helper: Transcribe audio using Whisper
async def transcribe_audio(audio_path: str) -> str:
    model = whisper.load_model("base")
    result = model.transcribe(audio_path)
    return result["text"]

# Command functions
def show_version():
    """Show version information with full attribution"""
    console.print(Panel(
        f"""[bold cyan]üé• HALO Video v{__version__}[/bold cyan]
[bold green]Interactive Video QA System[/bold green]

[yellow]üèõÔ∏è Built at Google DeepMind during Google Summer of Code 2025[/yellow]
[blue]üë®‚Äçüíª Created by: Jeet Dekivadia[/blue]  
[purple]‚ö° Powered by: Google Gemini Vision API[/purple]
[white]üìÑ License: MIT Open Source[/white]

[green]üåç AI-powered YouTube video analysis and question answering[/green]
[dim]https://github.com/jeet-dekivadia/google-deepmind[/dim]""",
        title="[bold magenta]About HALO Video[/bold magenta]",
        box=box.DOUBLE
    ))

def show_help():
    """Show comprehensive help"""
    help_table = Table(title="üéØ HALO Video Commands", box=box.ROUNDED)
    help_table.add_column("Command", style="bold cyan", no_wrap=True)
    help_table.add_column("Description", style="white")
    
    help_table.add_row("analyze", "üé• Analyze a YouTube video (main function)")
    help_table.add_row("config", "üîß Manage API key configuration")
    help_table.add_row("reset", "üîÑ Reset/re-enter API key")
    help_table.add_row("version", "üìã Show version information")
    help_table.add_row("upgrade", "‚¨ÜÔ∏è  Check for package updates")
    help_table.add_row("help", "‚ùì Show this help message")
    help_table.add_row("exit", "üëã Exit HALO Video")
    
    console.print(help_table)
    
    console.print(Panel(
        """[yellow]üí° Quick Start:[/yellow]
1. Run [cyan]'analyze'[/cyan] to start video analysis
2. Paste any YouTube URL when prompted
3. Ask questions about the video content
4. Type [cyan]'exit'[/cyan] to quit at any time

[yellow]üîë First time?[/yellow]
You'll be asked for your Google Gemini API key.
Get it free at: [blue]https://makersuite.google.com/app/apikey[/blue]

[green]üåü About HALO:[/green]
Interactive Video QA System built by Jeet Dekivadia during Google Summer 
of Code 2025 at Google DeepMind. Uses Google Gemini Vision API and Whisper 
for comprehensive video understanding and question answering.""",
        title="[bold green]Getting Started[/bold green]",
        box=box.DOUBLE
    ))

def check_for_updates():
    """Check for package updates"""
    try:
        import subprocess
        import json
        import re
        
        console.print("[dim]Checking for updates on PyPI...[/dim]")
        
        # Use pip index to check latest version
        result = subprocess.run([
            sys.executable, "-m", "pip", "index", "versions", "halo-video"
        ], capture_output=True, text=True, timeout=15)
        
        if result.returncode == 0 and result.stdout:
            # Parse the output to find available versions
            output = result.stdout.strip()
            # Look for version pattern in the output
            version_matches = re.findall(r'(\d+\.\d+\.\d+)', output)
            
            if version_matches:
                # Get the latest version (assuming they're in order)
                latest_version = version_matches[0]
                
                if latest_version != __version__:
                    console.print(f"[yellow]üì¶ Update available: v{latest_version} (current: v{__version__})[/yellow]")
                    console.print("[cyan]Run: pip install --upgrade halo-video[/cyan]")
                    return True
                else:
                    console.print(f"[green]‚úÖ You're running the latest version! (v{__version__})[/green]")
                    return False
        
        # Fallback: Try using PyPI API
        console.print("[dim]Trying PyPI API...[/dim]")
        result = subprocess.run([
            sys.executable, "-c", 
            "import requests; import json; r = requests.get('https://pypi.org/pypi/halo-video/json', timeout=10); print(r.json()['info']['version'])"
        ], capture_output=True, text=True, timeout=15)
        
        if result.returncode == 0 and result.stdout.strip():
            latest_version = result.stdout.strip().strip('"\'')
            if latest_version != __version__:
                console.print(f"[yellow]üì¶ Update available: v{latest_version} (current: v{__version__})[/yellow]")
                console.print("[cyan]Run: pip install --upgrade halo-video[/cyan]")
                return True
            else:
                console.print(f"[green]‚úÖ You're running the latest version! (v{__version__})[/green]")
                return False
                
        # If all methods fail
        console.print("[yellow]‚ö†Ô∏è  Could not check for updates. Please check manually at:[/yellow]")
        console.print("[blue]https://pypi.org/project/halo-video/[/blue]")
        return None
            
    except subprocess.TimeoutExpired:
        console.print("[yellow]‚ö†Ô∏è  Update check timed out[/yellow]")
        return None
    except Exception as e:
        console.print(f"[yellow]‚ö†Ô∏è  Update check failed: {str(e)[:100]}[/yellow]")
        console.print("[dim]You can check manually at: https://pypi.org/project/halo-video/[/dim]")
        return None

def manage_config():
    """Manage configuration"""
    config_manager = ConfigManager()
    
    if config_manager.has_api_key():
        console.print("[green]‚úÖ API key is configured[/green]")
        if Confirm.ask("[yellow]Would you like to view/change your API key?[/yellow]"):
            current_key = config_manager.get_api_key()
            masked_key = current_key[:8] + "..." + current_key[-8:] if len(current_key) > 16 else "***"
            console.print(f"[dim]Current API key: {masked_key}[/dim]")
            
            if Confirm.ask("[yellow]Enter a new API key?[/yellow]"):
                setup_api_key(config_manager, force_reset=True)
    else:
        console.print("[red]‚ùå No API key configured[/red]")
        setup_api_key(config_manager)

def setup_api_key(config_manager: ConfigManager, force_reset: bool = False):
    """Setup or reset API key with comprehensive handling"""
    if force_reset or not config_manager.has_api_key():
        console.print("\n[bold red]üîë Gemini API Key Required[/bold red]")
        console.print("[yellow]To use HALO, you need a Google Gemini API key.[/yellow]")
        console.print("[blue]Get your free API key at: https://makersuite.google.com/app/apikey[/blue]")
        console.print("[dim]Note: Your input will be hidden for security[/dim]")
        
        # Try multiple input methods for better compatibility
        api_key = None
        try:
            # First try with password=True (hidden input)
            api_key = Prompt.ask("[bold yellow]Enter your Gemini API key[/bold yellow]", password=True)
        except:
            try:
                # Fallback to regular input if password input fails
                console.print("[yellow]Note: API key input will be visible[/yellow]")
                api_key = Prompt.ask("[bold yellow]Enter your Gemini API key[/bold yellow]")
            except:
                # Final fallback to built-in input
                console.print("[yellow]Using basic input mode[/yellow]")
                api_key = input("Enter your Gemini API key: ")
        
        if not api_key or not api_key.strip():
            console.print("[bold red]‚ùå No API key provided.[/bold red]")
            return False
        
        api_key = api_key.strip()
        
        # Enhanced API key validation
        if not api_key.startswith('AI') or len(api_key) < 30:
            console.print("[bold yellow]‚ö†Ô∏è  Warning: API key format appears invalid[/bold yellow]")
            console.print("[dim]Expected format: AIzaSy... (starts with 'AIzaSy' and ~39 characters)[/dim]")
            if not Confirm.ask("[yellow]Continue anyway?[/yellow]", default=False):
                return False
        
        # Save the API key
        config_manager.save_api_key(api_key)
        console.print("[bold green]‚úÖ API key saved successfully![/bold green]")
        
        # Test API key immediately with better error handling
        console.print("[dim]üß™ Testing API key with Google Gemini...[/dim]")
        try:
            genai.configure(api_key=api_key)
            test_model = genai.GenerativeModel('gemini-1.5-flash')
            
            # Use a simple test prompt
            test_response = test_model.generate_content("Hello, respond with just 'API key working'")
            
            if test_response and hasattr(test_response, 'text') and test_response.text:
                response_text = test_response.text.strip().lower()
                if 'api' in response_text or 'working' in response_text or len(response_text) > 5:
                    console.print("[bold green]‚úÖ API key is working perfectly![/bold green]")
                    return True
                else:
                    console.print("[bold yellow]‚ö†Ô∏è  API key test returned unexpected response[/bold yellow]")
                    console.print(f"[dim]Response: {test_response.text[:100]}[/dim]")
            else:
                console.print("[bold yellow]‚ö†Ô∏è  API key test returned empty response[/bold yellow]")
                
        except Exception as e:
            error_msg = str(e).lower()
            if 'api_key' in error_msg or 'invalid' in error_msg or 'permission' in error_msg:
                console.print(f"[bold red]‚ùå API key is invalid: {str(e)[:200]}[/bold red]")
                console.print("[yellow]Please check your API key and try again.[/yellow]")
                config_manager.clear_config()  # Remove invalid key
                return False
            elif 'quota' in error_msg or 'limit' in error_msg:
                console.print(f"[bold yellow]‚ö†Ô∏è  API quota/limit issue: {str(e)[:200]}[/bold yellow]")
                console.print("[yellow]The API key appears valid but may have quota restrictions.[/yellow]")
            else:
                console.print(f"[bold yellow]‚ö†Ô∏è  API test failed: {str(e)[:200]}[/bold yellow]")
                console.print("[yellow]The API key was saved but testing failed. You can try to proceed.[/yellow]")
                
            return Confirm.ask("[yellow]Continue with this API key anyway?[/yellow]", default=True)
    
    # If we have an existing API key, validate it's still working
    try:
        api_key = config_manager.get_api_key()
        if api_key:
            genai.configure(api_key=api_key)
            console.print("[green]‚úÖ Using existing API key[/green]")
            return True
    except Exception as e:
        console.print(f"[yellow]‚ö†Ô∏è  Existing API key may have issues: {str(e)[:100]}[/yellow]")
        if Confirm.ask("[yellow]Would you like to enter a new API key?[/yellow]"):
            return setup_api_key(config_manager, force_reset=True)
    
    return True

def show_main_menu():
    """Show the main interactive menu"""
    console.clear()
    console.print(HALO_BANNER)
    console.print(WELCOME_MESSAGE)
    
    menu_table = Table(title="üéØ Choose an Action", box=box.ROUNDED, show_header=False)
    menu_table.add_column("Option", style="bold cyan", no_wrap=True)
    menu_table.add_column("Description", style="white")
    
    menu_table.add_row("1", "üé• Analyze YouTube Video")
    menu_table.add_row("2", "üîß Manage API Key")
    menu_table.add_row("3", "üìã Show Version")
    menu_table.add_row("4", "‚¨ÜÔ∏è  Check for Updates")
    menu_table.add_row("5", "‚ùì Show Help")
    menu_table.add_row("6", "üëã Exit")
    
    console.print(menu_table)
    
    while True:
        choice = Prompt.ask(
            "\n[bold yellow]Enter your choice (1-6) or command name[/bold yellow]",
            choices=["1", "2", "3", "4", "5", "6", "analyze", "config", "version", "upgrade", "help", "exit"],
            show_choices=False
        )
        
        if choice in ["1", "analyze"]:
            return "analyze"
        elif choice in ["2", "config"]:
            return "config"
        elif choice in ["3", "version"]:
            return "version"
        elif choice in ["4", "upgrade"]:
            return "upgrade"
        elif choice in ["5", "help"]:
            return "help"
        elif choice in ["6", "exit"]:
            return "exit"
# Interactive CLI for video analysis
async def analyze_video():
    """Main video analysis function with enhanced preview and QA capabilities"""
    config_manager = ConfigManager()
    
    # Ensure FFmpeg is available
    if not ensure_ffmpeg():
        console.print("[bold red]‚ùå Cannot proceed without FFmpeg. Please install it and try again.[/bold red]")
        return
    
    # Check for API key
    if not setup_api_key(config_manager):
        return
    
    console.print("\n[bold blue]üìπ YouTube Video Analysis[/bold blue]")
    console.print("[dim]Paste a YouTube link to analyze its content and ask questions about it.[/dim]")
    console.rule("[bold cyan]VIDEO INPUT[/bold cyan]")
    
    youtube_url = Prompt.ask("[bold yellow]üîó Enter YouTube video link[/bold yellow]").strip()
    if not youtube_url or youtube_url.lower() == 'exit':
        console.print("[bold yellow]üëã Analysis cancelled.[/bold yellow]")
        return
        
    video_id = extract_video_id(youtube_url)
    
    # Get and display video preview
    console.print("\n[dim]Fetching video information...[/dim]")
    video_info = get_video_info(youtube_url)
    show_video_preview(video_info, video_id)
    
    # Confirm analysis
    if not Confirm.ask("\n[bold yellow]üöÄ Start analyzing this video?[/bold yellow]", default=True):
        console.print("[yellow]Analysis cancelled.[/yellow]")
        return
    
    with tempfile.TemporaryDirectory() as tmpdir:
        console.rule("[bold cyan]PROCESSING PIPELINE[/bold cyan]")
        
        # Step 1: Download audio
        with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}"), transient=True) as progress:
            task = progress.add_task(description="üéµ Downloading and extracting audio...", total=None)
            audio_path = await download_youtube_audio(youtube_url, tmpdir)
        console.print(f"[green]‚úÖ Audio extracted successfully[/green]")
        
        # Step 2: Extract frames
        with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}"), transient=True) as progress:
            task = progress.add_task(description="üñºÔ∏è  Extracting video frames (every 15 seconds)...", total=None)
            frames = extract_frames_from_url(youtube_url, tmpdir)

        # Step 3: Transcribe audio
        with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}"), transient=True) as progress:
            task = progress.add_task(description="üéôÔ∏è  Transcribing audio using Whisper AI...", total=None)
            transcript = await transcribe_audio(audio_path)
        console.print(f"[green]‚úÖ Audio transcribed ({len(transcript)} characters)[/green]")
        
        # Step 4: Analyze frames with Gemini Vision
        frame_descriptions = []
        if frames:
            try:
                api_key = config_manager.get_api_key()
                if not api_key:
                    raise ValueError("No API key configured")
                genai.configure(api_key=api_key)
                vision_model = genai.GenerativeModel('gemini-1.5-flash')
                
                console.print(f"[dim]üîç Analyzing {len(frames)} visual frames with Gemini Vision...[/dim]")
                
                with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}"), transient=True) as progress:
                    task = progress.add_task(description="üëÅÔ∏è  Analyzing frames with Gemini Vision...", total=len(frames))
                    for i, frame_path in enumerate(frames):
                        timestamp = i * 15  # 15 seconds per frame
                        desc = await describe_image(frame_path, i, timestamp, vision_model)
                        if desc and len(desc) > 20:  # Only add meaningful descriptions
                            frame_descriptions.append(desc)
                        progress.update(task, advance=1)
                        
                console.print(f"[green]‚úÖ Analyzed {len(frame_descriptions)} visual frames successfully[/green]")
                        
            except Exception as e:
                console.print(f"[bold red]‚ùå Error with vision analysis: {str(e)[:200]}[/bold red]")
                console.print("[yellow]Continuing with audio transcript only...[/yellow]")
                frame_descriptions = []
                
        # Combine transcript with visual context for better Q&A
        if frame_descriptions:
            frames_text = "\n".join(frame_descriptions)
            transcript_with_images = transcript + "\n\n=== VISUAL CONTEXT (Key frames every 15 seconds) ===\n" + frames_text
            console.print(f"[bold green]üéØ Ready for Q&A! Video content analyzed with audio transcript + {len(frame_descriptions)} visual context frames[/bold green]")
        else:
            transcript_with_images = transcript
            console.print("[bold green]üéØ Ready for Q&A! Video content analyzed with audio transcript only[/bold green]")
        
        # Prepare for question answering
        chunks = chunk_transcript(transcript_with_images, max_tokens=4000, overlap=500)
        total_tokens_full = estimate_tokens(transcript_with_images)
        
        # Display analysis summary
        console.print(Panel(
            f"""[bold cyan]üìä Analysis Complete[/bold cyan]

[bold white]Video:[/bold white] {video_info['title']}
[bold white]Channel:[/bold white] {video_info['uploader']}
[bold white]Duration:[/bold white] {video_info['duration'] // 60:02d}:{video_info['duration'] % 60:02d}

[bold yellow]Content Analysis:[/bold yellow]
‚Ä¢ Audio transcript: {len(transcript)} characters
‚Ä¢ Visual frames: {len(frame_descriptions)} analyzed
‚Ä¢ Processing chunks: {len(chunks)} (optimized for efficiency)
‚Ä¢ Total content tokens: ~{total_tokens_full}

[green]üí¨ Ready to answer your questions![/green]""", 
            title="[bold magenta]üé¨ Video Analysis Summary[/bold magenta]", 
            box=box.DOUBLE
        ))
        
        # Initialize Q&A system
        total_tokens_sent = 0
        total_tokens_saved = 0
        cache_hits = 0
        cache_lookups = 0
        question_history = []
        
        # Initialize predictor with proper API key
        try:
            api_key = config_manager.get_api_key()
            if not api_key:
                raise ValueError("No API key configured")
            predictor = GeminiBatchPredictor(api_key=api_key, use_persistent_cache=True)
        except Exception as e:
            console.print(f"[bold red]‚ùå Error initializing Q&A system: {e}[/bold red]")
            return
        
        console.rule("[bold cyan]INTERACTIVE Q&A SESSION[/bold cyan]")
        console.print("[bold blue]üí≠ Ask questions about the video content. Type 'exit' to finish.[/bold blue]\n")
        
        try:
            while True:
                # Show question history if exists
                if question_history:
                    history_text = "\n".join([f"[bold cyan]Q{idx+1}:[/bold cyan] {q}" for idx, q in enumerate(question_history[-3:])])  # Show last 3 questions
                    console.print(Panel(history_text, title="[bold yellow]üìù Recent Questions[/bold yellow]", style="dim", box=box.ROUNDED))
                
                # Get user question
                question = Prompt.ask("[bold yellow]üí≠ What would you like to know about this video?[/bold yellow]").strip()
                if question.lower() in ("exit", "quit", "done"): 
                    break
                
                if not question:
                    console.print("[yellow]Please enter a question about the video.[/yellow]")
                    continue
                    
                question_history.append(question)
                
                console.rule("[bold cyan]üß† AI PROCESSING[/bold cyan]")
                
                # Find relevant context for the question
                console.print("[dim]üîç Analyzing question and finding relevant content...[/dim]")
                context = find_relevant_chunk(question, chunks)
                context_tokens = estimate_tokens(context)
                
                console.print(f"[dim]üìä Using {context_tokens} tokens of context (optimized from {total_tokens_full} total)[/dim]")
                
                # Check cache first
                cache_key = predictor._make_cache_key(video_id, question, context)
                cached = None
                if hasattr(predictor.cache, 'get'):
                    cached = predictor.cache.get(cache_key)
                    if asyncio.iscoroutine(cached):
                        cached = await cached
                
                cache_lookups += 1
                
                if cached:
                    cache_hits += 1
                    console.print("[dim]üíæ Found cached answer[/dim]")
                    console.print(Panel(cached, title="[bold green]ü§ñ Answer (from cache)[/bold green]", style="green", box=box.ROUNDED))
                    tokens_saved = total_tokens_full - context_tokens
                    total_tokens_saved += max(0, tokens_saved)
                else:
                    # Generate new answer
                    with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}"), transient=True) as progress:
                        task = progress.add_task(description="ü§ñ Generating AI answer using Gemini...", total=None)
                        questions = [{"question": question}]
                        results = await predictor.predict_batch(context, questions, use_chunking=False, video_id=video_id, context_override=context)
                    
                    answer = results[0]["answer"]
                    console.print(Panel(answer, title="[bold blue]ü§ñ Answer[/bold blue]", style="blue", box=box.ROUNDED))
                    
                    total_tokens_sent += context_tokens
                    tokens_saved = total_tokens_full - context_tokens
                    total_tokens_saved += max(0, tokens_saved)
                
                # Ask for feedback
                console.print("\n[dim]Was this answer helpful? You can ask follow-up questions or type 'exit' to finish.[/dim]")
                
                # Option for expanded answer if needed
                if not cached:
                    needs_more = Prompt.ask("[bold yellow]üîç Need more detailed answer? (y/N)[/bold yellow]", default="n").strip().lower()
                    if needs_more == 'y':
                        console.print("[dim]üîç Expanding context for more comprehensive answer...[/dim]")
                        
                        # Use multiple relevant chunks for expanded context
                        scored_chunks = [(c, sum(c.lower().count(k) for k in question.lower().split())) for c in chunks]
                        top_chunks = sorted(scored_chunks, key=lambda x: -x[1])[:3]
                        merged_context = '\n'.join([c[0] for c in top_chunks])
                        merged_tokens = estimate_tokens(merged_context)
                        
                        with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}"), transient=True) as progress:
                            task = progress.add_task(description="ü§ñ Generating expanded answer...", total=None)
                            results = await predictor.predict_batch(merged_context, questions, use_chunking=False, video_id=video_id, context_override=merged_context)
                        
                        expanded_answer = results[0]["answer"]
                        console.print(Panel(expanded_answer, title="[bold magenta]ü§ñ Expanded Answer[/bold magenta]", style="magenta", box=box.ROUNDED))
                        
                        total_tokens_sent += merged_tokens
                        tokens_saved = total_tokens_full - merged_tokens
                        total_tokens_saved += max(0, tokens_saved)
        finally:
            await predictor.close()
        
        # Show final session summary
        console.rule("[bold green]üìä SESSION COMPLETE[/bold green]")
        
        summary_table = Table(title="üéØ Q&A Session Summary", show_lines=True, box=box.DOUBLE)
        summary_table.add_column("Metric", style="bold")
        summary_table.add_column("Value", style="cyan")
        
        summary_table.add_row("Questions Asked", str(len(question_history)))
        summary_table.add_row("Total Tokens Processed", str(total_tokens_sent))
        summary_table.add_row("Tokens Saved (Optimization)", str(total_tokens_saved))
        summary_table.add_row("Cache Lookups", str(cache_lookups))
        summary_table.add_row("Cache Hits", str(cache_hits))
        
        hit_rate = f"{(cache_hits / cache_lookups * 100):.1f}%" if cache_lookups else "0%"
        summary_table.add_row("Cache Efficiency", hit_rate)
        
        # Calculate efficiency
        if total_tokens_full > 0:
            efficiency = f"{(total_tokens_saved / total_tokens_full * 100):.1f}%"
            summary_table.add_row("Processing Efficiency", efficiency)
        
        console.print(summary_table)
        
        console.print(Panel(
            f"""[bold green]‚úÖ Video Analysis Complete![/bold green]

[bold cyan]Video:[/bold cyan] {video_info['title']}
[bold cyan]Questions Answered:[/bold cyan] {len(question_history)}
[bold cyan]AI Technology:[/bold cyan] Google Gemini Vision + Whisper Audio

[yellow]Thank you for using the Interactive Video QA System![/yellow]
[dim]Built by Jeet Dekivadia during Google Summer of Code at Google DeepMind[/dim]""",
            title="[bold magenta]üé¨ Analysis Summary[/bold magenta]",
            box=box.ROUNDED,
            style="green"
        ))

# Main CLI application
async def run_cli():
    """Main CLI application with menu system"""
    try:
        while True:
            action = show_main_menu()
            
            if action == "analyze":
                await analyze_video()
                if not Confirm.ask("\n[yellow]Would you like to analyze another video?[/yellow]"):
                    break
            elif action == "config":
                manage_config()
                input("\nPress Enter to continue...")
            elif action == "version":
                show_version()
                input("\nPress Enter to continue...")
            elif action == "upgrade":
                check_for_updates()
                input("\nPress Enter to continue...")
            elif action == "help":
                show_help()
                input("\nPress Enter to continue...")
            elif action == "exit":
                break
                
    except KeyboardInterrupt:
        pass
    
    console.print("\n[bold blue]Thank you for using HALO Video![/bold blue]")
    console.print("[green]Built by Jeet Dekivadia during Google Summer of Code at Google DeepMind[/green]")

# Legacy function name for backward compatibility
async def interactive_cli():
    """Legacy function for backward compatibility"""
    await run_cli()

def main():
    """Main entry point for the CLI application."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="üé• HALO Video - AI-powered YouTube video analysis",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  halo-video              Start interactive CLI
  halo-video --version    Show version
  halo-video --help       Show this help

For more information, visit: https://github.com/jeet-dekivadia/halo-video
        """
    )
    parser.add_argument('--version', action='version', version=f'HALO Video {__version__}')
    parser.add_argument('--config', action='store_true', help='Manage API key configuration')
    parser.add_argument('--reset', action='store_true', help='Reset API key')
    parser.add_argument('--upgrade-check', action='store_true', help='Check for updates')
    
    args = parser.parse_args()
    
    try:
        if args.config:
            manage_config()
        elif args.reset:
            config_manager = ConfigManager()
            config_manager.clear_config()
            setup_api_key(config_manager, force_reset=True)
        elif args.upgrade_check:
            check_for_updates()
        else:
            # Show welcome message for first-time users
            config_manager = ConfigManager()
            if not config_manager.has_api_key():
                console.print(Panel(
                    """[bold green]Welcome to HALO Video![/bold green]
                    
[yellow]Interactive Video QA System[/yellow]

AI-powered YouTube video analysis tool built by Jeet Dekivadia 
during Google Summer of Code 2025 at Google DeepMind.

[green]Purpose:[/green] Analyze YouTube videos and answer questions about their content
[green]Features:[/green] Audio transcription, visual frame analysis, intelligent Q&A

[cyan]To get started, you'll need a free Gemini API key:[/cyan]
[blue]https://makersuite.google.com/app/apikey[/blue]

[dim]Contact: jeet.university@gmail.com[/dim]""",
                    title="[bold blue]HALO - GSoC 2025 Project[/bold blue]",
                    box=box.ROUNDED
                ))
            
            asyncio.run(run_cli())
    except KeyboardInterrupt:
        console.print("\n[bold yellow]üëã Goodbye![/bold yellow]")
    except Exception as e:
        console.print(f"\n[bold red]‚ùå Error: {e}[/bold red]")
        console.print("[dim]For help, run: halo-video --help[/dim]")

if __name__ == "__main__":
    main()
