import pandas as pd
import pandera.pandas as pa
from pandera.typing import DataFrame
from babel.dates import format_date

from electricore.core.p√©rim√®tre.mod√®les import HistoriqueP√©rim√®tre, SituationP√©rim√®tre, ModificationContractuelleImpactante
from electricore.core.relev√©s.mod√®les import Relev√©Index

@pa.check_types
def extraire_situation(date: pd.Timestamp, historique: DataFrame[HistoriqueP√©rim√®tre]) -> DataFrame[SituationP√©rim√®tre]:
    """
    Extrait la situation du p√©rim√®tre √† une date donn√©e.
    
    Args:
        date (pd.Timestamp): La date de r√©f√©rence.
        historique (pd.DataFrame): L'historique des √©v√©nements contractuels.

    Returns:
        pd.DataFrame: Une vue du p√©rim√®tre √† `date`, conforme √† `SituationP√©rim√®tre`.
    """
    return (
        historique[historique["Date_Evenement"] <= date]
        .sort_values(by="Date_Evenement", ascending=False)
        .drop_duplicates(subset=["Ref_Situation_Contractuelle"], keep="first")
    )
@pa.check_types
def extraire_historique_√†_date(
    historique: DataFrame[HistoriqueP√©rim√®tre],
    fin: pd.Timestamp
) -> DataFrame[HistoriqueP√©rim√®tre]:
    """
    Extrait uniquement les variations (changements contractuels) qui ont eu lieu dans une p√©riode donn√©e.

    Args:
        deb (pd.Timestamp): D√©but de la p√©riode.
        fin (pd.Timestamp): Fin de la p√©riode.
        historique (pd.DataFrame): Historique des √©v√©nements contractuels.

    Returns:
        pd.DataFrame: Un sous-ensemble de l'historique contenant uniquement les variations dans la p√©riode.
    """
    return historique[
        (historique["Date_Evenement"] <= fin)
    ].sort_values(by="Date_Evenement", ascending=True)  # Trie par ordre chronologique

@pa.check_types
def extraire_p√©riode(
    deb: pd.Timestamp, fin: pd.Timestamp, 
    historique: DataFrame[HistoriqueP√©rim√®tre]
) -> DataFrame[HistoriqueP√©rim√®tre]:
    """
    Extrait uniquement les variations (changements contractuels) qui ont eu lieu dans une p√©riode donn√©e.

    Args:
        deb (pd.Timestamp): D√©but de la p√©riode.
        fin (pd.Timestamp): Fin de la p√©riode.
        historique (pd.DataFrame): Historique des √©v√©nements contractuels.

    Returns:
        pd.DataFrame: Un sous-ensemble de l'historique contenant uniquement les variations dans la p√©riode.
    """
    return historique[
        (historique["Date_Evenement"] >= deb) & (historique["Date_Evenement"] <= fin)
    ].sort_values(by="Date_Evenement", ascending=True)  # Trie par ordre chronologique

@pa.check_types
def extraite_relev√©s_entr√©es(
    historique: DataFrame[HistoriqueP√©rim√®tre]
) -> DataFrame[Relev√©Index]:
        _√©v√©nements = ['MES', 'PMES', 'CFNE']
        _colonnes_meta_releve = ['Ref_Situation_Contractuelle', 'pdl', 'Unit√©', 'Pr√©cision', 'Source']
        _colonnes_relev√© = ['Id_Calendrier_Distributeur', 'Date_Releve', 'Nature_Index', 'HP', 'HC', 'HCH', 'HPH', 'HPB', 'HCB', 'BASE']
        _colonnes_relev√©_apr√®s = ['Apr√®s_'+c for c in _colonnes_relev√©]
        return Relev√©Index.validate(
            historique[historique['Evenement_Declencheur'].isin(_√©v√©nements)][_colonnes_meta_releve + _colonnes_relev√©_apr√®s]
            .rename(columns={k: v for k,v in zip(_colonnes_relev√©_apr√®s, _colonnes_relev√©)})
            .dropna(subset=['Date_Releve'])
            )

@pa.check_types
def extraite_relev√©s_sorties(
    historique: DataFrame[HistoriqueP√©rim√®tre]
) -> DataFrame[Relev√©Index]:
        _√©v√©nements = ['RES', 'CFNS']
        _colonnes_meta_releve = ['Ref_Situation_Contractuelle', 'pdl', 'Unit√©', 'Pr√©cision', 'Source']
        _colonnes_relev√© = ['Id_Calendrier_Distributeur', 'Date_Releve', 'Nature_Index', 'HP', 'HC', 'HCH', 'HPH', 'HPB', 'HCB', 'BASE']
        _colonnes_relev√©_avant = ['Avant_'+c for c in _colonnes_relev√©]
        return Relev√©Index.validate(
            historique[historique['Evenement_Declencheur'].isin(_√©v√©nements)][_colonnes_meta_releve + _colonnes_relev√©_avant]
            .rename(columns={k: v for k,v in zip(_colonnes_relev√©_avant, _colonnes_relev√©)})
            .dropna(subset=['Date_Releve'])
            )

@pa.check_types
def extraire_modifications_impactantes(
    deb: pd.Timestamp,
    historique: DataFrame[HistoriqueP√©rim√®tre]
) -> DataFrame[ModificationContractuelleImpactante]:
    """
    D√©tecte les MCT dans une p√©riode donn√©e et renvoie les variations de Puissance_Souscrite
    et Formule_Tarifaire_Acheminement avant et apr√®s chaque MCT.

    Args:
        deb (pd.Timestamp): D√©but de la p√©riode.
        historique (pd.DataFrame): Historique des √©v√©nements contractuels.

    Returns:
        DataFrame[ModificationContractuelleImpactante]: DataFrame contenant les MCT avec les valeurs avant/apr√®s.
    """

    # üîç D√©caler les valeurs pour obtenir les donn√©es "avant" AVANT de filtrer
    historique = historique.sort_values(by=["Ref_Situation_Contractuelle", "Date_Evenement"])
    historique["Avant_Puissance_Souscrite"] = historique.groupby("Ref_Situation_Contractuelle")["Puissance_Souscrite"].shift(1)
    historique["Avant_Formule_Tarifaire_Acheminement"] = historique.groupby("Ref_Situation_Contractuelle")["Formule_Tarifaire_Acheminement"].shift(1)


    # üìå Filtrer uniquement les MCT dans la p√©riode donn√©e
    impacts = (
          historique[
            (historique["Date_Evenement"] >= deb) &
            (historique["Evenement_Declencheur"] == "MCT")]
          .copy()
          .rename(columns={'Puissance_Souscrite': 'Apr√®s_Puissance_Souscrite', 'Formule_Tarifaire_Acheminement':'Apr√®s_Formule_Tarifaire_Acheminement'})
          .drop(columns=['Segment_Clientele', 'Num_Depannage', 'Categorie', 'Etat_Contractuel', 'Type_Compteur', 'Date_Derniere_Modification_FTA', 'Type_Evenement', 'Ref_Demandeur', 'Id_Affaire'])
    )
    
    # TODO: Prendre en compte plus de cas
    impacts['Impacte_energies'] = (
        impacts["Avant_Id_Calendrier_Distributeur"].notna() & 
        impacts["Apr√®s_Id_Calendrier_Distributeur"].notna() & 
        (impacts["Avant_Id_Calendrier_Distributeur"] != impacts["Apr√®s_Id_Calendrier_Distributeur"])
    )

    # ‚ûï Ajout de la colonne de lisibilit√© du changement
    def generer_resum√©(row):
        modifications = []
        if row["Avant_Puissance_Souscrite"] != row["Apr√®s_Puissance_Souscrite"]:
            modifications.append(f"P: {row['Avant_Puissance_Souscrite']} ‚Üí {row['Apr√®s_Puissance_Souscrite']}")
        if row["Avant_Formule_Tarifaire_Acheminement"] != row["Apr√®s_Formule_Tarifaire_Acheminement"]:
            modifications.append(f"FTA: {row['Avant_Formule_Tarifaire_Acheminement']} ‚Üí {row['Apr√®s_Formule_Tarifaire_Acheminement']}")
        return ", ".join(modifications) if modifications else "Aucun changement"
    
    impacts["R√©sum√©_Modification"] = impacts.apply(generer_resum√©, axis=1)

    ordre_colonnes = ModificationContractuelleImpactante.to_schema().columns.keys()
    impacts = impacts[ordre_colonnes]
    
    return impacts

@pa.check_types
def detecter_points_de_rupture(historique: DataFrame[HistoriqueP√©rim√®tre]) -> DataFrame[HistoriqueP√©rim√®tre]:
    """
    Enrichit l'historique avec les colonnes d'impact (turpe, √©nergie, turpe_variable) et un r√©sum√© des modifications.
    Toutes les lignes sont conserv√©es.

    Args:
        historique (pd.DataFrame): Historique complet des √©v√©nements contractuels.

    Returns:
        pd.DataFrame: Historique enrichi avec d√©tection des ruptures et r√©sum√© humain.
    """
    index_cols = ['BASE', 'HP', 'HC', 'HPH', 'HCH', 'HPB', 'HCB']

    historique = historique.sort_values(by=["Ref_Situation_Contractuelle", "Date_Evenement"]).copy()
    historique["Avant_Puissance_Souscrite"] = historique.groupby("Ref_Situation_Contractuelle")["Puissance_Souscrite"].shift(1)
    historique["Avant_Formule_Tarifaire_Acheminement"] = historique.groupby("Ref_Situation_Contractuelle")["Formule_Tarifaire_Acheminement"].shift(1)

    changement_fta = (
        historique["Avant_Formule_Tarifaire_Acheminement"].notna() &
        (historique["Avant_Formule_Tarifaire_Acheminement"] != historique["Formule_Tarifaire_Acheminement"])
    )
    
    impacte_abonnement = (
        (historique["Avant_Puissance_Souscrite"].notna() &
         (historique["Avant_Puissance_Souscrite"] != historique["Puissance_Souscrite"])) |
        changement_fta
    )
    
    changement_calendrier = (
        historique["Avant_Id_Calendrier_Distributeur"].notna() &
        historique["Apr√®s_Id_Calendrier_Distributeur"].notna() &
        (historique["Avant_Id_Calendrier_Distributeur"] != historique["Apr√®s_Id_Calendrier_Distributeur"])
    )
    
    changement_index = pd.concat([
        (historique[f"Avant_{col}"].notna() &
         historique[f"Apr√®s_{col}"].notna() &
         (historique[f"Avant_{col}"] != historique[f"Apr√®s_{col}"]))
        for col in index_cols
    ], axis=1).any(axis=1)

    impacte_energie = changement_calendrier | changement_index | changement_fta


    historique["impacte_abonnement"] = impacte_abonnement
    historique["impacte_energie"] = impacte_energie

    # Forcer les impacts √† True pour les √©v√©nements d‚Äôentr√©e et de sortie
    evenements_entree_sortie = ["CFNE", "MES", "PMES", "CFNS", "RES"]
    mask_entree_sortie = historique["Evenement_Declencheur"].isin(evenements_entree_sortie)

    historique.loc[mask_entree_sortie, ["impacte_abonnement", "impacte_energie"]] = True

    def generer_resume(row):
        modifs = []
        if row["impacte_abonnement"]:
            if pd.notna(row.get("Avant_Puissance_Souscrite")) and row["Avant_Puissance_Souscrite"] != row["Puissance_Souscrite"]:
                modifs.append(f"P: {row['Avant_Puissance_Souscrite']} ‚Üí {row['Puissance_Souscrite']}")
            if pd.notna(row.get("Avant_Formule_Tarifaire_Acheminement")) and row["Avant_Formule_Tarifaire_Acheminement"] != row["Formule_Tarifaire_Acheminement"]:
                modifs.append(f"FTA: {row['Avant_Formule_Tarifaire_Acheminement']} ‚Üí {row['Formule_Tarifaire_Acheminement']}")
        if row["impacte_energie"]:
            modifs.append("rupture index")
        if changement_calendrier.loc[row.name]:
            modifs.append(f"Cal: {row['Avant_Id_Calendrier_Distributeur']} ‚Üí {row['Apr√®s_Id_Calendrier_Distributeur']}")
        return ", ".join(modifs) if modifs else ""

    historique["resume_modification"] = historique.apply(generer_resume, axis=1)

    return historique.reset_index(drop=True)




@pa.check_types
def inserer_evenements_facturation(historique: DataFrame[HistoriqueP√©rim√®tre]) -> DataFrame[HistoriqueP√©rim√®tre]:
    """
    Ins√®re des √©v√©nements de facturation artificielle au 1er de chaque mois.
    
    Cette fonction g√©n√®re des √©v√©nements "FACTURATION" pour permettre un calcul mensuel
    des abonnements. Elle traite chaque PDL individuellement selon sa p√©riode d'activit√©.
    
    LOGIQUE GLOBALE :
    1. D√©tecter les p√©riodes d'activit√© de chaque PDL (entr√©e ‚Üí sortie)
    2. G√©n√©rer tous les 1ers du mois dans la plage globale
    3. Associer chaque PDL aux mois o√π il est actif
    4. Cr√©er les √©v√©nements artificiels et propager les donn√©es contractuelles
    
    Args:
        historique: DataFrame contenant l'historique des √©v√©nements contractuels
        
    Returns:
        DataFrame √©tendu avec les √©v√©nements de facturation artificiels
    """
    tz = "Europe/Paris"

    # =============================================================================
    # √âTAPE 1 : D√âTECTION DES P√âRIODES D'ACTIVIT√â (INDIVIDUALIS√â PAR PDL)
    # =============================================================================
    
    # 1A. D√©finir la date limite pour les PDL non r√©sili√©s
    # LOGIQUE : g√©n√®re des √©v√©nements jusqu'au d√©but du mois courant inclus
    fin_par_defaut = pd.Timestamp.now(tz=tz).to_period("M").start_time.tz_localize(tz)
    
    # 1B. Construire les p√©riodes d'activit√© valides avec filtrage int√©gr√©
    periodes = (pd.DataFrame({
        "start": (historique
            .query("Evenement_Declencheur in ['CFNE', 'MES', 'PMES']")
            .groupby('Ref_Situation_Contractuelle')['Date_Evenement']
            .min()),
        "end": (historique
            .query("Evenement_Declencheur in ['RES', 'CFNS']")
            .groupby('Ref_Situation_Contractuelle')['Date_Evenement']
            .max())
    })
    .fillna(fin_par_defaut)
    # Filtrer les PDL entr√©s apr√®s la date limite (pas d'√©v√©nements pour ces PDL)
    # LOGIQUE : Un PDL entr√© apr√®s le 1er du mois courant ne g√©n√®re pas d'√©v√©nements pour ce mois
    .query("start <= end"))
    
    if len(periodes) == 0:
        return historique  # Retourner l'historique original sans modification

    # =============================================================================
    # √âTAPE 2 : G√âN√âRATION DES DATES MENSUELLES (GLOBAL)
    # =============================================================================
    
    # 2A. G√©n√©rer tous les 1ers du mois dans la plage globale (inclus)
    # ASTUCE : ajouter 1 jour √† max_date pour √™tre s√ªr d'inclure le mois de fin
    all_months = pd.date_range(
        start=periodes["start"].min(),
        end=periodes["end"].max() + pd.DateOffset(days=1),
        freq="MS", 
        tz=tz
    )
    
    # =============================================================================
    # √âTAPE 3-4 : CR√âATION DES √âV√âNEMENTS ARTIFICIELS (PIPE UNIFI√â)
    # =============================================================================
    
    # Cr√©er les √©v√©nements de facturation en pipe unique
    evenements = (
        periodes.reset_index()
        # Produit cart√©sien : chaque PDL valide √ó chaque mois
        .merge(pd.DataFrame({"Date_Evenement": all_months}), how="cross")
        # Ajouter le mapping Ref_Situation_Contractuelle ‚Üí pdl
        .merge(
            historique[['Ref_Situation_Contractuelle', 'pdl']].drop_duplicates(), 
            on='Ref_Situation_Contractuelle', 
            how='left'
        )
        # Filtrer pour ne garder que les mois o√π chaque PDL est actif
        # CORRECTION : comparer les dates, pas les timestamps avec heures
        # Car les √©v√©nements FACTURATION sont g√©n√©r√©s avec freq="MS" (d√©but de mois avec heure)
        # alors que fin_par_defaut est √† 00:00:00
        # IMPORTANT : on exclue le mois d'entr√©e, c'est le relev√© CFNE/MES qui sera d√©but de p√©riode
        .query("Date_Evenement.dt.date > start.dt.date and Date_Evenement.dt.date <= end.dt.date")
        # Ajouter les colonnes d'√©v√©nements artificiels
        .assign(
            Evenement_Declencheur="FACTURATION",
            Type_Evenement="artificiel",
            Source="synthese_mensuelle",
            resume_modification="Facturation mensuelle",
            impacte_abonnement=True,
            impacte_energie=True
        )
        # S√©lectionner les colonnes n√©cessaires
        [[
            "Ref_Situation_Contractuelle", "pdl", "Date_Evenement",
            "Evenement_Declencheur", "Type_Evenement", "Source", "resume_modification",
            "impacte_abonnement", "impacte_energie"
        ]]
    )

    # =============================================================================
    # √âTAPE 5 : PROPAGATION DES DONN√âES CONTRACTUELLES (PIPE UNIFI√â)
    # =============================================================================
    
    # Fusionner et propager les donn√©es contractuelles en pipe unique
    fusion = (
        pd.concat([historique, evenements], ignore_index=True)
        .sort_values(["Ref_Situation_Contractuelle", "Date_Evenement"])
        .reset_index(drop=True)
        .assign(**{
            # Propager les donn√©es par PDL avec forward fill
            # LOGIQUE : chaque √©v√©nement artificiel h√©rite des caract√©ristiques du dernier √©v√©nement r√©el
            col: lambda df, c=col: df.groupby("Ref_Situation_Contractuelle")[c].ffill()
            for col in [
                name for name, col_info in HistoriqueP√©rim√®tre.to_schema().columns.items()
                if not col_info.nullable
            ]
            # Filtrer les colonnes pr√©sentes dans le DataFrame
            if col in pd.concat([historique, evenements], ignore_index=True).columns
        })
    )
    return fusion

@pa.check_types
def extraire_releves_evenements(historique: DataFrame[HistoriqueP√©rim√®tre]) -> DataFrame[Relev√©Index]:
    """
    G√©n√®re des relev√©s d'index (avant/apr√®s) √† partir d'un historique enrichi des √©v√©nements contractuels.

    - Un relev√© "avant" (ordre_index=0) est cr√©√© √† partir des index Avant_*
    - Un relev√© "apr√®s" (ordre_index=1) est cr√©√© √† partir des index Apr√®s_*
    - La colonne 'ordre_index' permet de trier correctement les relev√©s successifs.

    Args:
        historique (pd.DataFrame): Historique enrichi (HistoriqueP√©rim√®tre√âtendu).

    Returns:
        pd.DataFrame: Relev√©s d'index conformes au mod√®le Relev√©Index.
    """
    index_cols = ["BASE", "HP", "HC", "HCH", "HPH", "HPB", "HCB", "Id_Calendrier_Distributeur"]
    identifiants = ["pdl", "Ref_Situation_Contractuelle", "Formule_Tarifaire_Acheminement"]

    # G√©n√©rer les relev√©s avant/apr√®s en pipe unique
    return (
        pd.concat([
            # Relev√©s "avant" (ordre_index=0)
            (historique[identifiants + ["Date_Evenement"] + [f"Avant_{col}" for col in index_cols]]
             .rename(columns={f"Avant_{col}": col for col in index_cols})
             .assign(ordre_index=0)),
            # Relev√©s "apr√®s" (ordre_index=1) 
            (historique[identifiants + ["Date_Evenement"] + [f"Apr√®s_{col}" for col in index_cols]]
             .rename(columns={f"Apr√®s_{col}": col for col in index_cols})
             .assign(ordre_index=1))
        ], ignore_index=True)
        # Filtrer les lignes avec des index valides
        .dropna(subset=index_cols, how="all")
        # Ajouter les m√©tadonn√©es
        .assign(
            Source="flux_C15",
            Unit√©="kWh",
            Pr√©cision="kWh"
        )
        # Renommer la colonne de date
        .rename(columns={"Date_Evenement": "Date_Releve"})
        # S√©lectionner les colonnes finales pr√©sentes dans le DataFrame
        .pipe(lambda df: df[[col for col in Relev√©Index.to_schema().columns.keys() if col in df.columns]])
    )


@pa.check_types
def enrichir_historique_p√©rim√®tre(historique: DataFrame[HistoriqueP√©rim√®tre]) -> DataFrame[HistoriqueP√©rim√®tre]:
    """
    Enrichit l'historique du p√©rim√®tre avec les points de rupture et les √©v√©nements de facturation.
    
    Cette fonction combine deux traitements essentiels sur l'historique du p√©rim√®tre :
    1. D√©tection des points de rupture (changements de p√©riodes)
    2. Insertion des √©v√©nements de facturation synth√©tiques (1er du mois)
    
    Utilis√©e comme √©tape pr√©paratoire dans les pipelines de calcul d'abonnements et d'√©nergies.
    
    Args:
        historique: Historique des √©v√©nements contractuels du p√©rim√®tre
        
    Returns:
        DataFrame enrichi avec points de rupture d√©tect√©s et √©v√©nements de facturation
    """
    return (
        historique
        .pipe(detecter_points_de_rupture)
        .pipe(inserer_evenements_facturation)
    )