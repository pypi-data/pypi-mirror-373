{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from example_models import get_linear_chain_2v\n",
    "from mxlpy import Simulator, fit_local, make_protocol, plot, unwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "\n",
    "Almost every model at some point needs to be fitted to experimental data to be **validated**.  \n",
    "\n",
    "*mxlpy* offers highly customisable local and global routines for fitting either **time series** or **steady-states**.  \n",
    "\n",
    "<img src=\"assets/fitting.png\" style=\"max-height: 175px;\" />\n",
    "\n",
    "For this tutorial we are going to use the `fit` module to optimise our parameter values and the `plot` module to plot some results.  \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating synthetic data\n",
    "\n",
    "Normally, you would fit your model to experimental data.  \n",
    "Here, for the sake of simplicity, we will generate some synthetic data.  \n",
    "\n",
    "Checkout the [basics tutorial](basics.ipynb) if you need a refresher on building and simulating models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a small trick, let's define a variable for the model function\n",
    "# That way, we can re-use it all over the file and easily replace\n",
    "# it with another model\n",
    "model_fn = get_linear_chain_2v\n",
    "\n",
    "res = unwrap(\n",
    "    Simulator(model_fn())\n",
    "    .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})\n",
    "    .simulate_time_course(np.linspace(0, 10, 101))\n",
    "    .get_result()\n",
    ").get_combined()\n",
    "\n",
    "fig, ax = plot.lines(res)\n",
    "ax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. & Flux / a.u.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steady-states\n",
    "\n",
    "For the steady-state fit we need two inputs:\n",
    "\n",
    "1. the steady state data, which we supply as a `pandas.Series`\n",
    "2. an initial parameter guess\n",
    "\n",
    "The fitting routine will compare all data contained in that series to the model output.  \n",
    "\n",
    "> Note that the data both contains concentrations and fluxes!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res.iloc[-1]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = unwrap(\n",
    "    fit_local.steady_state(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res.iloc[-1],\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If only some of the data is required, you can use a subset of it.  \n",
    "The fitting routine will only try to fit concentrations and fluxes contained in that series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = unwrap(\n",
    "    fit_local.steady_state(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=data.loc[[\"x\", \"y\"]],\n",
    "    )\n",
    ")\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time course\n",
    "\n",
    "For the time course fit we need again need two inputs\n",
    "\n",
    "1. the time course data, which we supply as a `pandas.DataFrame`\n",
    "2. an initial parameter guess\n",
    "\n",
    "The fitting routine will create data at every time points specified in the `DataFrame` and compare all of them.  \n",
    "\n",
    "Other than that, the same rules of the steady-state fitting apply.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = unwrap(\n",
    "    fit_local.time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res,\n",
    "        minimizer=fit_local.ScipyMinimizer(\n",
    "            tol=1e-6,\n",
    "            method=\"Nelder-Mead\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protcol time courses\n",
    "\n",
    "\n",
    "Normally, you would fit your model to experimental data.  \n",
    "Here, again, for the sake of simplicity, we will generate some synthetic data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = make_protocol(\n",
    "    [\n",
    "        (1, {\"k1\": 1.0}),\n",
    "        (1, {\"k1\": 2.0}),\n",
    "        (1, {\"k1\": 1.0}),\n",
    "    ]\n",
    ")\n",
    "\n",
    "res_protocol = unwrap(\n",
    "    Simulator(model_fn())\n",
    "    .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})\n",
    "    .simulate_protocol(\n",
    "        protocol,\n",
    "        time_points_per_step=10,\n",
    "    )\n",
    "    .get_result()\n",
    ").get_combined()\n",
    "\n",
    "fig, ax = plot.lines(res_protocol)\n",
    "ax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. & Flux / a.u.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the protocol time course fit we need three inputs\n",
    "\n",
    "1. an initial parameter guess\n",
    "2. the time course data, which we supply as a `pandas.DataFrame`\n",
    "3. the protocol, which we supply as a `pandas.DataFrame`\n",
    "\n",
    "> Note that the parameter given by the protocol cannot be fitted anymore  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = unwrap(\n",
    "    fit_local.protocol_time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k2\": 1.87, \"k3\": 1.093},  # note that k1 is given by the protocol\n",
    "        data=res_protocol,\n",
    "        protocol=protocol,\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #ffffff; background-color: #04AA6D; padding: 3rem 1rem 3rem 1rem; box-sizing: border-box\">\n",
    "    <h2>First finish line</h2>\n",
    "    With that you now know most of what you will need from a day-to-day basis about fitting in mxlpy.\n",
    "    <br />\n",
    "    <br />\n",
    "    Congratulations!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced topics / customisation\n",
    "\n",
    "\n",
    "All fitting routines internally are build in a way that they will call a tree of functions. \n",
    "\n",
    "- `minimizer`\n",
    "  - `residual_fn`\n",
    "    - `integrator`\n",
    "    - `loss_fn`\n",
    "  \n",
    "\n",
    "You can therefore use dependency injection to overwrite the minimisation function, the loss function, the residual function and the integrator if need be.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import TYPE_CHECKING, cast\n",
    "\n",
    "from mxlpy.fit.common import LossFn\n",
    "from mxlpy.integrators import Scipy\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    import pandas as pd\n",
    "\n",
    "    from mxlpy.fit.common import ResidualFn\n",
    "    from mxlpy.model import Model\n",
    "    from mxlpy.types import Array, IntegratorType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterising scipy optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = fit_local.ScipyMinimizer(tol=1e-6, method=\"Nelder-Mead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function\n",
    "\n",
    "You can change the loss function that is being passed to the minimsation function using the `loss_fn` keyword.  \n",
    "Depending on the use case (time course vs steady state) this function will be passed two pandas `DataFrame`s or `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(\n",
    "    x: pd.DataFrame | pd.Series,\n",
    "    y: pd.DataFrame | pd.Series,\n",
    ") -> float:\n",
    "    \"\"\"Mean absolute error between two dataframes.\"\"\"\n",
    "    return cast(float, np.mean(np.abs(x - y)))\n",
    "\n",
    "\n",
    "fit_result = unwrap(\n",
    "    fit_local.time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res,\n",
    "        loss_fn=mean_absolute_error,\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom integrator\n",
    "\n",
    "You can change the default integrator to an integrator of your choice by partially application of the class of any of the existing ones.  \n",
    "\n",
    "Here, for example, we choose the `Scipy` solver suite and set the default relative and absolute tolerances to `1e-6` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = unwrap(\n",
    "    fit_local.time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res,\n",
    "        integrator=partial(Scipy, rtol=1e-6, atol=1e-6),\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom minimisation\n",
    "\n",
    "You can change the default `minimizer` from to any other function that takes a `ResidualFn` and minimizes it.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxlpy.fit.local_ import Bounds, MinResult\n",
    "\n",
    "\n",
    "def nelder_mead(\n",
    "    residual_fn: ResidualFn,\n",
    "    p0: dict[str, float],\n",
    "    bounds: Bounds,\n",
    ") -> MinResult | None:\n",
    "    res = minimize(\n",
    "        residual_fn,\n",
    "        x0=list(p0.values()),\n",
    "        bounds=[bounds.get(name, (1e-6, 1e6)) for name in p0],\n",
    "        method=\"Nelder-Mead\",\n",
    "    )\n",
    "    if res.success:\n",
    "        return MinResult(\n",
    "            parameters=dict(\n",
    "                zip(\n",
    "                    p0,\n",
    "                    res.x,\n",
    "                    strict=True,\n",
    "                )\n",
    "            ),\n",
    "            residual=res.fun,\n",
    "        )\n",
    "    return None\n",
    "\n",
    "\n",
    "fit_result = unwrap(\n",
    "    fit_local.time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res,\n",
    "        minimizer=nelder_mead,\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom residual function\n",
    "\n",
    "You can change the residual function to include further behaviour.  \n",
    "\n",
    "The barebones implementation is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_course_residual(\n",
    "    par_values: Array,\n",
    "    # This will be filled out by partial\n",
    "    par_names: list[str],\n",
    "    data: pd.DataFrame,\n",
    "    model: Model,\n",
    "    y0: dict[str, float] | None,\n",
    "    integrator: IntegratorType,\n",
    "    loss_fn: LossFn,\n",
    ") -> float:\n",
    "    \"\"\"Calculate residual error between model time course and experimental data.\n",
    "\n",
    "    Args:\n",
    "        par_values: Parameter values to test\n",
    "        data: Experimental time course data\n",
    "        model: Model instance to simulate\n",
    "        y0: Initial conditions\n",
    "        par_names: Names of parameters being fit\n",
    "        integrator: ODE integrator class to use\n",
    "        loss_fn: Loss function to use for residual calculation\n",
    "\n",
    "    Returns:\n",
    "        float: Root mean square error between model and data\n",
    "\n",
    "    \"\"\"\n",
    "    res = (\n",
    "        Simulator(\n",
    "            model.update_parameters(dict(zip(par_names, par_values, strict=True))),\n",
    "            y0=y0,\n",
    "            integrator=integrator,\n",
    "        )\n",
    "        .simulate_time_course(cast(list, data.index))\n",
    "        .get_result()\n",
    "    )\n",
    "    if res is None:\n",
    "        return cast(float, np.inf)\n",
    "    results_ss = res.get_combined()\n",
    "\n",
    "    return loss_fn(\n",
    "        results_ss.loc[:, cast(list, data.columns)],\n",
    "        data,\n",
    "    )\n",
    "\n",
    "\n",
    "fit_result = unwrap(\n",
    "    fit_local.time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res,\n",
    "        residual_fn=time_course_residual,\n",
    "    )\n",
    ")\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mxlpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
